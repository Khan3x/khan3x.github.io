

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/logo.png">
  <link rel="icon" href="/img/logo.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="toutou">
  <meta name="keywords" content="">
  
    <meta name="description" content="CS Concepts本章笔记着重对CS相关专业科目的名词进行解释，在修考问答题和面试八股文场景下适用。这些名词都来源于CS相关学科。本篇笔记内容按科目划分，每个科目下面有对应的常见高频名词解释（中&#x2F;英）。 1. Data Stucture &amp; AlgorithmsHash TableA Hash Table is a data structure that maps keys to va">
<meta property="og:type" content="article">
<meta property="og:title" content="CS Concepts">
<meta property="og:url" content="http://toutou.zeabur.app/2025/02/09/CS-Concepts/index.html">
<meta property="og:site_name" content="偷偷星球">
<meta property="og:description" content="CS Concepts本章笔记着重对CS相关专业科目的名词进行解释，在修考问答题和面试八股文场景下适用。这些名词都来源于CS相关学科。本篇笔记内容按科目划分，每个科目下面有对应的常见高频名词解释（中&#x2F;英）。 1. Data Stucture &amp; AlgorithmsHash TableA Hash Table is a data structure that maps keys to va">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/hash.jpg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/hash2.jpg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/pnp.jpg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/tsp.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/bnb.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/btree.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/astar.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/minimax.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/process.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/dynamic_branch.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/parallelism.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/wb.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/multicache.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/cache3.jpg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/superscalar.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/tlb.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/random.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/linear.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/logistic.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/dht.svg">
<meta property="article:published_time" content="2025-02-09T15:25:17.000Z">
<meta property="article:modified_time" content="2025-08-17T17:39:06.135Z">
<meta property="article:author" content="toutou">
<meta property="article:tag" content="修考">
<meta property="article:tag" content="CS Concepts">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://toutou.zeabur.app/img/concepts/hash.jpg">
  
  
  
  <title>CS Concepts - 偷偷星球</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"toutou.zeabur.app","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>偷偷星球</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/wall.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CS Concepts"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-02-09 23:25" pubdate>
          February 9, 2025 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.1k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          60 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CS Concepts</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="CS-Concepts"><a href="#CS-Concepts" class="headerlink" title="CS Concepts"></a>CS Concepts</h1><p>本章笔记着重对CS相关专业科目的名词进行解释，在修考问答题和面试八股文场景下适用。这些名词都来源于CS相关学科。本篇笔记内容按科目划分，每个科目下面有对应的常见高频名词解释（中/英）。</p>
<h2 id="1-Data-Stucture-amp-Algorithms"><a href="#1-Data-Stucture-amp-Algorithms" class="headerlink" title="1. Data Stucture &amp; Algorithms"></a>1. Data Stucture &amp; Algorithms</h2><h3 id="Hash-Table"><a href="#Hash-Table" class="headerlink" title="Hash Table"></a>Hash Table</h3><p>A Hash Table is a data structure that maps keys to values using a hash function. It stores data in an array-like structure, where each key is hashed to an index. Collisions (when different keys map to the same index) are handled using techniques like chaining or open addressing. Hash tables provide average O(1) time complexity for insertion, deletion, and lookup. They are widely used in databases, caching, and symbol tables.<br><img src="/img/concepts/hash.jpg" srcset="/img/loading.gif" lazyload alt="Hash Table" style="max-width: 70%; height: auto;" /></p>
<hr>
<h3 id="Hash-Collision-Hash-Clash"><a href="#Hash-Collision-Hash-Clash" class="headerlink" title="Hash Collision / Hash Clash"></a>Hash Collision / Hash Clash</h3><p>A <strong>hash collision (hash clash)</strong> occurs when two different inputs produce the same hash value in a hash function. Since hash functions map a large input space to a smaller output space, collisions are inevitable due to the <strong>pigeonhole principle</strong>. Collisions can weaken security in cryptographic hashes (e.g., MD5, SHA-1) and reduce efficiency in hash tables. Techniques like <strong>chaining, open addressing, and better hash functions</strong> help mitigate collisions. Stronger cryptographic hashes (e.g., SHA-256) minimize the risk of intentional hash clashes (collision attacks).</p>
<hr>
<h3 id="Open-Addressing-Closed-Hashing"><a href="#Open-Addressing-Closed-Hashing" class="headerlink" title="Open Addressing / Closed Hashing"></a>Open Addressing / Closed Hashing</h3><p><strong>Open addressing</strong> is a collision resolution technique in hash tables where all elements are stored directly in the table without external chaining. When a collision occurs, the algorithm searches for the next available slot using a probing sequence (e.g., <strong>linear probing, quadratic probing, or double hashing</strong>). <strong>Linear probing</strong> checks the next slot sequentially, <strong>quadratic probing</strong> uses a quadratic function to find slots, and <strong>double hashing</strong> applies a second hash function for probing. Open addressing avoids linked lists, reducing memory overhead but may suffer from clustering. It works best when the load factor is kept low to maintain efficient lookups.</p>
<hr>
<h3 id="Seperate-Chaining"><a href="#Seperate-Chaining" class="headerlink" title="Seperate Chaining"></a>Seperate Chaining</h3><p><strong>Separate chaining</strong> is a collision resolution technique in hash tables where each bucket stores multiple values using a linked list (or another data structure like a BST). When a collision occurs, the new element is simply added to the linked list at that index. This method allows the table to handle an unlimited number of collisions but increases memory usage. Performance depends on the length of the chains; with a well-distributed hash function, the average lookup time remains <strong>O(1) in best case</strong> and <strong>O(n) in worst case</strong>. <strong>Rehashing</strong> or using a larger table can help maintain efficiency.</p>
<p><img src="/img/concepts/hash2.jpg" srcset="/img/loading.gif" lazyload alt="Hash Table" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="P-≠-NP"><a href="#P-≠-NP" class="headerlink" title="P ≠ NP"></a>P ≠ NP</h3><p><strong>P ≠ NP</strong> means that not all problems whose solutions can be <em>verified quickly</em> (in polynomial time) can also be <em>solved quickly</em>.<br><strong>P</strong> is the class of problems that can be <strong>solved</strong> in polynomial time.<br><strong>NP</strong> is the class of problems whose solutions can be <strong>verified</strong> in polynomial time.<br>The question is: if a problem’s solution can be verified quickly, can it also be found quickly?<br>Most experts believe <strong>P ≠ NP</strong>, but it has not been proven yet.</p>
<p><img src="/img/concepts/pnp.jpg" srcset="/img/loading.gif" lazyload alt="Hash Table" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="NP-Hard-Problems"><a href="#NP-Hard-Problems" class="headerlink" title="NP Hard Problems"></a>NP Hard Problems</h3><p>NP-Hard problems are computational problems that are at least as difficult as the hardest problems in NP (nondeterministic polynomial time). Solving an NP-Hard problem quickly would mean we could solve every NP problem quickly too, but no such efficient solution is known. These problems may not even have verifiable solutions in polynomial time. They often involve optimization or decision-making with many possibilities, like scheduling, routing, or packing.Examples include the Traveling Salesman Problem and Knapsack Problem.</p>
<hr>
<h3 id="NP-Complete-Problems"><a href="#NP-Complete-Problems" class="headerlink" title="NP-Complete Problems"></a>NP-Complete Problems</h3><p><strong>NP-Complete problems</strong> are a special class of problems that are both:</p>
<ol>
<li><strong>In NP</strong> – their solutions can be verified in polynomial time, and</li>
<li><strong>NP-Hard</strong> – as hard as the hardest problems in NP.</li>
</ol>
<p>If you can solve any NP-Complete problem quickly (in polynomial time), you can solve <em>all</em> NP problems quickly. Famous examples include the <strong>Boolean Satisfiability Problem (SAT)</strong> and <strong>Traveling Salesman Problem (decision version)</strong>.</p>
<hr>
<h3 id="The-Travelling-Salesman-Problem"><a href="#The-Travelling-Salesman-Problem" class="headerlink" title="The Travelling Salesman Problem"></a>The Travelling Salesman Problem</h3><p>The <strong>Travelling Salesman Problem (TSP)</strong> asks for the shortest possible route that visits each city once and returns to the starting city.<br>It is a classic <strong>combinatorial optimization</strong> problem in computer science and operations research.<br>TSP is <strong>NP-hard</strong>, meaning there’s no known efficient algorithm to solve all cases quickly.<br>Exact solutions use methods like <strong>brute force</strong>, <strong>dynamic programming</strong>, or <strong>branch and bound</strong>.<br>Approximation and heuristic algorithms (e.g. genetic algorithms, simulated annealing) are used for large instances.</p>
<p><img src="/img/concepts/tsp.svg" srcset="/img/loading.gif" lazyload alt="TSP" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="The-Knapsack-Problem"><a href="#The-Knapsack-Problem" class="headerlink" title="The Knapsack Problem"></a>The Knapsack Problem</h3><p>The <strong>Knapsack Problem</strong> asks how to choose items with given weights and values to maximize total value without exceeding a weight limit.<br>Each item can be either included or excluded (0-1 Knapsack).<br>It’s a classic <strong>NP-hard</strong> optimization problem.<br>Dynamic programming is commonly used for exact solutions.<br>Greedy or approximation methods are used for large instances.</p>
<hr>
<h3 id="The-SAT-Boolean-Satisfiability-problem"><a href="#The-SAT-Boolean-Satisfiability-problem" class="headerlink" title="The SAT (Boolean Satisfiability) problem"></a>The SAT (Boolean Satisfiability) problem</h3><p>The <strong>SAT (Boolean Satisfiability)</strong> problem asks whether there exists an assignment of true/false values to variables that makes a Boolean formula true.<br>It’s the <strong>first problem proven to be NP-complete</strong>.<br>The formula is usually given in <strong>CNF (Conjunctive Normal Form)</strong>.<br>SAT solvers use techniques like backtracking and clause learning.<br>Many real-world problems (e.g. planning, verification) can be reduced to SAT.</p>
<hr>
<h3 id="Divide-and-Conquer"><a href="#Divide-and-Conquer" class="headerlink" title="Divide and Conquer"></a>Divide and Conquer</h3><p><strong>Divide and Conquer</strong> is a problem-solving strategy that works in three main steps:</p>
<ol>
<li><strong>Divide</strong> the problem into smaller sub-problems of the same type.</li>
<li><strong>Conquer</strong> each sub-problem by solving them recursively.</li>
<li><strong>Combine</strong> the solutions of sub-problems to get the final result.</li>
</ol>
<p>Classic examples include <strong>Merge Sort</strong>, <strong>Quick Sort</strong>, and <strong>Binary Search</strong>.</p>
<hr>
<h3 id="Branch-and-Bound"><a href="#Branch-and-Bound" class="headerlink" title="Branch and Bound"></a>Branch and Bound</h3><p>Branch and Bound is an algorithmic paradigm for solving combinatorial optimization problems efficiently. It systematically divides the solution space into smaller subproblems (branching) and computes bounds to eliminate unpromising branches early (pruning). The method maintains an upper bound from feasible solutions and a lower bound from relaxed problems, allowing it to discard branches that cannot contain the optimal solution. This approach significantly reduces the search space compared to exhaustive enumeration, making it effective for problems like integer programming, traveling salesman, and knapsack problems.</p>
<p><img src="/img/concepts/bnb.svg" srcset="/img/loading.gif" lazyload alt="Branch and Bound" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="B-tree"><a href="#B-tree" class="headerlink" title="B-tree"></a>B-tree</h3><p>A <strong>B-tree</strong> is a self-balancing search tree that maintains sorted data for efficient insertion, deletion, and search in <strong>O(log n)</strong> time.<br>It allows each node to have <strong>multiple keys and children</strong>, making it wider and shallower than binary trees.<br>All leaf nodes are at the same level, ensuring the tree stays balanced.<br>It’s widely used in <strong>databases and file systems</strong> for fast disk-based access.</p>
<p><img src="/img/concepts/btree.svg" srcset="/img/loading.gif" lazyload alt="Hash Table" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Heap-Sort"><a href="#Heap-Sort" class="headerlink" title="Heap Sort"></a>Heap Sort</h3><p><strong>Heap Sort</strong> is a comparison-based sorting algorithm that uses a <strong>binary heap</strong> data structure. It works in two main steps:</p>
<ol>
<li><strong>Build a Max Heap</strong> from the input data so that the largest element is at the root.</li>
<li><strong>Extract the root (maximum element)</strong>, swap it with the last item, reduce the heap size, and <strong>heapify</strong> the root to maintain the max heap. Repeat until the heap is empty.</li>
</ol>
<p>Time Complexity: <strong>Best, Average, Worst:</strong> O(n log n)</p>
<p>Key Characteristics:</p>
<ul>
<li><strong>In-place</strong> sorting (no extra space needed)</li>
<li><strong>Not stable</strong></li>
<li>Good for scenarios where memory is limited and performance is important.</li>
</ul>
<hr>
<h3 id="Merge-Sort"><a href="#Merge-Sort" class="headerlink" title="Merge Sort"></a>Merge Sort</h3><p><strong>Merge Sort</strong> is a <strong>divide and conquer</strong> sorting algorithm that divides the input array into smaller parts, sorts them, and then merges the sorted parts.</p>
<p>Steps:</p>
<ol>
<li><strong>Divide</strong> the array into two halves.</li>
<li><strong>Recursively sort</strong> each half.</li>
<li><strong>Merge</strong> the two sorted halves into one sorted array.</li>
</ol>
<p>Time Complexity:</p>
<ul>
<li><strong>Best, Average, Worst:</strong> O(n log n)</li>
</ul>
<p>Key Characteristics:</p>
<ul>
<li><strong>Stable</strong> sort</li>
<li><strong>Not in-place</strong> (uses extra space for merging)</li>
<li>Great for sorting linked lists or large datasets with consistent performance.</li>
</ul>
<hr>
<h3 id="Quick-Sort"><a href="#Quick-Sort" class="headerlink" title="Quick Sort"></a>Quick Sort</h3><p><strong>Quick Sort</strong> is a <strong>divide and conquer</strong> sorting algorithm that works by selecting a <strong>pivot</strong> element and partitioning the array into two parts:</p>
<p>Steps:</p>
<ol>
<li><strong>Choose a pivot</strong> (e.g., first, last, or random element).</li>
<li><strong>Partition</strong> the array: elements less than pivot go left, greater go right.</li>
<li><strong>Recursively apply</strong> Quick Sort to the left and right parts.</li>
</ol>
<p>Time Complexity:</p>
<ul>
<li><strong>Best &amp; Average:</strong> O(n log n)</li>
<li><strong>Worst (unbalanced partition):</strong> O(n²)</li>
</ul>
<p>Key Characteristics:</p>
<ul>
<li><strong>In-place</strong></li>
<li><strong>Not stable</strong></li>
<li>Very fast in practice with good pivot selection</li>
</ul>
<hr>
<h3 id="A-Algorithm"><a href="#A-Algorithm" class="headerlink" title="A* Algorithm"></a>A* Algorithm</h3><p>The A* algorithm finds the shortest path by combining actual cost from the start (g) and estimated cost to the goal (h).<br>It selects nodes with the lowest total cost <code>f(n) = g(n) + h(n)</code>.<br>It uses a priority queue to explore the most promising paths first.<br>The heuristic <code>h(n)</code> must not overestimate to ensure optimality.<br>It’s widely used in games, maps, and AI for efficient pathfinding.</p>
<p><img src="/img/concepts/astar.svg" srcset="/img/loading.gif" lazyload alt="A* Algorithm" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Minimax-Algorithm"><a href="#Minimax-Algorithm" class="headerlink" title="Minimax Algorithm"></a>Minimax Algorithm</h3><p>The <strong>Minimax algorithm</strong> is used in two-player games to find the optimal move by assuming both players play optimally.<br>It recursively explores all possible moves, maximizing the player’s score and minimizing the opponent’s.<br>“Max” tries to get the highest score; “Min” tries to get the lowest.<br>The game tree is evaluated using a scoring function at terminal states.<br>It’s often optimized with <strong>alpha-beta pruning</strong> to skip unnecessary branches.</p>
<p><img src="/img/concepts/minimax.svg" srcset="/img/loading.gif" lazyload alt="Minimax Algorithm" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="🤖-Alpha-Beta-Pruning"><a href="#🤖-Alpha-Beta-Pruning" class="headerlink" title="🤖 Alpha-Beta Pruning"></a>🤖 Alpha-Beta Pruning</h3><p><strong>Alpha-Beta Pruning</strong> is an <strong>optimization technique</strong> for the <strong>Minimax algorithm</strong> used in <strong>two-player games</strong> (like chess or tic-tac-toe).<br>It <strong>reduces the number of nodes</strong> evaluated in the game tree <strong>without affecting the final result</strong>.</p>
<p><strong>🧠 How It Works</strong></p>
<ul>
<li><strong>Alpha (α):</strong> the best <strong>already explored</strong> value for the <strong>maximizing</strong> player.</li>
<li><strong>Beta (β):</strong> the best <strong>already explored</strong> value for the <strong>minimizing</strong> player.</li>
</ul>
<p>While traversing the tree:</p>
<ul>
<li>If the <strong>current branch</strong> cannot possibly influence the final decision (because it’s worse than previously examined branches), it is <strong>pruned</strong> (skipped).</li>
</ul>
<p><strong>✅ Benefits</strong></p>
<ul>
<li>Same result as Minimax, but faster</li>
<li>Reduces time complexity from <strong>O(b^d)</strong> to <strong>O(b^(d/2))</strong> in the best case<br>(where <code>b</code> is branching factor, <code>d</code> is depth)</li>
</ul>
<p><strong>📌 Example</strong></p>
<p>In a minimax tree:</p>
<ul>
<li>If a <strong>max node</strong> finds a value <strong>≥ β</strong>, it <strong>stops</strong> exploring further children.</li>
<li>If a <strong>min node</strong> finds a value <strong>≤ α</strong>, it <strong>prunes</strong> the remaining branches.</li>
</ul>
<p><strong>🎯 Use Cases</strong></p>
<ul>
<li>AI game engines</li>
<li>Decision-making in adversarial environments</li>
<li>Game tree search optimization</li>
</ul>
<h2 id="2-Operating-System"><a href="#2-Operating-System" class="headerlink" title="2. Operating System"></a>2. Operating System</h2><h3 id="Procss-amp-Thread"><a href="#Procss-amp-Thread" class="headerlink" title="Procss &amp; Thread"></a>Procss &amp; Thread</h3><p>A process is the basic unit of resource allocation and scheduling in an operating system, with its own independent address space and resources. A thread is the basic unit of CPU scheduling, and a process can contain multiple threads that share the process’s memory and resources. Threads switch faster and have lower overhead, making them suitable for concurrent execution. In contrast, processes are independent of each other, with higher switching overhead but greater stability. While multithreading improves execution efficiency, it also introduces challenges such as synchronization and mutual exclusion.</p>
<p><img src="/img/concepts/process.svg" srcset="/img/loading.gif" lazyload alt="Process & Thread" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h3><p>A <strong>semaphore</strong> in an operating system is a synchronization tool used to manage <strong>concurrent access to shared resources</strong> by multiple processes or threads.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li>It is an <strong>integer variable</strong> that controls access based on its value.</li>
<li><p>There are two main operations:</p>
<ul>
<li><strong>wait (P)</strong>: Decreases the semaphore value. If the result is negative, the process is blocked.</li>
<li><strong>signal (V)</strong>: Increases the semaphore value. If there are blocked processes, one is unblocked.</li>
</ul>
</li>
</ul>
<p><strong>Types:</strong></p>
<ol>
<li><strong>Binary Semaphore</strong>: Takes values 0 or 1, similar to a mutex.</li>
<li><strong>Counting Semaphore</strong>: Can take non-negative integer values, used to control access to a resource with multiple instances.</li>
</ol>
<p><strong>Use Case:</strong></p>
<p>Semaphores help <strong>avoid race conditions</strong>, <strong>deadlocks</strong>, and ensure <strong>mutual exclusion</strong> in critical sections.</p>
<p>Example use: Controlling access to a printer shared by multiple processes.</p>
<hr>
<h3 id="Critical-Section"><a href="#Critical-Section" class="headerlink" title="Critical Section"></a>Critical Section</h3><p>A <strong>Critical Section</strong> in an operating system is a part of a program where a <strong>shared resource</strong> (like a variable, file, or device) is accessed. Since shared resources can be corrupted if accessed by multiple processes or threads simultaneously, <strong>only one process should enter the critical section at a time</strong>.</p>
<p><strong>Key Concepts:</strong></p>
<ul>
<li><strong>Mutual Exclusion</strong>: Ensures that only one process is in the critical section at any given time.</li>
<li><strong>Entry Section</strong>: Code that requests entry to the critical section.</li>
<li><strong>Exit Section</strong>: Code that signals the process is leaving the critical section.</li>
<li><strong>Remainder Section</strong>: All other code outside the critical section.</li>
</ul>
<blockquote>
<p>Goals of Critical Section Management:</p>
</blockquote>
<ol>
<li><strong>Mutual Exclusion</strong> – Only one process in the critical section at a time.</li>
<li><strong>Progress</strong> – If no process is in the critical section, one of the waiting processes should be allowed to enter.</li>
<li><strong>Bounded Waiting</strong> – A process should not wait forever to enter the critical section.</li>
</ol>
<p><strong>Tools Used:</strong></p>
<ul>
<li><strong>Semaphores</strong></li>
<li><strong>Mutexes</strong></li>
<li><strong>Monitors</strong></li>
<li><strong>Locks</strong></li>
</ul>
<p>These tools help implement and manage access to critical sections safely.</p>
<hr>
<h2 id="3-Computer-Architecture"><a href="#3-Computer-Architecture" class="headerlink" title="3. Computer Architecture"></a>3. Computer Architecture</h2><h3 id="Pipeline-hazard"><a href="#Pipeline-hazard" class="headerlink" title="Pipeline hazard"></a>Pipeline hazard</h3><p>A <strong>pipeline hazard</strong> in computer architecture refers to a situation that <strong>prevents the next instruction in the pipeline from executing at its expected time</strong>, causing delays.</p>
<p><strong>Types of Pipeline Hazards:</strong></p>
<ol>
<li><p><strong>Data Hazard</strong>:<br>Occurs when instructions <strong>depend on the result of a previous instruction</strong> that hasn’t completed yet.<br>Example:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-pgsql" data-language="pgsql"><code class="language-pgsql">ADD R1, R2, R3  
SUB R4, R1, R5  ← depends on R1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
</li>
<li><p><strong>Control Hazard</strong> (Branch Hazard):<br>Happens when the pipeline makes <strong>wrong predictions about instruction flow</strong>, such as branches or jumps.</p>
</li>
<li><p><strong>Structural Hazard</strong>:<br>Arises when <strong>hardware resources are insufficient</strong> to support all instructions in parallel (e.g., one memory unit shared by two stages).</p>
</li>
</ol>
<p><strong>Solution Techniques:</strong></p>
<ul>
<li><strong>Forwarding (data hazard)</strong></li>
<li><strong>Stalling (inserting bubbles)</strong></li>
<li><strong>Branch prediction (control hazard)</strong></li>
<li><strong>Adding hardware units (structural hazard)</strong></li>
</ul>
<p>Pipeline hazards reduce performance and must be carefully handled in modern CPUs.</p>
<hr>
<h3 id="Data-hazard"><a href="#Data-hazard" class="headerlink" title="Data hazard"></a>Data hazard</h3><p>A <strong>data hazard</strong> occurs in a pipelined processor when an instruction depends on the <strong>result of a previous instruction</strong> that has not yet completed, causing a conflict in data access.</p>
<p><strong>Types of Data Hazards:</strong></p>
<ol>
<li><p><strong>RAW (Read After Write)</strong> – Most common<br>An instruction needs to <strong>read</strong> a register that a previous instruction will <strong>write</strong>, but the write hasn’t happened yet.<br>Example:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-pgsql" data-language="pgsql"><code class="language-pgsql">ADD R1, R2, R3  
SUB R4, R1, R5  ← needs R1 before it&#39;s written<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
</li>
<li><p><strong>WAR (Write After Read)</strong> – Rare in simple pipelines<br>A later instruction writes to a register <strong>before</strong> an earlier instruction reads it.</p>
</li>
<li><p><strong>WAW (Write After Write)</strong> – Happens in out-of-order execution<br>Two instructions write to the same register in the wrong order.</p>
</li>
</ol>
<p><strong>Solutions:</strong></p>
<ul>
<li><strong>Forwarding (bypassing)</strong> – Pass result directly to the next instruction.</li>
<li><strong>Stalling</strong> – Delay the dependent instruction until data is ready.</li>
</ul>
<p>Data hazards can slow down pipeline performance if not properly managed.</p>
<hr>
<h3 id="Control-hazard"><a href="#Control-hazard" class="headerlink" title="Control hazard"></a>Control hazard</h3><p>A <strong>control hazard</strong> (also called a <strong>branch hazard</strong>) occurs in pipelined processors when the <strong>flow of instruction execution changes</strong>, typically due to <strong>branch or jump instructions</strong>.</p>
<p><strong>Cause:</strong></p>
<p>The processor <strong>doesn’t know early enough</strong> whether a branch will be taken, so it may <strong>fetch the wrong instructions</strong>.</p>
<p><strong>Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">BEQ R1, R2, LABEL   ; Branch if R1 &#x3D;&#x3D; R2
ADD R3, R4, R5      ; May be wrongly fetched if branch is taken<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>Solutions:</strong></p>
<ul>
<li><strong>Branch Prediction</strong> – Guess whether the branch will be taken.</li>
<li><strong>Branch Delay Slot</strong> – Always execute the instruction after the branch.</li>
<li><strong>Pipeline Flushing</strong> – Discard wrongly fetched instructions.</li>
<li><strong>Early Branch Resolution</strong> – Move branch decision to earlier pipeline stage.</li>
</ul>
<p>Control hazards can reduce pipeline efficiency by introducing <strong>stalls or flushes</strong>.</p>
<hr>
<h3 id="Structural-hazard"><a href="#Structural-hazard" class="headerlink" title="Structural hazard"></a>Structural hazard</h3><p>A <strong>structural hazard</strong> occurs in a pipelined processor when <strong>two or more instructions compete for the same hardware resource</strong> at the same time, and the hardware <strong>cannot handle all of them simultaneously</strong>.</p>
<p><strong>Example:</strong></p>
<p>If the CPU has <strong>one memory unit</strong> shared for both <strong>instruction fetch</strong> and <strong>data access</strong>, a conflict arises when:</p>
<ul>
<li>One instruction is being <strong>fetched</strong>, and</li>
<li>Another instruction needs to <strong>read/write data</strong> from memory at the same time.</li>
</ul>
<p><strong>Solution:</strong></p>
<ul>
<li><strong>Add more hardware resources</strong> (e.g. separate instruction and data memory – like in Harvard architecture)</li>
<li><strong>Stall one of the instructions</strong> to resolve the conflict</li>
</ul>
<p>Structural hazards are <strong>less common</strong> in modern CPUs due to better hardware design but can still occur in resource-limited systems.</p>
<hr>
<h3 id="Dynamic-Branch-Prediction"><a href="#Dynamic-Branch-Prediction" class="headerlink" title="Dynamic Branch Prediction"></a>Dynamic Branch Prediction</h3><p><strong>Dynamic Branch Prediction</strong> is a technique used in modern CPUs to <strong>predict the outcome of branch instructions (e.g., if-else, loops) at runtime</strong>, based on the <strong>history of previous executions</strong>.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Learns from past behavior</strong> of branches.</li>
<li><strong>Updates prediction</strong> as the program runs.</li>
<li>More accurate than static prediction (which always predicts taken/not taken).</li>
</ul>
<p><strong>Common Methods:</strong></p>
<ol>
<li><p><strong>1-bit predictor</strong>:<br>Remembers the last outcome (taken or not taken).</p>
</li>
<li><p><strong>2-bit predictor</strong>:<br>More stable; uses a state machine to change prediction only after two mispredictions.</p>
</li>
<li><p><strong>Branch History Table (BHT)</strong>:<br>Stores past branch outcomes and uses them for prediction.</p>
</li>
<li><p><strong>Global History &amp; Pattern History Table (PHT)</strong>:<br>Tracks patterns of multiple branches for more accuracy (used in <strong>two-level predictors</strong>).</p>
</li>
</ol>
<p><strong>Benefit:</strong></p>
<p>Improves <strong>pipeline efficiency</strong> by reducing <strong>control hazards</strong> and minimizing <strong>stall cycles</strong> caused by branch mispredictions.</p>
<p><img src="/img/concepts/dynamic_branch.svg" srcset="/img/loading.gif" lazyload alt="Dynamic Branch Prediction" style="max-width: 100%; height: auto;" /></p>
<p>—</p>
<h3 id="Instruction-level-Parallelsim"><a href="#Instruction-level-Parallelsim" class="headerlink" title="Instruction-level Parallelsim"></a>Instruction-level Parallelsim</h3><p><strong>Instruction-Level Parallelism (ILP)</strong> refers to the ability of a CPU to <strong>execute multiple instructions simultaneously</strong> during a single clock cycle.</p>
<p><strong>Key Idea:</strong></p>
<p>Many instructions in a program are <strong>independent</strong> and can be executed in <strong>parallel</strong>, rather than strictly one after another.</p>
<p><strong>Types of ILP:</strong></p>
<ol>
<li><p><strong>Compiler-Level ILP (Static ILP)</strong><br>The <strong>compiler rearranges instructions</strong> at compile time to exploit parallelism (e.g., instruction scheduling).</p>
</li>
<li><p><strong>Hardware-Level ILP (Dynamic ILP)</strong><br>The <strong>CPU detects parallelism at runtime</strong>, using features like:</p>
<ul>
<li><strong>Pipelining</strong></li>
<li><strong>Superscalar execution</strong> (multiple execution units)</li>
<li><strong>Out-of-order execution</strong></li>
<li><strong>Speculative execution</strong></li>
</ul>
</li>
</ol>
<p><strong>Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">ADD R1, R2, R3  
MUL R4, R5, R6   ; Independent → can run in parallel with ADD<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>Benefits:</strong></p>
<ul>
<li>Increases CPU performance <strong>without increasing clock speed</strong></li>
<li>Makes better use of CPU resources</li>
</ul>
<p><strong>Limitations:</strong></p>
<ul>
<li><strong>Data, control, and structural hazards</strong> limit ILP</li>
<li><strong>Dependence between instructions</strong> reduces parallelism</li>
</ul>
<p>Modern processors heavily rely on ILP for high-speed performance.</p>
<p><img src="/img/concepts/parallelism.svg" srcset="/img/loading.gif" lazyload alt="Instruction-level Parallelsim" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Clock-frequency"><a href="#Clock-frequency" class="headerlink" title="Clock frequency"></a>Clock frequency</h3><p><strong>Clock frequency</strong> (also called <strong>clock speed</strong>) is the rate at which a processor executes instructions, measured in <strong>Hertz (Hz)</strong> — typically in <strong>gigahertz (GHz)</strong> for modern CPUs.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>1 GHz = 1 billion cycles per second</strong></li>
<li>Each <strong>clock cycle</strong> is a tick of the CPU’s internal clock, during which it can perform basic operations (like fetch, decode, execute).</li>
<li>A <strong>higher clock frequency</strong> generally means the CPU can <strong>perform more operations per second</strong>.</li>
</ul>
<blockquote>
<p>Example: A CPU with <strong>3.0 GHz</strong> can perform <strong>3 billion clock cycles per second</strong>.</p>
</blockquote>
<p>Higher clock speed <strong>doesn’t always mean better performance</strong>, because:</p>
<ul>
<li>Other factors like <strong>Instruction-Level Parallelism (ILP)</strong>, <strong>number of cores</strong>, <strong>cache</strong>, and <strong>architecture efficiency</strong> also matter.</li>
<li>Very high clock speeds can cause <strong>more heat and power consumption</strong>.</li>
</ul>
<p><strong>Clock frequency = speed of instruction processing</strong>, but <strong>not the only factor</strong> in CPU performance.</p>
<hr>
<h3 id="Register-renaming"><a href="#Register-renaming" class="headerlink" title="Register renaming"></a>Register renaming</h3><p><strong>Register renaming</strong> is a technique used in modern CPUs to <strong>eliminate false data dependencies</strong> (also called <em>name dependencies</em>) between instructions, allowing for more <strong>instruction-level parallelism (ILP)</strong> and better performance.</p>
<blockquote>
<p>Why It’s Needed?</p>
</blockquote>
<p>In pipelined or out-of-order execution, instructions may appear dependent due to <strong>using the same register name</strong>, even when there’s <strong>no real data dependency</strong>.</p>
<p>There are two main false dependencies:</p>
<ol>
<li><strong>Write After Write (WAW)</strong></li>
<li><strong>Write After Read (WAR)</strong></li>
</ol>
<p><strong>Example (with false dependency):</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">1. ADD R1, R2, R3  
2. SUB R1, R4, R5  ← falsely depends on instruction 1 (WAW)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p>Both write to <code>R1</code>, but they’re unrelated operations. Register renaming removes this conflict.</p>
<blockquote>
<p>How It Works:</p>
</blockquote>
<ul>
<li>The CPU maintains a <strong>larger set of physical registers</strong> than the number of logical (visible) registers.</li>
<li>It dynamically assigns <strong>different physical registers</strong> to each instruction, even if they use the same logical name.</li>
<li>This avoids name-based conflicts, enabling <strong>out-of-order</strong> and <strong>parallel execution</strong>.</li>
</ul>
<p>Benefits:</p>
<ul>
<li><strong>Eliminates false dependencies</strong></li>
<li><strong>Increases parallelism</strong></li>
<li><strong>Improves CPU throughput</strong></li>
</ul>
<p>Summary:</p>
<p><strong>Register renaming</strong> helps CPUs <strong>run more instructions in parallel</strong> by resolving unnecessary register name conflicts, boosting performance.</p>
<hr>
<h3 id="Sign-Magnitude-Representation-原码"><a href="#Sign-Magnitude-Representation-原码" class="headerlink" title="Sign-Magnitude Representation (原码)"></a>Sign-Magnitude Representation (原码)</h3><p><strong>Sign-Magnitude Representation (原码)</strong> is a binary method for representing signed integers.</p>
<ul>
<li><strong>Sign bit</strong>: The most significant bit indicates the sign — <code>0</code> for positive, <code>1</code> for negative.</li>
<li><strong>Magnitude bits</strong>: The remaining bits represent the absolute value of the number in binary.</li>
</ul>
<p><strong>Example (using 8 bits):</strong></p>
<ul>
<li><code>+5</code> in sign-magnitude: <code>00000101</code></li>
<li><code>-5</code> in sign-magnitude: <code>10000101</code></li>
</ul>
<p><strong>Features:</strong></p>
<ul>
<li>Symmetrical representation for positive and negative numbers</li>
<li>Has <strong>two representations of zero</strong>: <code>00000000</code> (+0) and <code>10000000</code> (−0)</li>
</ul>
<p>Since arithmetic operations with sign-magnitude require handling the sign separately, it is less efficient in hardware compared to two’s complement.</p>
<hr>
<h3 id="One’s-Complement-反码"><a href="#One’s-Complement-反码" class="headerlink" title="One’s Complement (反码)"></a><strong>One’s Complement (反码)</strong></h3><p><strong>One’s Complement (反码)</strong> is a binary method for representing signed integers.</p>
<ul>
<li><strong>Positive numbers</strong>: Same as in regular binary.</li>
<li><strong>Negative numbers</strong>: Invert all bits of the positive number (i.e., change 0 to 1 and 1 to 0).</li>
</ul>
<p><strong>Example (using 8 bits):</strong></p>
<ul>
<li><code>+5</code>: <code>00000101</code></li>
<li><code>-5</code>: <code>11111010</code> (one’s complement of <code>00000101</code>)</li>
</ul>
<p><strong>Features:</strong></p>
<ul>
<li>Two representations of zero: <code>00000000</code> (+0) and <code>11111111</code> (−0)</li>
<li>Subtraction can be done using addition, but still needs end-around carry handling.</li>
</ul>
<p>Less efficient than two’s complement for arithmetic operations.</p>
<hr>
<h3 id="Two’s-Complement-补码"><a href="#Two’s-Complement-补码" class="headerlink" title="Two’s Complement (补码)"></a>Two’s Complement (补码)</h3><p><strong>Two’s Complement (补码)</strong> is the most common binary method for representing signed integers.</p>
<ul>
<li><strong>Positive numbers</strong>: Same as regular binary.</li>
<li><strong>Negative numbers</strong>: Invert all bits of the positive number (get the one’s complement), then add 1.</li>
</ul>
<p><strong>Example (using 8 bits):</strong></p>
<ul>
<li><code>+5</code>: <code>00000101</code></li>
<li><code>-5</code>: <code>11111011</code> (one’s complement of <code>00000101</code> is <code>11111010</code>, plus 1 gives <code>11111011</code>)</li>
</ul>
<p><strong>Features:</strong></p>
<ul>
<li>Only <strong>one zero</strong>: <code>00000000</code></li>
<li>Arithmetic operations (addition and subtraction) are simple and efficient</li>
<li>Widely used in modern computers for signed integer representation</li>
</ul>
<hr>
<h3 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h3><p><strong>Benchmark</strong> refers to a <strong>standardized test or reference</strong> used to evaluate the performance or quality of a system, device, program, or product.</p>
<p>A <strong>benchmark</strong> is a method of assessing the performance of an object by running a set of standard tests and comparing the results to others. It helps measure efficiency and identify areas for improvement.</p>
<p><strong>Common Use Cases</strong></p>
<ol>
<li><p><strong>Computer Hardware:</strong></p>
<ul>
<li>Benchmarking CPUs, GPUs, SSDs, etc., by running performance tests and comparing scores.</li>
<li>Common tools: Cinebench, Geekbench, PCMark.</li>
</ul>
</li>
<li><p><strong>Software Development:</strong></p>
<ul>
<li>Measuring the speed or efficiency of code or algorithms to optimize performance.</li>
</ul>
</li>
<li><p><strong>Business Management:</strong></p>
<ul>
<li>Comparing business performance to industry best practices to find room for improvement.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="Big-endian"><a href="#Big-endian" class="headerlink" title="Big-endian"></a>Big-endian</h3><p><strong>Big-endian</strong> is a type of <strong>byte order</strong> where the <strong>most significant byte (MSB)</strong> is stored at the <strong>lowest memory address</strong>, and the least significant byte is stored at the highest address.</p>
<p>Suppose we have a 32-bit hexadecimal number: <code>0x12345678</code></p>
<p>In <strong>Big-endian</strong> format, it would be stored in memory like this (from low to high address):</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Address</th>
<th>Byte Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>0x00</td>
<td>0x12</td>
</tr>
<tr>
<td>0x01</td>
<td>0x34</td>
</tr>
<tr>
<td>0x02</td>
<td>0x56</td>
</tr>
<tr>
<td>0x03</td>
<td>0x78</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Commonly used in <strong>network protocols</strong> (e.g., TCP/IP), hence also known as <strong>network byte order</strong>.</li>
<li>The opposite of Big-endian is <strong>Little-endian</strong>, where the least significant byte comes first.</li>
</ul>
<hr>
<h3 id="Little-endian-Brief-Explanation"><a href="#Little-endian-Brief-Explanation" class="headerlink" title="Little-endian (Brief Explanation)"></a>Little-endian (Brief Explanation)</h3><p><strong>Little-endian</strong> is a type of <strong>byte order</strong> where the <strong>least significant byte (LSB)</strong> is stored at the <strong>lowest memory address</strong>, and the most significant byte is stored at the highest address.</p>
<p>Suppose we have a 32-bit hexadecimal number: <code>0x12345678</code></p>
<p>In <strong>Little-endian</strong> format, it would be stored in memory like this (from low to high address):</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Address</th>
<th>Byte Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>0x00</td>
<td>0x78</td>
</tr>
<tr>
<td>0x01</td>
<td>0x56</td>
</tr>
<tr>
<td>0x02</td>
<td>0x34</td>
</tr>
<tr>
<td>0x03</td>
<td>0x12</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Commonly used in <strong>x86 architecture</strong> (Intel and AMD CPUs).</li>
<li>It is the <strong>opposite of Big-endian</strong>, which stores the most significant byte first.</li>
<li>Easier for some CPUs to handle arithmetic operations on varying byte lengths.</li>
</ul>
<hr>
<h3 id="Temporal-Locality-时间局部性"><a href="#Temporal-Locality-时间局部性" class="headerlink" title="Temporal Locality (时间局部性)"></a>Temporal Locality (时间局部性)</h3><p><strong>Temporal locality</strong> is a common program behavior in computer systems that means:</p>
<blockquote>
<p><strong>“If a data item is accessed, it is likely to be accessed again in the near future.”</strong></p>
</blockquote>
<p>Consider the following code snippet:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    sum <span class="token operator">+=</span> array<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure>
<ul>
<li>When <code>array[0]</code> is accessed, the program will soon access <code>array[1]</code>, <code>array[2]</code>, etc.</li>
<li>The variable <code>sum</code> is also accessed repeatedly.</li>
<li>This demonstrates <strong>temporal locality</strong>.</li>
</ul>
<p><strong>Additional Notes:</strong></p>
<ul>
<li><strong>Caches</strong> take advantage of temporal locality to improve performance.</li>
<li><p>Temporal locality commonly appears in:</p>
<ul>
<li>Loop variables</li>
<li>Frequently called functions</li>
<li>Intermediate computation results</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Spatial-Locality-空间局部性"><a href="#Spatial-Locality-空间局部性" class="headerlink" title="Spatial Locality (空间局部性)"></a>Spatial Locality (空间局部性)</h3><p><strong>Spatial locality</strong> is a common program behavior in computer systems that means:</p>
<blockquote>
<p><strong>“If a data item is accessed, nearby data items (in memory) are likely to be accessed soon.”</strong></p>
</blockquote>
<p>Consider the following code snippet:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    sum <span class="token operator">+=</span> array<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure>
<ul>
<li>When <code>array[0]</code> is accessed, the program will likely access <code>array[1]</code>, <code>array[2]</code>, …, <code>array[99]</code> shortly after.</li>
<li>These elements are stored in <strong>adjacent memory locations</strong>, so this illustrates <strong>spatial locality</strong>.</li>
</ul>
<p><strong>Additional Notes:</strong></p>
<ul>
<li><strong>Caches</strong> use spatial locality by loading not just a single data item but also <strong>nearby memory blocks</strong> (called a cache line).</li>
<li><p>Spatial locality commonly appears in:</p>
<ul>
<li>Sequential array access</li>
<li>Traversal of linked lists or other data structures with contiguous memory</li>
<li>Instruction fetches during linear code execution</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Hardware-Prefetching-a-k-a-Prefetch"><a href="#Hardware-Prefetching-a-k-a-Prefetch" class="headerlink" title="Hardware Prefetching (a.k.a. Prefetch)"></a>Hardware Prefetching (a.k.a. Prefetch)</h3><p><strong>Hardware Prefetching</strong> is a technique where the CPU automatically predicts and loads data into the cache <strong>before</strong> it is actually needed.<br>It helps reduce memory latency by exploiting <strong>spatial</strong> and <strong>temporal locality</strong>.<br>For example, if a program accesses memory sequentially, the hardware may prefetch the next few addresses.<br>Prefetched data is stored in the cache, making future access faster.<br>This improves overall CPU performance, especially in data-intensive workloads.</p>
<hr>
<h3 id="Write-Through（写直达）"><a href="#Write-Through（写直达）" class="headerlink" title="Write Through（写直达）"></a>Write Through（写直达）</h3><p><strong>Write Through</strong> is a <strong>cache writing policy</strong> used in computer architecture to manage how data is written to the memory hierarchy, specifically between the <strong>cache</strong> and <strong>main memory</strong>.</p>
<p><strong>🔧 Definition:</strong><br>In a <strong>Write Through</strong> policy, <strong>every write operation</strong> to the cache is <strong>immediately and simultaneously written to main memory</strong>. This ensures that the main memory always holds the most up-to-date data.</p>
<p><strong>✅ Advantages:</strong></p>
<ul>
<li><strong>Data consistency</strong>: Main memory always reflects the latest data written by the CPU.</li>
<li><strong>Simple to implement</strong>: Because memory and cache are always in sync, it simplifies memory coherence in multi-processor systems.</li>
</ul>
<p><strong>❌ Disadvantages:</strong></p>
<ul>
<li><strong>Slower write performance</strong>: Every write operation must access main memory, which is slower than just writing to cache.</li>
<li><strong>Higher memory traffic</strong>: Frequent memory writes can increase bus usage and reduce overall system performance.</li>
</ul>
<p><strong>🧠 Example:</strong><br>If a CPU writes value <code>42</code> to memory address <code>0xA0</code>:</p>
<ul>
<li>The value is written to <strong>L1 cache</strong>.</li>
<li>At the same time, the value is also written to <strong>main memory</strong>.</li>
</ul>
<p><strong>💡 Related Concept:</strong></p>
<ul>
<li>Compare with <strong>Write Back</strong> policy, where updates are only made to the cache and written to memory <strong>later</strong>, often when the cache block is replaced.</li>
</ul>
<p><strong>Summary:</strong><br>Write Through provides <strong>strong consistency</strong> between cache and memory at the cost of <strong>write speed and efficiency</strong>.</p>
<hr>
<h3 id="Write-Back（写回）"><a href="#Write-Back（写回）" class="headerlink" title="Write Back（写回）"></a>Write Back（写回）</h3><p><strong>Write Back</strong> is a <strong>cache writing policy</strong> used in computer architecture to manage how data is written between the <strong>CPU cache</strong> and <strong>main memory</strong>.</p>
<p><strong>🔧 Definition:</strong><br>In a <strong>Write Back</strong> policy, data is written <strong>only to the cache</strong> at first. The updated data is written to <strong>main memory only when the cache block is replaced</strong> (i.e., evicted). Until then, the main memory may hold stale data.</p>
<p><strong>✅ Advantages:</strong></p>
<ul>
<li><strong>Faster write performance</strong>: Since writes are done only in cache, it reduces the latency of write operations.</li>
<li><strong>Reduced memory traffic</strong>: Multiple writes to the same memory location are performed only once to main memory when the block is evicted.</li>
</ul>
<p><strong>❌ Disadvantages:</strong></p>
<ul>
<li><strong>Data inconsistency risk</strong>: Main memory may not reflect the latest data, which complicates memory coherence in multi-core systems.</li>
<li><strong>More complex control logic</strong>: Needs a <strong>dirty bit</strong> to track whether a cache block has been modified.</li>
</ul>
<p><strong>🧠 Example:</strong><br>If the CPU writes value <code>42</code> to memory address <code>0xA0</code>:</p>
<ul>
<li>The value is written <strong>only to the cache</strong> (marked as dirty).</li>
<li>When the cache block containing <code>0xA0</code> is later evicted, <strong>then</strong> the value is written to <strong>main memory</strong>.</li>
</ul>
<p><strong>💡 Related Concept:</strong></p>
<ul>
<li>Compare with <strong>Write Through</strong>, where every write updates both the cache and main memory <strong>simultaneously</strong>.</li>
</ul>
<p><strong>Summary:</strong><br>Write Back improves <strong>write efficiency and performance</strong>, but introduces <strong>complexity and consistency challenges</strong>.</p>
<p><img src="/img/concepts/wb.svg" srcset="/img/loading.gif" lazyload alt="Write Back VS Write Through" style="max-width: 100%; height: auto;" /></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>特性</th>
<th>写回（Write Back）</th>
<th>写直达（Write Through）</th>
</tr>
</thead>
<tbody>
<tr>
<td>写入位置</td>
<td>只写缓存（先缓存，后主存）</td>
<td>同时写入缓存和主存</td>
</tr>
<tr>
<td>写入主存时机</td>
<td>缓存块被替换时才写回主存</td>
<td>每次写操作都立即写入主存</td>
</tr>
<tr>
<td>性能</td>
<td>高性能，减少主存访问，延迟更低</td>
<td>写入慢，因频繁访问主存</td>
</tr>
<tr>
<td>主存数据一致性</td>
<td>复杂，需要使用“脏位”等一致性机制管理</td>
<td>简单，主存总是最新数据</td>
</tr>
<tr>
<td>系统总线负载</td>
<td>较低，减少写操作带来的总线流量</td>
<td>较高，写操作总是同步主存，增加总线压力</td>
</tr>
<tr>
<td>缓存一致性维护</td>
<td>较困难，多核系统中需额外一致性协议支持</td>
<td>较简单，主存作为权威数据源</td>
</tr>
<tr>
<td>适用场景</td>
<td>写操作频繁、对性能要求高的系统</td>
<td>对一致性要求高、系统结构简单的场景</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="Multicache-Multi-level-Cache"><a href="#Multicache-Multi-level-Cache" class="headerlink" title="Multicache (Multi-level Cache)"></a>Multicache (Multi-level Cache)</h3><p><strong>Multicache</strong>, or <strong>Multi-level Cache</strong>, refers to a hierarchical(分层的) caching system used in modern CPUs to bridge the speed gap between the fast processor and the slower main memory. It typically consists of <strong>multiple levels of cache</strong>, such as <strong>L1</strong>, <strong>L2</strong>, and <strong>L3</strong>, each with different sizes, speeds, and purposes.</p>
<p><strong>🔧 Definition:</strong> A <strong>multi-level cache</strong> system includes:</p>
<ul>
<li><strong>L1 Cache</strong>: Closest to the CPU core, smallest and fastest.</li>
<li><strong>L2 Cache</strong>: Larger than L1, slower, and may be shared or private per core.</li>
<li><strong>L3 Cache</strong>: Even larger and slower, typically shared across all CPU cores.</li>
</ul>
<p>This layered structure allows faster access to frequently used data while reducing latency and improving CPU efficiency.</p>
<p><strong>🏗️ Structure Example:</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Level</th>
<th>Size</th>
<th>Speed</th>
<th>Shared</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td>L1</td>
<td>~32KB</td>
<td>Very fast</td>
<td>No</td>
<td>Immediate access for the CPU</td>
</tr>
<tr>
<td>L2</td>
<td>~256KB</td>
<td>Fast</td>
<td>Maybe</td>
<td>Secondary buffer</td>
</tr>
<tr>
<td>L3</td>
<td>~8MB</td>
<td>Slower</td>
<td>Yes</td>
<td>Shared cache for all cores</td>
</tr>
</tbody>
</table>
</div>
<p><strong>✅ Advantages:</strong></p>
<ul>
<li><strong>Improved performance</strong>: Reduces average memory access time.</li>
<li><strong>Lower latency</strong>: L1 and L2 caches are much faster than main memory.</li>
<li><strong>Better scalability</strong>: Helps in multi-core systems where data sharing and access times are critical.</li>
</ul>
<p><strong>❌ Disadvantages:</strong></p>
<ul>
<li><strong>Complex design</strong>: Managing coherence and consistency across multiple levels is challenging.</li>
<li><strong>Increased cost and power</strong>: More hardware and logic are required.</li>
<li><strong>Cache misses</strong>: Still possible, especially if working sets exceed cache sizes.</li>
</ul>
<p><strong>💡 Notes:</strong></p>
<ul>
<li>Most modern processors use <strong>inclusive（包容）</strong>, <strong>exclusive（排他）</strong>, or <strong>non-inclusive（非包容）</strong> cache strategies to determine how data is stored across cache levels.</li>
<li>Multi-level cache systems often work in tandem with <strong>cache coherence protocols</strong> like MESI in multi-core CPUs.</li>
</ul>
<p><strong>📌 Summary</strong></p>
<p><strong>Multicache systems</strong> provide a hierarchical buffer between the CPU and main memory, optimizing performance and efficiency by leveraging fast, small caches for frequently accessed data and larger, slower caches for broader access.</p>
<p><img src="/img/concepts/multicache.svg" srcset="/img/loading.gif" lazyload alt="multicache" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Direct-Mapping（直接映射）"><a href="#Direct-Mapping（直接映射）" class="headerlink" title="Direct Mapping（直接映射）"></a>Direct Mapping（直接映射）</h3><p><strong>Direct Mapping</strong> is a simple cache mapping technique used in computer architecture to determine where a memory block will be placed in the cache.</p>
<p><strong>🔧 Definition:</strong><br>In <strong>Direct Mapping</strong>, each block of main memory maps to <strong>exactly one</strong> cache line. The mapping is usually done using:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Cache Line Index &#x3D; (Main Memory Block Address) mod (Number of Cache Lines)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>This makes it easy and fast to locate data in the cache, but can lead to many <strong>conflicts</strong> if multiple blocks map to the same cache line.</p>
<p><strong>✅ Advantages:</strong></p>
<ul>
<li><strong>Simple and fast</strong> implementation</li>
<li><strong>Low hardware complexity</strong></li>
</ul>
<p><strong>❌ Disadvantages:</strong></p>
<ul>
<li><strong>High conflict rate</strong>: Two different memory blocks mapping to the same line will continuously evict each other</li>
<li><strong>Low flexibility</strong> compared to other mapping techniques (e.g., set-associative)</li>
</ul>
<p><strong>🧠 Example:</strong><br>If a cache has 8 lines (0 to 7), and a block from main memory has address 24:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Cache Line &#x3D; 24 mod 8 &#x3D; 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>So this block will always be placed in cache line 0.</p>
<p><strong>Summary:</strong><br>Direct Mapping provides fast and simple cache access, but is prone to frequent conflicts.</p>
<hr>
<h3 id="Set-Associative-Mapping（组相连映射）"><a href="#Set-Associative-Mapping（组相连映射）" class="headerlink" title="Set- Associative Mapping（组相连映射）"></a>Set- Associative Mapping（组相连映射）</h3><p><strong>Set-Associative Mapping</strong> is a cache mapping technique that combines the benefits of both <strong>Direct Mapping</strong> and <strong>Fully Associative Mapping</strong> to balance performance and complexity.</p>
<p><strong>🔧 Definition:</strong><br>In <strong>Set-Associative Mapping</strong>, the cache is divided into multiple <strong>sets</strong>, and each set contains <strong>multiple cache lines (ways)</strong>. A block from main memory maps to <strong>exactly one set</strong>, but <strong>can be placed in any line (way) within that set</strong>.</p>
<p>The set is selected using:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Set Index &#x3D; (Main Memory Block Address) mod (Number of Sets)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Within the set, placement and replacement follow policies like <strong>Least Recently Used (LRU)</strong> or <strong>Random</strong>.</p>
<p><strong>✅ Advantages:</strong></p>
<ul>
<li><strong>Lower conflict rate</strong> than Direct Mapping</li>
<li><strong>More flexible</strong> placement within sets</li>
<li><strong>Good balance</strong> between speed and cache hit rate</li>
</ul>
<p><strong>❌ Disadvantages:</strong></p>
<ul>
<li><strong>More complex</strong> hardware than Direct Mapping</li>
<li><strong>Slightly slower</strong> lookup due to checking multiple lines in a set</li>
</ul>
<p><strong>🧠 Example:</strong><br>If a cache has <strong>4 sets</strong>, each with <strong>2 lines (2-way set-associative)</strong>, and a memory block with address 12:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Set Index &#x3D; 12 mod 4 &#x3D; 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>The block can be placed in <strong>either of the 2 lines in Set 0</strong>.</p>
<p><strong>Summary:</strong><br>Set-Associative Mapping provides a <strong>balanced approach</strong> with better conflict resolution than Direct Mapping and <strong>less complexity</strong> than Fully Associative Mapping.</p>
<hr>
<h3 id="Full-Associative-Mapping（全相联映射）"><a href="#Full-Associative-Mapping（全相联映射）" class="headerlink" title="Full Associative Mapping（全相联映射）"></a>Full Associative Mapping（全相联映射）</h3><p><strong>Full Associative Mapping</strong> is a cache mapping technique in which <strong>a memory block can be placed in any cache line</strong>, offering maximum flexibility and minimal conflict.</p>
<p><strong>🔧 Definition:</strong><br>In <strong>Full Associative Mapping</strong>, there are <strong>no restrictions</strong> on where a block can be placed in the cache. Any block from main memory can be stored in <strong>any cache line</strong>.</p>
<p>To find a block, the cache must <strong>search all lines</strong> using <strong>comparators</strong> that match tags.</p>
<p><strong>✅ Advantages:</strong></p>
<ul>
<li><strong>No conflict misses</strong> (except when cache is full)</li>
<li><strong>Best flexibility</strong> in placement</li>
<li><strong>Highest cache hit potential</strong></li>
</ul>
<p><strong>❌ Disadvantages:</strong></p>
<ul>
<li><strong>Complex hardware</strong>: Requires searching the entire cache in parallel</li>
<li><strong>Slower access time</strong> due to tag comparisons</li>
<li><strong>Expensive</strong> in terms of power and chip area</li>
</ul>
<p><strong>🧠 Example:</strong><br>If a cache has <strong>8 lines</strong>, and a block from memory has address <code>0x2F</code>, it can be placed in <strong>any one</strong> of the 8 lines. When checking for a hit, the cache must compare the block’s tag with the tags of <strong>all 8 lines</strong>.</p>
<p><strong>Summary:</strong><br>Full Associative Mapping provides <strong>maximum flexibility</strong> and <strong>minimal conflict</strong>, but comes with <strong>higher hardware cost</strong> and <strong>slower lookup times</strong>.</p>
<hr>
<h3 id="Comparison-of-Cache-Mapping-Techniques"><a href="#Comparison-of-Cache-Mapping-Techniques" class="headerlink" title="Comparison of Cache Mapping Techniques"></a>Comparison of Cache Mapping Techniques</h3><div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Direct Mapping</th>
<th>Set-Associative Mapping</th>
<th>Full Associative Mapping</th>
</tr>
</thead>
<tbody>
<tr>
<td>Placement Rule</td>
<td>Each block maps to <strong>one line</strong></td>
<td>Each block maps to <strong>one set</strong>, can go into <strong>any line</strong> in that set</td>
<td>Each block can go into <strong>any line</strong> in the cache</td>
</tr>
<tr>
<td>Flexibility</td>
<td>Low</td>
<td>Medium</td>
<td>High</td>
</tr>
<tr>
<td>Hardware Complexity</td>
<td>Low (simplest)</td>
<td>Medium</td>
<td>High (most complex)</td>
</tr>
<tr>
<td>Access Speed</td>
<td>Fast</td>
<td>Slightly slower</td>
<td>Slowest (due to parallel comparisons)</td>
</tr>
<tr>
<td>Conflict Misses</td>
<td>High</td>
<td>Lower than Direct Mapping</td>
<td>None (except capacity misses)</td>
</tr>
<tr>
<td>Replacement Policy</td>
<td>Not needed (only one line)</td>
<td>Needed within each set (e.g., LRU)</td>
<td>Needed for the entire cache (e.g., LRU)</td>
</tr>
<tr>
<td>Cost (Power/Area)</td>
<td>Low</td>
<td>Moderate</td>
<td>High</td>
</tr>
<tr>
<td>Use Case Suitability</td>
<td>Simple, low-power systems</td>
<td>General-purpose CPUs</td>
<td>High-performance or critical systems</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/img/concepts/cache3.jpg" srcset="/img/loading.gif" lazyload alt="三种cache映射" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h3><p><strong>Cache</strong> is a small, high-speed memory that stores frequently used data to speed up access. It sits between the CPU and main memory to reduce latency. It enables fast program access to frequently used addresses.</p>
<hr>
<h3 id="Non-blocking-Cache（非阻塞缓存）"><a href="#Non-blocking-Cache（非阻塞缓存）" class="headerlink" title="Non-blocking Cache（非阻塞缓存）"></a>Non-blocking Cache（非阻塞缓存）</h3><p>A <strong>Non-blocking Cache</strong> allows the CPU to continue processing other instructions <strong>while waiting for a cache miss</strong> to be resolved.<br>It supports <strong>multiple outstanding memory requests</strong> simultaneously.<br>This improves overall system performance by reducing CPU idle time.<br>Non-blocking caches are especially useful in <strong>out-of-order execution</strong> and <strong>superscalar processors</strong>.<br>They often use structures like <strong>Miss Status Handling Registers (MSHRs)</strong> to track pending requests.</p>
<p><strong>非阻塞缓存</strong>允许 CPU 在<strong>等待缓存未命中（Cache Miss）处理完成的同时继续执行其他指令</strong>。<br>它支持<strong>多个未完成的内存请求</strong>同时存在。<br>这通过减少 CPU 空闲时间来提升系统整体性能。<br>非阻塞缓存在<strong>乱序执行</strong>和<strong>超标量处理器</strong>中尤为重要。<br>它通常使用如 <strong>未命中状态处理寄存器（Miss Status Handling Registers, MSHRs）</strong> 的结构来追踪未完成的请求。</p>
<hr>
<h3 id="Superscalar-Architecture（超标量架构）"><a href="#Superscalar-Architecture（超标量架构）" class="headerlink" title="Superscalar Architecture（超标量架构）"></a>Superscalar Architecture（超标量架构）</h3><p><strong>Superscalar Architecture</strong> is a CPU design that allows the processor to <strong>fetch, decode, and execute multiple instructions simultaneously</strong> during each clock cycle.<br>It achieves this by using <strong>multiple pipelines</strong> and <strong>parallel execution units</strong> (e.g., ALUs, FPUs).<br>This architecture increases <strong>instruction-level parallelism (ILP)</strong>, boosting performance without raising the clock speed.<br>Superscalar CPUs include features like <strong>out-of-order execution</strong>, <strong>register renaming</strong>, and <strong>branch prediction</strong> to handle dependencies and control flow efficiently.<br>Examples of superscalar processors include modern Intel and AMD CPUs.</p>
<p><img src="/img/concepts/superscalar.svg" srcset="/img/loading.gif" lazyload alt="超标量架构" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="🔍-TLB-Translation-Lookaside-Buffer"><a href="#🔍-TLB-Translation-Lookaside-Buffer" class="headerlink" title="🔍 TLB (Translation Lookaside Buffer)"></a>🔍 TLB (Translation Lookaside Buffer)</h3><p><strong>TLB</strong> stands for <strong>Translation Lookaside Buffer</strong>. It is a small, fast cache used in the memory management unit (MMU) of a computer’s CPU to improve the speed of <strong>virtual-to-physical address translation</strong>.</p>
<p><strong>📌 Why is TLB needed?</strong></p>
<p>When a CPU accesses memory using a virtual address, it must be translated into a physical address using the <strong>page table</strong>. This translation is time-consuming. The TLB stores recent translations, so if the virtual address has been accessed recently, the translation can be retrieved quickly without accessing the full page table.</p>
<p><strong>✅ Key Characteristics</strong></p>
<ul>
<li><strong>Cache for page table entries</strong></li>
<li><strong>Reduces page table access time</strong></li>
<li>Typically contains <strong>64 to 512 entries</strong></li>
<li>Can be <strong>fully associative</strong>, <strong>set-associative</strong>, or <strong>direct-mapped</strong></li>
</ul>
<p><strong>📈 How it works</strong></p>
<ol>
<li><strong>CPU generates a virtual address</strong></li>
<li><strong>MMU checks the TLB</strong> for the virtual page number (VPN)</li>
<li>If found (<strong>TLB hit</strong>): use the cached physical page number (PPN)</li>
<li>If not found (<strong>TLB miss</strong>): access the page table, then update the TLB</li>
</ol>
<p><strong>🧠 TLB Hit vs TLB Miss</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Event</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>TLB Hit</td>
<td>The virtual address is found in the TLB → Fast address translation</td>
</tr>
<tr>
<td>TLB Miss</td>
<td>The virtual address is not found in the TLB → Page table lookup is required</td>
</tr>
</tbody>
</table>
</div>
<p><strong>🧮 Example</strong></p>
<p>Let’s say the CPU wants to access virtual address <code>0x00403ABC</code>:</p>
<ul>
<li>VPN = top bits of address → check if TLB has entry</li>
<li>If yes → get PPN and combine with offset → access physical memory</li>
<li>If no → consult page table → update TLB → then access memory</li>
</ul>
<p><strong>🔄 TLB Replacement Policy</strong></p>
<p>When the TLB is full, and a new entry must be loaded, a <strong>replacement policy</strong> is used, such as:</p>
<ul>
<li><strong>Least Recently Used (LRU)</strong></li>
<li><strong>Random replacement</strong></li>
</ul>
<p><strong>🚀 Summary</strong> </p>
<ul>
<li>TLB significantly <strong>improves performance</strong> of memory access.</li>
<li>Acts as a <strong>fast cache</strong> for recent address translations.</li>
<li>Helps bridge the speed gap between the CPU and memory systems.</li>
</ul>
<hr>
<h3 id="Page-Table"><a href="#Page-Table" class="headerlink" title="Page Table"></a>Page Table</h3><p>In computer architecture, a <strong>Page Table</strong> is a data structure used by the <strong>virtual memory system</strong> to manage the mapping between <strong>virtual addresses</strong> and <strong>physical addresses</strong>.</p>
<p><strong>🧠 What is Virtual Memory?</strong></p>
<p>Virtual memory allows a program to use a large, continuous address space even if the physical memory (RAM) is smaller. The CPU generates <strong>virtual addresses</strong>, which must be translated into <strong>physical addresses</strong> before accessing actual memory.</p>
<p><strong>📘 What is a Page Table?</strong></p>
<p>A <strong>Page Table</strong> stores the mapping between <strong>virtual pages</strong> and <strong>physical frames</strong>. Each entry in the page table is called a <strong>Page Table Entry (PTE)</strong> and contains information such as:</p>
<ul>
<li><strong>Frame Number</strong>: the physical frame corresponding to the virtual page.</li>
<li><strong>Valid/Invalid Bit</strong>: indicates if the mapping is valid.</li>
<li><strong>Protection Bits</strong>: control read/write permissions.</li>
<li><strong>Dirty Bit</strong>: indicates if the page has been modified.</li>
<li><strong>Accessed Bit</strong>: indicates if the page has been accessed recently.</li>
</ul>
<p><strong>🧾 Example Structure</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Virtual Page Number</th>
<th>Physical Frame Number</th>
<th>Valid Bit</th>
<th>Protection</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>5</td>
<td>1</td>
<td>Read/Write</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>1</td>
<td>Read-only</td>
</tr>
<tr>
<td>2</td>
<td>-</td>
<td>0</td>
<td>-</td>
</tr>
</tbody>
</table>
</div>
<p><strong>🧮 Address Translation Steps</strong></p>
<ol>
<li>The CPU generates a <strong>virtual address</strong>.</li>
<li><p>The virtual address is divided into:</p>
<ul>
<li><strong>Page Number</strong></li>
<li><strong>Offset</strong></li>
</ul>
</li>
<li>The <strong>Page Number</strong> is used to index into the Page Table.</li>
<li>The Page Table Entry provides the <strong>Frame Number</strong>.</li>
<li>The <strong>Physical Address</strong> is formed by combining the Frame Number and the Offset.</li>
</ol>
<p><strong>🛑 Page Fault</strong></p>
<p>If the <strong>Valid Bit</strong> is 0, the page is not currently in memory. This triggers a <strong>Page Fault</strong>, and the operating system must load the page from disk into RAM.</p>
<p><strong>🧭 Types of Page Tables</strong></p>
<ul>
<li><strong>Single-Level Page Table</strong>: Simple but not scalable for large address spaces.</li>
<li><strong>Multi-Level Page Table</strong>: Reduces memory usage by using a tree-like structure.</li>
<li><strong>Inverted Page Table</strong>: Indexes by physical frame instead of virtual page.</li>
<li><strong>Hashed Page Table</strong>: Used in systems with large address spaces (like 64-bit).</li>
</ul>
<p><strong>📌 Summary</strong></p>
<ul>
<li>Page Tables are essential for translating virtual to physical addresses.</li>
<li>They enable <strong>memory protection</strong>, <strong>process isolation</strong>, and <strong>efficient memory use</strong>.</li>
<li>Optimized with techniques like <strong>TLB</strong> (Translation Lookaside Buffer) to speed up address translation.</li>
</ul>
<p><img src="/img/concepts/tlb.svg" srcset="/img/loading.gif" lazyload alt="虚实地址转换" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="🧩-3-Types-of-Cache-Misses"><a href="#🧩-3-Types-of-Cache-Misses" class="headerlink" title="🧩 3 Types of Cache Misses"></a>🧩 3 Types of Cache Misses</h3><p>In computer architecture, a <strong>cache miss</strong> occurs when the data requested by the CPU is <strong>not found in the cache</strong>, requiring access to a slower memory level (like RAM). There are <strong>three main types</strong> of cache misses:</p>
<p><strong>🧠 Summary Table</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>Cause</th>
<th>Possible Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Compulsory Miss</td>
<td>First-time access to a block</td>
<td>Prefetching, larger block size</td>
</tr>
<tr>
<td>Capacity Miss</td>
<td>Cache too small for working set</td>
<td>Larger cache, better algorithms</td>
</tr>
<tr>
<td>Conflict Miss</td>
<td>Blocks map to the same cache location</td>
<td>Higher associativity, alignment</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="1-Compulsory-Miss-a-k-a-Cold-Miss"><a href="#1-Compulsory-Miss-a-k-a-Cold-Miss" class="headerlink" title="1. Compulsory Miss (a.k.a. Cold Miss)"></a>1. <strong>Compulsory Miss</strong> (a.k.a. Cold Miss)</h3><p><strong>🔹 What is it?</strong></p>
<p>Occurs the <strong>first time</strong> a block is accessed and <strong>has never been loaded into the cache</strong> before.</p>
<p><strong>🧠 Cause:</strong></p>
<ul>
<li>Cache is empty or data is accessed for the first time.</li>
</ul>
<p><strong>📌 Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Accessing array A[0] for the first time → not in cache → compulsory miss<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p><strong>✅ Solution:</strong></p>
<ul>
<li>Prefetching</li>
<li>Larger block size (to bring in more adjacent data)</li>
</ul>
<hr>
<h3 id="2-Capacity-Miss"><a href="#2-Capacity-Miss" class="headerlink" title="2. Capacity Miss"></a>2. <strong>Capacity Miss</strong></h3><p><strong>🔹 What is it?</strong></p>
<p>Happens when the <strong>cache cannot contain all the needed data</strong>, and a previously loaded block gets evicted due to <strong>limited size</strong>.</p>
<p><strong>🧠 Cause:</strong></p>
<ul>
<li>The working set is <strong>larger than the cache</strong>.</li>
</ul>
<p><strong>📌 Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Looping through a large dataset that exceeds cache size → older blocks are evicted → miss<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p><strong>✅ Solution:</strong></p>
<ul>
<li>Increase cache size</li>
<li>Optimize algorithm locality</li>
</ul>
<hr>
<h3 id="3-Conflict-Miss-a-k-a-Collision-Miss"><a href="#3-Conflict-Miss-a-k-a-Collision-Miss" class="headerlink" title="3. Conflict Miss (a.k.a. Collision Miss)"></a><strong>3. Conflict Miss</strong> (a.k.a. Collision Miss)</h3><p><strong>🔹 What is it?</strong></p>
<p>Occurs when <strong>multiple blocks map to the same cache line</strong> (in set-associative or direct-mapped caches), causing <strong>unnecessary evictions</strong>.</p>
<p><strong>🧠 Cause:</strong></p>
<ul>
<li>Limited associativity in the cache</li>
<li>Poor address mapping</li>
</ul>
<p><strong>📌 Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Accessing addresses A and B that both map to cache set 3 → one evicts the other → conflict miss<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p><strong>✅ Solution:</strong></p>
<ul>
<li>Increase associativity</li>
<li>Use fully associative cache</li>
<li>Better hash functions or memory alignment</li>
</ul>
<hr>
<h3 id="🔗-Four-Types-of-Data-Dependencies-in-Computer-Architecture"><a href="#🔗-Four-Types-of-Data-Dependencies-in-Computer-Architecture" class="headerlink" title="🔗 Four Types of Data Dependencies in Computer Architecture"></a>🔗 Four Types of Data Dependencies in Computer Architecture</h3><p>In pipelined processors, <strong>data dependencies</strong> occur when instructions depend on the results of previous instructions. These dependencies can cause <strong>pipeline hazards</strong> and impact instruction-level parallelism.</p>
<p>There are <strong>four types</strong> of data dependencies:</p>
<p><strong>📊 Summary Table</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>Abbreviation</th>
<th>Cause</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Flow Dependency</td>
<td>RAW</td>
<td>Read after write</td>
<td>Forwarding, Stall</td>
</tr>
<tr>
<td>Anti Dependency</td>
<td>WAR</td>
<td>Write after read</td>
<td>Register renaming</td>
</tr>
<tr>
<td>Output Dependency</td>
<td>WAW</td>
<td>Write after write</td>
<td>Register renaming, in-order commit</td>
</tr>
<tr>
<td>Control Dependency</td>
<td>–</td>
<td>Depends on branch outcome</td>
<td>Branch prediction, speculation</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="1-Flow-Dependency-Read-After-Write-RAW"><a href="#1-Flow-Dependency-Read-After-Write-RAW" class="headerlink" title="1. Flow Dependency (Read After Write, RAW)"></a>1. <strong>Flow Dependency</strong> (Read After Write, <strong>RAW</strong>)</h3><p><strong>🔹 What is it?</strong></p>
<p>Occurs when an instruction needs to <strong>read a value</strong> that has not yet been <strong>written</strong> by a previous instruction.</p>
<p><strong>🧠 Cause:</strong></p>
<ul>
<li>The second instruction <strong>depends</strong> on the result of the first.</li>
</ul>
<p><strong>📌 Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">I1: R1 ← R2 + R3
I2: R4 ← R1 + R5   ; RAW: I2 reads R1 before I1 writes it<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>✅ Solution:</strong></p>
<ul>
<li><strong>Forwarding/Bypassing</strong></li>
<li><strong>Stalling</strong> the pipeline</li>
</ul>
<hr>
<h3 id="2-Anti-Dependency-Write-After-Read-WAR"><a href="#2-Anti-Dependency-Write-After-Read-WAR" class="headerlink" title="2. Anti Dependency (Write After Read, WAR)"></a>2. <strong>Anti Dependency</strong> (Write After Read, <strong>WAR</strong>)</h3><p><strong>🔹 What is it?</strong></p>
<p>Occurs when a later instruction <strong>writes</strong> to a location that a previous instruction still needs to <strong>read</strong> from.</p>
<p><strong>🧠 Cause:</strong></p>
<ul>
<li>The second instruction must <strong>not overwrite</strong> the value too early.</li>
</ul>
<p><strong>📌 Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">I1: R4 ← R1 + R2   ; Reads R1
I2: R1 ← R3 + R5   ; WAR: I2 writes R1 before I1 finishes reading<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>✅ Solution:</strong></p>
<ul>
<li><strong>Register renaming</strong></li>
</ul>
<hr>
<h3 id="3-Output-Dependency-Write-After-Write-WAW"><a href="#3-Output-Dependency-Write-After-Write-WAW" class="headerlink" title="3. Output Dependency (Write After Write, WAW)"></a>3. <strong>Output Dependency</strong> (Write After Write, <strong>WAW</strong>)</h3><p><strong>🔹 What is it?</strong></p>
<p>Occurs when two instructions <strong>write</strong> to the <strong>same destination</strong>, and the final result must reflect the correct write order.</p>
<p><strong>🧠 Cause:</strong></p>
<ul>
<li>Later instruction must not overwrite an earlier write <strong>out of order</strong>.</li>
</ul>
<p><strong>📌 Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">I1: R1 ← R2 + R3
I2: R1 ← R4 + R5   ; WAW: I2 writes R1 before I1 completes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>✅ Solution:</strong></p>
<ul>
<li><strong>Register renaming</strong></li>
<li><strong>In-order commit</strong> in out-of-order execution</li>
</ul>
<hr>
<h3 id="4-Control-Dependency"><a href="#4-Control-Dependency" class="headerlink" title="4. Control Dependency"></a>4. <strong>Control Dependency</strong></h3><p><strong>🔹 What is it?</strong></p>
<p>Occurs when the <strong>execution</strong> of an instruction depends on the <strong>outcome of a branch</strong>.</p>
<p><strong>🧠 Cause:</strong></p>
<ul>
<li>It’s not clear <strong>whether to execute</strong> the instruction until the branch is resolved.</li>
</ul>
<p><strong>📌 Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">I1: if (R1 &#x3D;&#x3D; 0) goto LABEL
I2: R2 ← R3 + R4   ; Control dependent on I1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>✅ Solution:</strong></p>
<ul>
<li><strong>Branch prediction</strong></li>
<li><strong>Speculative execution</strong></li>
</ul>
<hr>
<h3 id="Microprogramming（微程序设计）"><a href="#Microprogramming（微程序设计）" class="headerlink" title="Microprogramming（微程序设计）"></a>Microprogramming（微程序设计）</h3><p><strong>Microprogramming</strong> is a method of implementing a CPU’s control unit using <strong>a sequence of microinstructions</strong> stored in a special memory called <strong>control memory</strong>.<br>Each <strong>microinstruction</strong> specifies low-level operations like setting control signals, reading/writing registers, or ALU actions.<br>It acts as an intermediate layer between machine instructions and hardware control signals.<br>There are two types of control units: <strong>hardwired control</strong> and <strong>microprogrammed control</strong> — the latter is easier to modify and extend.<br>Microprogramming was widely used in classic CISC architectures like IBM System/360.</p>
<hr>
<h3 id="Snoopy-Cache（监听式缓存）"><a href="#Snoopy-Cache（监听式缓存）" class="headerlink" title="Snoopy Cache（监听式缓存）"></a>Snoopy Cache（监听式缓存）</h3><p><strong>Snoopy Cache</strong> is a cache coherence protocol used in <strong>multiprocessor systems</strong> to maintain data consistency among multiple caches.<br>Each cache monitors (or “snoops”) a shared communication bus to detect if other processors are reading or writing a memory block it has cached.<br>If a write is detected, the snooping cache can <strong>invalidate</strong> or <strong>update</strong> its own copy to keep data coherent.<br>This ensures that all processors work with the <strong>most recent version</strong> of data.<br>Common snoopy-based protocols include <strong>MSI</strong>, <strong>MESI</strong>, and <strong>MOESI</strong>.</p>
<p><strong>Snoopy Cache（监听式缓存）</strong>是一种用于<strong>多处理器系统</strong>的缓存一致性协议，用于保持多个缓存之间的数据一致性。<br>每个缓存会监听（snoop）共享总线，检测其他处理器是否在读取或写入它缓存中的数据块。<br>当检测到写操作时，监听缓存会<strong>更新</strong>或<strong>无效化</strong>自己的副本，以保持数据的一致性。<br>这样可以确保所有处理器使用的都是<strong>最新版本的数据</strong>。<br>常见的监听式协议包括 <strong>MSI</strong>、<strong>MESI</strong> 和 <strong>MOESI</strong> 协议。</p>
<hr>
<h3 id="Out-of-order-Execution-乱序执行"><a href="#Out-of-order-Execution-乱序执行" class="headerlink" title="Out-of-order Execution (乱序执行)"></a>Out-of-order Execution (乱序执行)</h3><p><strong>Out-of-order execution</strong> is a technique used in modern processors to improve performance by allowing instructions to be executed <strong>out of the order they appear</strong> in the program.<br>Instead of waiting for earlier instructions to complete (which might be delayed due to data hazards or memory stalls), the CPU executes instructions that are ready and independent of others.<br>This reduces <strong>idle CPU time</strong> and <strong>increases throughput</strong> by utilizing all available execution units.<br>Dependencies between instructions are tracked, and results are committed in the correct order.<br>Out-of-order execution is common in <strong>superscalar processors</strong> and is part of <strong>dynamic instruction scheduling</strong>.</p>
<p><strong>乱序执行</strong>是一种现代处理器中常用的技术，通过允许指令<strong>按非顺序</strong>的方式执行来提升性能。<br>CPU 不必等待前面的指令完成（这些指令可能因为数据依赖或内存延迟而被拖慢），而是执行那些准备好且相互独立的指令。<br>这样可以减少<strong>CPU空闲时间</strong>并<strong>增加吞吐量</strong>，充分利用所有可用的执行单元。<br>指令之间的依赖关系会被追踪，结果会按正确的顺序提交。<br>乱序执行在<strong>超标量处理器</strong>中很常见，并且是<strong>动态指令调度</strong>的一部分。</p>
<hr>
<h3 id="DMA-Direct-Memory-Access"><a href="#DMA-Direct-Memory-Access" class="headerlink" title="DMA (Direct Memory Access)"></a>DMA (Direct Memory Access)</h3><p><strong>DMA</strong> stands for <strong>Direct Memory Access</strong>, a feature that allows certain hardware components (like disk controllers or network cards) to <strong>transfer data directly to/from main memory</strong> without involving the CPU.<br>This improves system efficiency by <strong>freeing the CPU</strong> from managing large or repetitive data transfers.<br>A <strong>DMA controller</strong> handles the data movement and signals the CPU when the transfer is complete.<br>DMA is commonly used for tasks like <strong>disk I/O</strong>, <strong>audio/video streaming</strong>, and <strong>network communication</strong>.<br>It helps achieve <strong>high-speed data transfer</strong> with minimal CPU overhead.</p>
<p><strong>DMA</strong> 是 <strong>直接内存访问（Direct Memory Access）</strong> 的缩写，是一种允许某些硬件组件（如磁盘控制器或网卡）<strong>在不经过 CPU 的情况下直接与主存进行数据传输</strong>的技术。<br>它通过<strong>减轻 CPU 的数据搬运负担</strong>，提高了系统效率。<br>数据传输由一个 <strong>DMA 控制器</strong>负责，传输完成后会通知 CPU。<br>DMA 广泛应用于 <strong>磁盘 I/O</strong>、<strong>音视频流处理</strong> 和 <strong>网络通信</strong> 等领域。<br>它能以<strong>极低的 CPU 开销实现高速数据传输</strong>。</p>
<hr>
<h3 id="RISC-Reduced-Instruction-Set-Computing"><a href="#RISC-Reduced-Instruction-Set-Computing" class="headerlink" title="RISC (Reduced Instruction Set Computing)"></a>RISC (Reduced Instruction Set Computing)</h3><p><strong>RISC</strong> stands for <strong>Reduced Instruction Set Computing</strong>, a CPU design strategy that uses a <strong>small set of simple and fast instructions</strong>.<br>Each instruction typically executes in <strong>one clock cycle</strong>, allowing efficient pipelining and parallelism.<br>RISC emphasizes <strong>hardware simplicity</strong>, <strong>fixed instruction length</strong>, and <strong>a load/store architecture</strong>.<br>It is well-suited for modern compilers and high-performance applications.<br>Examples: <strong>ARM</strong>, <strong>RISC-V</strong>, <strong>MIPS</strong>.</p>
<p><strong>RISC</strong> 是 <strong>精简指令集计算（Reduced Instruction Set Computing）</strong> 的缩写，是一种使用<strong>少量简单指令</strong>的 CPU 设计理念。<br>每条指令通常在<strong>一个时钟周期内完成</strong>，便于实现流水线和并行处理。<br>RISC 强调<strong>硬件简化</strong>、<strong>固定长度指令</strong>以及<strong>Load/Store 架构</strong>。<br>这种架构非常适合现代编译器和高性能应用。<br>代表架构：<strong>ARM</strong>、<strong>RISC-V</strong>、<strong>MIPS</strong>。</p>
<hr>
<h3 id="CISC-Complex-Instruction-Set-Computing"><a href="#CISC-Complex-Instruction-Set-Computing" class="headerlink" title="CISC (Complex Instruction Set Computing)"></a>CISC (Complex Instruction Set Computing)</h3><p><strong>CISC</strong> stands for <strong>Complex Instruction Set Computing</strong>, which uses a <strong>large and versatile set of instructions</strong>, where some instructions perform <strong>multi-step operations</strong>.<br>This design reduces the number of instructions per program but increases the complexity of the CPU.<br>CISC instructions often have <strong>variable lengths</strong> and require <strong>multiple clock cycles</strong> to execute.<br>It was originally designed to minimize memory usage and support simpler compilers.<br>Example: <strong>x86 architecture</strong> (Intel, AMD).</p>
<p><strong>CISC</strong> 是 <strong>复杂指令集计算（Complex Instruction Set Computing）</strong> 的缩写，采用<strong>数量多、功能强的指令集</strong>，其中一些指令能完成<strong>多个低层次操作</strong>。<br>这种设计可以减少程序中所需的指令数量，但会增加 CPU 的实现复杂度。<br>CISC 指令通常是<strong>不固定长度</strong>，并且执行时<strong>可能需要多个时钟周期</strong>。<br>它最初为了减少内存使用、便于早期编译器设计而提出。<br>代表架构：<strong>x86 架构</strong>（如 Intel 和 AMD 处理器）。</p>
<hr>
<h3 id="SIMD-Single-Instruction-Multiple-Data"><a href="#SIMD-Single-Instruction-Multiple-Data" class="headerlink" title="SIMD (Single Instruction, Multiple Data)"></a>SIMD (Single Instruction, Multiple Data)</h3><p><strong>SIMD</strong> stands for <strong>Single Instruction, Multiple Data</strong>, a parallel computing model where <strong>one instruction</strong> operates on <strong>multiple data elements simultaneously</strong>.<br>It is especially useful for tasks like <strong>image processing</strong>, <strong>audio/video encoding</strong>, <strong>machine learning</strong>, and <strong>scientific computing</strong>.<br>SIMD improves performance by exploiting <strong>data-level parallelism</strong>.<br>Modern CPUs include SIMD instruction sets such as <strong>SSE</strong>, <strong>AVX</strong> (Intel/AMD), and <strong>NEON</strong> (ARM).<br>It is a core concept in <strong>vector processing</strong> and used in <strong>GPUs</strong> as well.</p>
<p><strong>SIMD</strong> 是 <strong>单指令多数据流（Single Instruction, Multiple Data）</strong> 的缩写，是一种并行计算模型，其中<strong>一条指令</strong>可以同时作用于<strong>多个数据元素</strong>。<br>它非常适用于图像处理、音视频编解码、机器学习和科学计算等场景。<br>SIMD 通过挖掘数据级并行性（Data-level Parallelism）来提升性能。<br>现代 CPU 提供了 SIMD 指令集，如 <strong>SSE</strong>、<strong>AVX</strong>（Intel/AMD）和 <strong>NEON</strong>（ARM）。<br>它是向量处理（Vector Processing）的核心思想，并广泛用于 <strong>GPU</strong> 中。</p>
<h2 id="4-Formal-Language-amp-Automata"><a href="#4-Formal-Language-amp-Automata" class="headerlink" title="4. Formal Language &amp; Automata"></a>4. Formal Language &amp; Automata</h2><h3 id="Regular-Grammar"><a href="#Regular-Grammar" class="headerlink" title="Regular Grammar"></a>Regular Grammar</h3><p>A <strong>Regular Grammar</strong> is the simplest type of grammar in the Chomsky hierarchy. It is used to define <strong>regular languages</strong>, which can also be recognized by <strong>finite automata</strong>. Regular grammars are widely used in lexical analysis, pattern matching, and simple parsing tasks.</p>
<p><strong>📘 Definition</strong></p>
<p>A <strong>Regular Grammar</strong> is a type of <strong>context-free grammar (CFG)</strong> with special restrictions on its production rules. It consists of:</p>
<ul>
<li>A finite set of <strong>non-terminal symbols</strong></li>
<li>A finite set of <strong>terminal symbols</strong></li>
<li>A <strong>start symbol</strong></li>
<li>A finite set of <strong>production rules</strong></li>
</ul>
<p><strong>🧾 Types of Regular Grammar</strong></p>
<p>There are <strong>two forms</strong> of regular grammars:</p>
<ol>
<li><strong>Right-Linear Grammar</strong></li>
</ol>
<p>All production rules are of the form:</p>
<ul>
<li>$A \rightarrow aB$</li>
<li>$A \rightarrow a$</li>
<li>$A \rightarrow \varepsilon$ (optional for generating empty string)</li>
</ul>
<p>Where:</p>
<ul>
<li>$A, B$ are non-terminal symbols</li>
<li>$a$ is a terminal symbol</li>
</ul>
<p>✅ This is the <strong>most common</strong> form used to generate regular languages.</p>
<ol>
<li><strong>Left-Linear Grammar</strong></li>
</ol>
<p>All production rules are of the form:</p>
<ul>
<li>$A \rightarrow Ba$</li>
<li>$A \rightarrow a$</li>
<li>$A \rightarrow \varepsilon$</li>
</ul>
<p>Both right-linear and left-linear grammars generate <strong>regular languages</strong>, but <strong>mixing them is not allowed</strong> in regular grammar.</p>
<p><strong>🧮 Example of a Right-Linear Grammar</strong></p>
<p>Let’s define a grammar for the regular language $L = { a^n b \mid n \geq 0 }$:</p>
<p><strong>Non-terminals</strong>: ${S, A}$<br><strong>Terminals</strong>: ${a, b}$<br><strong>Start symbol</strong>: $S$<br><strong>Production rules</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">S → aS  
S → b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p>This generates strings like:</p>
<ul>
<li><code>b</code></li>
<li><code>ab</code></li>
<li><code>aab</code></li>
<li><code>aaab</code>, etc.</li>
</ul>
<p><strong>🤖 Equivalent Automata</strong></p>
<p>Every regular grammar corresponds to a <strong>finite automaton</strong>, and vice versa:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Regular Grammar</td>
<td>Generates strings by rules</td>
</tr>
<tr>
<td>Finite Automaton</td>
<td>Accepts strings by state transitions</td>
</tr>
</tbody>
</table>
</div>
<p>So, regular grammar and finite automaton are <strong>equivalent in expressive power</strong>.</p>
<p><strong>📊 Closure Properties</strong></p>
<p>Regular grammars inherit all the closure properties of regular languages:</p>
<ul>
<li>✅ Union</li>
<li>✅ Concatenation</li>
<li>✅ Kleene Star</li>
<li>✅ Intersection with regular sets</li>
<li>✅ Complement</li>
</ul>
<p><strong>🚫 Limitations</strong></p>
<ul>
<li>Cannot handle <strong>nested structures</strong> (e.g., balanced parentheses)</li>
<li>Cannot count or match multiple dependencies (e.g., $a^n b^n$)</li>
</ul>
<p><strong>✅ Summary</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Regular Grammar</th>
</tr>
</thead>
<tbody>
<tr>
<td>Structure</td>
<td>Right- or left-linear rules</td>
</tr>
<tr>
<td>Generates</td>
<td>Regular languages</td>
</tr>
<tr>
<td>Equivalent to</td>
<td>Finite Automaton</td>
</tr>
<tr>
<td>Used in</td>
<td>Lexical analysis, pattern matching</td>
</tr>
<tr>
<td>Can generate $a^n$</td>
<td>✅ Yes</td>
</tr>
<tr>
<td>Can generate $a^n b^n$</td>
<td>❌ No</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="Regular-Language"><a href="#Regular-Language" class="headerlink" title="Regular Language"></a>Regular Language</h3><p>A <strong>Regular Language</strong> is a class of formal languages that can be <strong>recognized by finite automata</strong>. It can be described by:</p>
<ul>
<li><strong>Deterministic Finite Automata (DFA)</strong></li>
<li><strong>Non-deterministic Finite Automata (NFA)</strong></li>
<li><strong>Regular expressions</strong></li>
</ul>
<p>If a language can be represented using any of the above methods, it is a <strong>regular language</strong>.</p>
<p><strong>🔹 Examples</strong></p>
<ol>
<li><p>Language of all strings over <code>&#123;a, b&#125;</code> that contain <strong>only</strong> <code>a</code>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">L &#x3D; &#123; ε, a, aa, aaa, ... &#125; &#x3D; a*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
</li>
<li><p>Language of all strings that start with <code>a</code> and end with <code>b</code>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">L &#x3D; a(a|b)*b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
</li>
<li><p>Language of all strings with even number of <code>0</code>s over <code>&#123;0,1&#125;</code>:</p>
<ul>
<li>This can be recognized by a DFA with two states toggling on <code>0</code>.</li>
</ul>
</li>
</ol>
<ul>
<li><p>They can be <strong>expressed using regular expressions</strong>, and there is an equivalence between:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">DFA ⇄ NFA ⇄ Regular Expression<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
</li>
</ul>
<hr>
<h3 id="Non-Regular-Languages"><a href="#Non-Regular-Languages" class="headerlink" title="Non-Regular Languages"></a>Non-Regular Languages</h3><p>Some languages <strong>cannot</strong> be described by regular expressions or finite automata. For example:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">L &#x3D; &#123; aⁿbⁿ | n ≥ 0 &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>This language requires memory to keep track of the number of <code>a</code>s and <code>b</code>s, which finite automata do not have.</p>
<p>To prove that a language is <strong>not regular</strong>, we can use the <strong>Pumping Lemma</strong>, which states:</p>
<p>If a language <code>L</code> is regular, there exists an integer <code>p &gt; 0</code> (pumping length) such that any string <code>s ∈ L</code> with length ≥ <code>p</code> can be split into <code>s = xyz</code> such that:</p>
<ul>
<li>|y| &gt; 0</li>
<li>|xy| ≤ p</li>
<li>For all <code>i ≥ 0</code>, the string <code>xyⁱz ∈ L</code></li>
</ul>
<p>If no such decomposition exists for a string, the language is <strong>not regular</strong>.</p>
<hr>
<h3 id="Closure-Properties-of-Regular-Languages"><a href="#Closure-Properties-of-Regular-Languages" class="headerlink" title="Closure Properties of Regular Languages"></a>Closure Properties of Regular Languages</h3><blockquote>
<p>🔹 What is “Closure”?</p>
</blockquote>
<p>In automata theory, a class of languages is said to be <strong>closed under an operation</strong> if <strong>applying that operation</strong> to languages in the class <strong>results in a language that is also in the class</strong>.</p>
<p>For <strong>regular languages</strong>, they are closed under many operations. This means if you take <strong>regular languages</strong> and apply these operations, the result will <strong>still be a regular language</strong>.</p>
<blockquote>
<p>🔹 Closure Under Common Operations</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>Operation</th>
<th>Description</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Union</strong></td>
<td>If L₁ and L₂ are regular, then L₁ ∪ L₂ is also regular.</td>
<td>✅ Regular</td>
</tr>
<tr>
<td><strong>Intersection</strong></td>
<td>If L₁ and L₂ are regular, then L₁ ∩ L₂ is also regular.</td>
<td>✅ Regular</td>
</tr>
<tr>
<td><strong>Complement</strong></td>
<td>If L is regular, then its complement ¬L is also regular.</td>
<td>✅ Regular</td>
</tr>
<tr>
<td><strong>Concatenation</strong></td>
<td>If L₁ and L₂ are regular, then L₁L₂ is also regular.</td>
<td>✅ Regular</td>
</tr>
<tr>
<td><strong>Kleene Star</strong></td>
<td>If L is regular, then L* (zero or more repetitions) is also regular.</td>
<td>✅ Regular</td>
</tr>
<tr>
<td><strong>Reversal</strong></td>
<td>If L is regular, then the reverse of L is also regular.</td>
<td>✅ Regular</td>
</tr>
<tr>
<td><strong>Difference</strong></td>
<td>If L₁ and L₂ are regular, then L₁ - L₂ is also regular.</td>
<td>✅ Regular</td>
</tr>
<tr>
<td><strong>Homomorphism</strong></td>
<td>Applying a homomorphism to a regular language gives a regular language.</td>
<td>✅ Regular</td>
</tr>
<tr>
<td><strong>Inverse Homomorphism</strong></td>
<td>Inverse images of regular languages under homomorphisms are regular.</td>
<td>✅ Regular</td>
</tr>
<tr>
<td><strong>Substitution</strong></td>
<td>Regular languages are closed under substitution with regular languages.</td>
<td>✅ Regular</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>🔹 Example: Union Closure</p>
</blockquote>
<p>Let:</p>
<ul>
<li>L₁ = { w | w contains only a’s } = <code>a*</code></li>
<li>L₂ = { w | w contains only b’s } = <code>b*</code></li>
</ul>
<p>Then:</p>
<ul>
<li>L₁ ∪ L₂ = { w | w contains only a’s or only b’s } = <code>a* ∪ b*</code></li>
<li>This is still a regular language.</li>
</ul>
<blockquote>
<p>🔹 Why Closure is Useful</p>
</blockquote>
<ul>
<li>Closure properties help us <strong>construct complex regular languages</strong> from simpler ones.</li>
<li>They are essential in <strong>proving properties</strong> of languages.</li>
<li>They are used in <strong>compiler design</strong>, <strong>regex engines</strong>, and <strong>automated verification</strong>.</li>
</ul>
<hr>
<h3 id="🤖-DFA-Deterministic-Finite-Automaton"><a href="#🤖-DFA-Deterministic-Finite-Automaton" class="headerlink" title="🤖 DFA (Deterministic Finite Automaton)"></a>🤖 DFA (Deterministic Finite Automaton)</h3><p><strong>🔹 Definition</strong></p>
<p>A <strong>DFA</strong> is a type of <strong>finite automaton</strong> used to <strong>recognize regular languages</strong>. It reads an input string <strong>symbol by symbol</strong>, and <strong>at any point</strong> in time, it is in <strong>exactly one state</strong>.</p>
<p>A DFA is defined as a <strong>5-tuple</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">DFA &#x3D; (Q, Σ, δ, q₀, F)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Where:</p>
<ul>
<li><code>Q</code> → Finite set of <strong>states</strong></li>
<li><code>Σ</code> → Finite set of <strong>input symbols</strong> (alphabet)</li>
<li><code>δ</code> → <strong>Transition function</strong>: δ : Q × Σ → Q</li>
<li><code>q₀</code> → <strong>Start state</strong>, where the computation begins (<code>q₀ ∈ Q</code>)</li>
<li><code>F</code> → Set of <strong>accepting/final states</strong> (<code>F ⊆ Q</code>)</li>
</ul>
<p><strong>🔹 Characteristics</strong></p>
<ul>
<li><strong>Deterministic</strong>: For every state <code>q ∈ Q</code> and every input symbol <code>a ∈ Σ</code>, <strong>there is exactly one transition</strong> defined:<br>δ(q, a) = q’</li>
<li><strong>No epsilon (ε) transitions</strong>: Input must be read <strong>one symbol at a time</strong></li>
<li>DFA <strong>always knows</strong> what to do next</li>
</ul>
<p><strong>🔹 Example DFA</strong></p>
<p>Let’s define a DFA that accepts all strings over <code>&#123;0,1&#125;</code> that end with <code>01</code>.</p>
<ul>
<li><code>Q = &#123;q0, q1, q2&#125;</code></li>
<li><code>Σ = &#123;0, 1&#125;</code></li>
<li><code>q₀ = q0</code></li>
<li><code>F = &#123;q2&#125;</code></li>
</ul>
<p>Transition table:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Current State</th>
<th>Input</th>
<th>Next State</th>
</tr>
</thead>
<tbody>
<tr>
<td>q0</td>
<td>0</td>
<td>q1</td>
</tr>
<tr>
<td>q0</td>
<td>1</td>
<td>q0</td>
</tr>
<tr>
<td>q1</td>
<td>0</td>
<td>q1</td>
</tr>
<tr>
<td>q1</td>
<td>1</td>
<td>q2</td>
</tr>
<tr>
<td>q2</td>
<td>0</td>
<td>q1</td>
</tr>
<tr>
<td>q2</td>
<td>1</td>
<td>q0</td>
</tr>
</tbody>
</table>
</div>
<p>This DFA accepts strings like: <code>01</code>, <code>1001</code>, <code>1101</code>, etc.</p>
<p><strong>🔹 DFA vs NFA</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>DFA</th>
<th>NFA</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transition</td>
<td>One unique next state</td>
<td>May have multiple next states</td>
</tr>
<tr>
<td>ε-transitions</td>
<td>Not allowed</td>
<td>Allowed</td>
</tr>
<tr>
<td>Simplicity</td>
<td>Easier to implement</td>
<td>Easier to design</td>
</tr>
<tr>
<td>Power</td>
<td><strong>Same (both recognize regular languages)</strong></td>
</tr>
</tbody>
</table>
</div>
<p><strong>🔹 Applications</strong></p>
<ul>
<li>Lexical analysis (token recognition)</li>
<li>Pattern matching (e.g., <code>grep</code>, <code>regex</code>)</li>
<li>Protocol design</li>
<li>Digital circuits</li>
</ul>
<hr>
<h3 id="🔄-NFA-Nondeterministic-Finite-Automaton"><a href="#🔄-NFA-Nondeterministic-Finite-Automaton" class="headerlink" title="🔄 NFA (Nondeterministic Finite Automaton)"></a>🔄 NFA (Nondeterministic Finite Automaton)</h3><p><strong>🔹 Definition</strong></p>
<p>An <strong>NFA</strong> is a type of <strong>finite automaton</strong> used to recognize <strong>regular languages</strong>, just like a DFA. The key difference is that <strong>multiple transitions</strong> are allowed for the <strong>same input</strong> from a single state, and <strong>ε-transitions</strong> (transitions without consuming input) are permitted.</p>
<p>An NFA is formally defined as a <strong>5-tuple</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">NFA &#x3D; (Q, Σ, δ, q₀, F)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Where:</p>
<ul>
<li><code>Q</code> → Finite set of <strong>states</strong></li>
<li><code>Σ</code> → Finite set of <strong>input symbols</strong> (alphabet)</li>
<li><code>δ</code> → <strong>Transition function</strong>: δ : Q × (Σ ∪ {ε}) → 2^Q</li>
<li><code>q₀</code> → <strong>Start state</strong>, <code>q₀ ∈ Q</code></li>
<li><code>F</code> → Set of <strong>accepting/final states</strong>, <code>F ⊆ Q</code></li>
</ul>
<p><strong>🔹 Characteristics</strong></p>
<ul>
<li><p><strong>Non-deterministic</strong>:</p>
<ul>
<li>From a given state and input, the NFA can <strong>go to multiple next states</strong>.</li>
<li>The NFA <strong>accepts</strong> an input string if <strong>at least one possible path</strong> leads to an accepting state.</li>
</ul>
</li>
<li><strong>ε-transitions allowed</strong>: The machine can move <strong>without reading input</strong>.</li>
<li><strong>Can be in multiple states</strong> at once during computation.</li>
</ul>
<p><strong>🔹 Example NFA</strong></p>
<p>Let’s define an NFA that accepts strings over <code>&#123;0,1&#125;</code> ending in <code>01</code>.</p>
<ul>
<li><code>Q = &#123;q0, q1, q2&#125;</code></li>
<li><code>Σ = &#123;0, 1&#125;</code></li>
<li><code>q₀ = q0</code></li>
<li><code>F = &#123;q2&#125;</code></li>
</ul>
<p>Transition table:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Current State</th>
<th>Input</th>
<th>Next States</th>
</tr>
</thead>
<tbody>
<tr>
<td>q0</td>
<td>0</td>
<td>{q0, q1}</td>
</tr>
<tr>
<td>q0</td>
<td>1</td>
<td>{q0}</td>
</tr>
<tr>
<td>q1</td>
<td>1</td>
<td>{q2}</td>
</tr>
<tr>
<td>q2</td>
<td>0,1</td>
<td>∅</td>
</tr>
</tbody>
</table>
</div>
<p>In this NFA, from <code>q0</code>, if we read <code>0</code>, we can <strong>either</strong> stay in <code>q0</code> or go to <code>q1</code>.</p>
<p><strong>🔹 NFA vs DFA</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>NFA</th>
<th>DFA</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transitions</td>
<td>Can go to <strong>multiple</strong> states</td>
<td>Only <strong>one</strong> next state</td>
</tr>
<tr>
<td>ε-transitions</td>
<td><strong>Allowed</strong></td>
<td><strong>Not allowed</strong></td>
</tr>
<tr>
<td>Execution</td>
<td>Can explore multiple paths in parallel</td>
<td>Only one deterministic path</td>
</tr>
<tr>
<td>Implementation</td>
<td>More complex</td>
<td>Easier</td>
</tr>
<tr>
<td>Expressive Power</td>
<td><strong>Same</strong> – both recognize regular languages</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>💡 Every NFA can be converted into an equivalent DFA (subset construction), though the DFA may have exponentially more states.</p>
</blockquote>
<p><strong>🔹 Applications</strong></p>
<ul>
<li>Easier to <strong>design</strong> than DFA for complex patterns</li>
<li>Used in <strong>regular expression engines</strong></li>
<li>Foundations for <strong>parser generators</strong> and <strong>compiler design</strong></li>
</ul>
<hr>
<h3 id="Finite-State-Machine-FSM"><a href="#Finite-State-Machine-FSM" class="headerlink" title="Finite-State Machine (FSM)"></a>Finite-State Machine (FSM)</h3><p>A <strong>Finite-State Machine (FSM)</strong> is a computational model used to design and describe the behavior of digital systems, software, or processes that are dependent on a sequence of inputs and a finite number of internal states.</p>
<p><strong>🧠 Key Concepts</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Term</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>State</strong></td>
<td>A unique configuration or condition of the system at a given time.</td>
</tr>
<tr>
<td><strong>Input</strong></td>
<td>External data or signal that triggers a transition.</td>
</tr>
<tr>
<td><strong>Transition</strong></td>
<td>The process of moving from one state to another.</td>
</tr>
<tr>
<td><strong>Initial State</strong></td>
<td>The state in which the FSM starts.</td>
</tr>
<tr>
<td><strong>Final State(s)</strong></td>
<td>Some FSMs may have one or more accepting states that signify a successful process.</td>
</tr>
</tbody>
</table>
</div>
<p><strong>🛠 Types of FSM</strong></p>
<ol>
<li><p><strong>Deterministic Finite Automaton (DFA)</strong></p>
<ul>
<li>Each state has <em>exactly one</em> transition for each possible input.</li>
<li>There is <em>no ambiguity</em> in state transitions.</li>
</ul>
</li>
<li><p><strong>Nondeterministic Finite Automaton (NFA)</strong></p>
<ul>
<li>A state can have <em>multiple transitions</em> for the same input.</li>
<li>May include <em>ε-transitions</em> (transitions without input).</li>
</ul>
</li>
</ol>
<p><strong>⚙️ Components of an FSM</strong></p>
<p>An FSM is formally defined as a 5-tuple:</p>
<script type="math/tex; mode=display">
M = (Q, \Sigma, \delta, q_0, F)</script><p><strong>🧭 How It Works (Example)</strong></p>
<p>Suppose we have an FSM that accepts binary strings ending in <code>01</code>.</p>
<ul>
<li><strong>States</strong>: <code>S0</code> (start), <code>S1</code> (seen 0), <code>S2</code> (accepting, seen 01)</li>
<li><strong>Input</strong>: <code>0</code>, <code>1</code></li>
<li><p><strong>Transitions</strong>:</p>
<ul>
<li>From <code>S0</code>, on <code>0</code> → <code>S1</code></li>
<li>From <code>S1</code>, on <code>1</code> → <code>S2</code></li>
<li>From <code>S2</code>, on <code>0</code> → <code>S1</code>, on <code>1</code> → <code>S0</code> (reset if wrong pattern)</li>
</ul>
</li>
</ul>
<p><strong>📦 Applications</strong></p>
<ul>
<li>Lexical analyzers (compilers)</li>
<li>Protocol design</li>
<li>Game development (e.g., AI behavior)</li>
<li>Digital circuit design</li>
<li>Control systems</li>
</ul>
<hr>
<h3 id="Pumping-Lemma-for-regular-languages"><a href="#Pumping-Lemma-for-regular-languages" class="headerlink" title="Pumping Lemma for regular languages"></a>Pumping Lemma for regular languages</h3><p>The <strong>Pumping Lemma</strong> for regular languages is an important tool in formal language and automata theory, used to prove that a given language is <strong>not</strong> regular. The pumping lemma provides a “pumping” property, which means that certain strings in a regular language can be repeated (or “pumped”) under specific conditions without changing whether the string belongs to the language.</p>
<p>The pumping lemma mainly applies to regular languages. It states:<br>If a language is regular, then there exists a constant $p$ (called the pumping length), such that for any string $s \in L$ (where $s$ belongs to language $L$) with length greater than or equal to $p$, it is possible to divide $s$ into the following three parts:</p>
<ul>
<li><p>$s = xyz$, where:</p>
<ul>
<li>$x$ is a prefix of $s$ (possibly empty).</li>
<li>$y$ is the part that can be “pumped”, and $|y| &gt; 0$.</li>
<li>$z$ is a suffix of $s$ (possibly empty).</li>
</ul>
</li>
</ul>
<p>Moreover, for any $i \geq 0$, the string $xy^i z$ must also belong to the language $L$. That is, the substring $y$ can be repeated any number of times without affecting whether $s$ belongs to $L$.</p>
<hr>
<h3 id="Pumping-Lemma-for-CFLs"><a href="#Pumping-Lemma-for-CFLs" class="headerlink" title="Pumping Lemma for CFLs"></a>Pumping Lemma for CFLs</h3><p>The Pumping Lemma for Context-Free Languages (CFLs) states that for any context-free language $L$, if $L$ is infinite, then there exists a constant $p$ (pumping length), such that for every string $s \in L$ with length greater than or equal to $p$, the string $s$ can be divided into five parts $s = uvwxy$, satisfying the following conditions:</p>
<ol>
<li>For all $i \geq 0$, $uv^i w x^i y \in L$.</li>
<li>$|v| + |x| &gt; 0$ (i.e., $v$ and $x$ are not both empty).</li>
<li>$|vwx| \leq p$ (the total length of $v$, $w$, and $x$ does not exceed the pumping length $p$).</li>
</ol>
<p>We assume that $L$ is an infinite context-free language. Since $L$ is a context-free language, based on the structural properties of context-free grammars, it corresponds to a pushdown automaton (PDA). This PDA must satisfy one condition: it can “pump” strings, i.e., repeat certain parts of the string while keeping the resulting string within the language $L$.</p>
<p>According to the pumping lemma assumption, there exists a pumping length $p$, such that for all strings $s \in L$ with length greater than or equal to $p$, the string $s$ can be decomposed as $s = uvwxy$, satisfying the following conditions:</p>
<ul>
<li>$|vwx| \leq p$</li>
<li>$|v| + |x| &gt; 0$</li>
</ul>
<p>Context-free languages can be generated by context-free grammars (CFGs) or recognized by pushdown automata (PDAs). We use these structures to demonstrate the pumping lemma.</p>
<ul>
<li>For any string $s \in L$ with length greater than or equal to $p$, it must be generated by derivation using a context-free grammar.</li>
<li><p>Since $L$ is infinite, there exists a derivation tree for some parts that can be broken down into five parts $uvwxy$, where:</p>
<ul>
<li>$v$ and $x$ are the parts that can be “pumped” or repeated.</li>
<li>The total length of $v$ and $x$ does not exceed $p$.</li>
<li>This means that for some appropriate $i$, $v$ and $x$ can be repeated without breaking the structure of the language.</li>
</ul>
</li>
</ul>
<blockquote>
<p>The proof here also involves the Pigeonhole Principle, which is not elaborated on in detail.</p>
</blockquote>
<p>Based on the structure of context-free languages, the string $s$ can be decomposed as $s = uvwxy$, satisfying the following conditions:</p>
<ul>
<li>$|vwx| \leq p$, which means the total length of $v$ and $x$ does not exceed the pumping length $p$; their lengths are finite.</li>
<li>$|v| + |x| &gt; 0$, which means $v$ and $x$ cannot both be empty.</li>
</ul>
<p>According to the pumping lemma, we know that if we “pump” the parts $v$ and $x$ of the string $s$, i.e., repeat them multiple times, then the new string $uv^i w x^i y$ will still belong to the language $L$, for all $i \geq 0$.</p>
<p>According to the pumping lemma assumption, for all $i \geq 0$, $uv^i w x^i y \in L$. This means that by increasing the number of repetitions of parts $v$ and $x$, the string remains within the language $L$.</p>
<p>The key to this process is that through appropriate decomposition and pumping operations, the structure of the language remains unchanged, and therefore it can be accepted by a context-free grammar or pushdown automaton.</p>
<p>Using the pumping lemma, we can prove that some languages are <strong>not</strong> context-free. A proof by contradiction is often used to show that a language does not satisfy the requirements of a context-free language. By choosing an appropriate string and assuming it satisfies the conditions of the pumping lemma, we can show that certain operations cause the resulting string to no longer belong to the language, thus concluding that the language is not context-free.</p>
<hr>
<p>Using the pumping lemma, we can prove that certain languages are not context-free by contradiction. Suppose we want to prove that a language $L$ is not context-free. The process usually involves the following steps:</p>
<ol>
<li>Assume that $L$ is a context-free language and that it satisfies the pumping lemma.</li>
<li>Choose a string $s \in L$ with length greater than or equal to the pumping length $p$, then decompose it as $s = uvwxy$ and apply the pumping lemma.</li>
<li>Expand $uv^i w x^i y$ and prove that for some values of $i$, $uv^i w x^i y \notin L$, thus leading to a contradiction.</li>
<li>Conclude that $L$ is not a context-free language.</li>
</ol>
<p>Example: Prove that $L = { a^n b^n c^n \mid n \geq 0 }$ is not a context-free language.</p>
<p>We use the pumping lemma for context-free languages to prove that $L = { a^n b^n c^n \mid n \geq 0 }$ is not context-free.</p>
<ol>
<li><p><strong>Assume $L$ is a context-free language:</strong><br>Assume that $L$ is a context-free language and that a pumping length $p$ exists. According to the pumping lemma, any string $s$ with length greater than or equal to $p$ can be decomposed as $s = uvwxy$, where $|vwx| \leq p$ and $|v| + |x| &gt; 0$.</p>
</li>
<li><p><strong>Choose the string $s = a^p b^p c^p$:</strong><br>Choose the string $s = a^p b^p c^p$, which clearly belongs to $L$, and its length $|s| = 3p \geq p$.</p>
</li>
<li><p><strong>Decompose the string $s$:</strong><br>According to the pumping lemma, $s = uvwxy$, where $|vwx| \leq p$ and $|v| + |x| &gt; 0$. Since $|vwx| \leq p$, it can only span one portion of the string (i.e., the $a^n$, $b^n$, or $c^n$ part). Also, since $|v| + |x| &gt; 0$, $v$ and $x$ must include some repeating characters.</p>
</li>
<li><p><strong>Apply the pumping lemma:</strong><br>According to the pumping lemma, for all $i \geq 0$, $uv^i w x^i y$ should still belong to $L$. However, if we choose $i &gt; 1$, we get a mismatched string such as $uv^2 w x^2 y$. This string would no longer maintain the same number of <code>a</code>s, <code>b</code>s, and <code>c</code>s, and thus would not belong to $L$.</p>
</li>
<li><p><strong>Reach a contradiction:</strong><br>Therefore, we conclude that $L$ cannot be a context-free language because the result from the pumping lemma contradicts the definition of $L$.</p>
</li>
</ol>
<p>The pumping lemma for context-free languages demonstrates certain properties of languages by decomposing and repeating parts of their strings. It provides a method to prove by contradiction that certain languages are not context-free.</p>
<hr>
<h3 id="Context-Free-Language-CFL"><a href="#Context-Free-Language-CFL" class="headerlink" title="Context-Free Language (CFL)"></a>Context-Free Language (CFL)</h3><p>A <strong>Context-Free Language (CFL)</strong> is a type of formal language that can be generated by a <strong>Context-Free Grammar (CFG)</strong>. It is an essential concept in the theory of computation and plays a major role in compiler design and parsing.</p>
<p><strong>📘 What is a Context-Free Grammar (CFG)?</strong></p>
<p>A <strong>Context-Free Grammar</strong> is a set of recursive rewriting rules (productions) used to generate strings in a language. A CFG is formally defined as a 4-tuple:</p>
<script type="math/tex; mode=display">
G = (V, \Sigma, R, S)</script><p>Where:</p>
<ul>
<li>$V$: A finite set of <strong>variables</strong> (non-terminal symbols)</li>
<li>$\Sigma$: A finite set of <strong>terminal symbols</strong> (alphabet of the language)</li>
<li>$R$: A finite set of <strong>production rules</strong>, each of the form $A \rightarrow \gamma$, where $A \in V$ and $\gamma \in (V \cup \Sigma)^*$</li>
<li>$S$: The <strong>start symbol</strong>, $S \in V$</li>
</ul>
<p><strong>🧠 Key Characteristics of CFLs</strong></p>
<ul>
<li>The <strong>left-hand side</strong> of every production rule in a CFG has exactly <strong>one non-terminal</strong>.</li>
<li>A string belongs to the CFL if it can be derived from the start symbol using the rules.</li>
<li>CFLs are more powerful than <strong>regular languages</strong>, but less powerful than <strong>context-sensitive languages</strong>.</li>
</ul>
<p><strong>🧮 Example of a Context-Free Grammar</strong></p>
<p>Let’s define a CFG for the language $L = { a^n b^n \mid n \geq 0 }$:</p>
<p><strong>Grammar:</strong></p>
<ul>
<li>$V = { S }$</li>
<li>$\Sigma = { a, b }$</li>
<li><p><strong>Production Rules</strong>:</p>
<ul>
<li>$S \rightarrow aSb$</li>
<li>$S \rightarrow \varepsilon$ <em>(epsilon, the empty string)</em></li>
</ul>
</li>
<li>$S$: start symbol</li>
</ul>
<p>This grammar generates:</p>
<ul>
<li>$\varepsilon$</li>
<li>$ab$</li>
<li>$aabb$</li>
<li>$aaabbb$, etc.</li>
</ul>
<p><strong>📊 Closure Properties of CFLs</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Operation</th>
<th>Closed under?</th>
</tr>
</thead>
<tbody>
<tr>
<td>Union</td>
<td>✅ Yes</td>
</tr>
<tr>
<td>Concatenation</td>
<td>✅ Yes</td>
</tr>
<tr>
<td>Kleene Star</td>
<td>✅ Yes</td>
</tr>
<tr>
<td>Intersection</td>
<td>❌ No</td>
</tr>
<tr>
<td>Complement</td>
<td>❌ No</td>
</tr>
</tbody>
</table>
</div>
<p><strong>🖥 Recognizing CFLs with Pushdown Automata (PDA)</strong></p>
<p>A <strong>Pushdown Automaton (PDA)</strong> is a computational model that recognizes context-free languages.<br>It is similar to a finite automaton but with an added <strong>stack</strong>, which allows it to store an unbounded amount of information.</p>
<blockquote>
<p>CFLs are <strong>exactly</strong> the class of languages accepted by nondeterministic PDAs.</p>
</blockquote>
<p><strong>🚫 Not All Languages Are CFLs</strong></p>
<p>Some languages are <strong>not</strong> context-free, for example:</p>
<script type="math/tex; mode=display">
L = \{ a^n b^n c^n \mid n \geq 0 \}</script><p>No CFG can generate this language because it requires <strong>three-way balancing</strong>, which CFGs cannot handle.</p>
<p><strong>🧪 Applications of CFLs</strong></p>
<ul>
<li><strong>Programming languages</strong> (syntax parsing)</li>
<li><strong>Compilers</strong> (syntax analysis)</li>
<li><strong>Natural language processing</strong></li>
<li><strong>XML and structured data parsing</strong></li>
</ul>
<hr>
<h3 id="Pushdown-Automaton-PDA"><a href="#Pushdown-Automaton-PDA" class="headerlink" title="Pushdown Automaton (PDA)"></a>Pushdown Automaton (PDA)</h3><p>A <strong>Pushdown Automaton (PDA)</strong> is a type of computational model that extends the <strong>finite automaton</strong> by adding a <strong>stack</strong> as memory. This additional memory allows it to recognize <strong>context-free languages</strong> (CFLs), which are more powerful than regular languages.</p>
<p><strong>🧠 Intuition</strong></p>
<p>A PDA reads input symbols <strong>one at a time</strong>, transitions between states based on the current input <strong>and</strong> the <strong>top of the stack</strong>, and can <strong>push</strong> or <strong>pop</strong> symbols from the stack.</p>
<ul>
<li>Think of the <strong>stack</strong> as an unlimited memory that operates in <strong>LIFO</strong> (Last-In, First-Out) order.</li>
<li>The PDA uses the stack to keep track of nested or recursive patterns (e.g. matching parentheses).</li>
</ul>
<p><strong>🧱 Formal Definition</strong></p>
<p>A <strong>PDA</strong> is a 7-tuple:</p>
<script type="math/tex; mode=display">
M = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)</script><p>Where:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>$Q$</td>
<td>A finite set of <strong>states</strong></td>
</tr>
<tr>
<td>$\Sigma$</td>
<td>The <strong>input alphabet</strong></td>
</tr>
<tr>
<td>$\Gamma$</td>
<td>The <strong>stack alphabet</strong></td>
</tr>
<tr>
<td>$\delta$</td>
<td>The <strong>transition function</strong>: $Q \times (\Sigma \cup \varepsilon) \times \Gamma \rightarrow \mathcal{P}(Q \times \Gamma^*)$</td>
</tr>
<tr>
<td>$q_0$</td>
<td>The <strong>start state</strong>, $q_0 \in Q$</td>
</tr>
<tr>
<td>$Z_0$</td>
<td>The <strong>initial stack symbol</strong>, $Z_0 \in \Gamma$</td>
</tr>
<tr>
<td>$F$</td>
<td>A set of <strong>accepting (final) states</strong>, $F \subseteq Q$</td>
</tr>
</tbody>
</table>
</div>
<p><strong>🔁 Transition Function Explanation</strong></p>
<p>The transition function:</p>
<script type="math/tex; mode=display">
\delta(q, a, X) = \{ (q', \gamma) \}</script><p>Means:</p>
<ul>
<li>In state $q$, if the input symbol is $a$ (or $\varepsilon$), and the <strong>top of the stack</strong> is $X$,</li>
<li><p>Then the machine can:</p>
<ul>
<li><strong>Move</strong> to state $q’$</li>
<li><strong>Replace</strong> $X$ with $\gamma$ on the stack (where $\gamma$ can be multiple symbols or empty)</li>
</ul>
</li>
</ul>
<p>🧮 Example: PDA for $L = { a^n b^n \mid n \geq 0 }$</p>
<p>We want to accept strings where the number of <code>a</code>s equals the number of <code>b</code>s.</p>
<p><strong>Idea</strong>:</p>
<ul>
<li>Push <code>A</code> onto the stack for each <code>a</code>.</li>
<li>Pop <code>A</code> from the stack for each <code>b</code>.</li>
<li>Accept if the stack is empty at the end.</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Step</th>
<th>Stack Operation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Read <code>a</code></td>
<td>Push <code>A</code></td>
</tr>
<tr>
<td>Read <code>b</code></td>
<td>Pop <code>A</code></td>
</tr>
<tr>
<td>Input done</td>
<td>Accept if stack empty</td>
</tr>
</tbody>
</table>
</div>
<p><strong>✅ Acceptance Criteria</strong></p>
<p>There are <strong>two common acceptance methods</strong> for PDAs:</p>
<ol>
<li><strong>By final state</strong>: The PDA ends in an accepting state after reading the entire input.</li>
<li><strong>By empty stack</strong>: The PDA’s stack is empty after reading the entire input.</li>
</ol>
<blockquote>
<p>Both methods define the same class of languages: <strong>context-free languages</strong>.</p>
</blockquote>
<p><strong>⚠️ Deterministic vs Nondeterministic PDA</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>NPDA</strong></td>
<td>Nondeterministic PDA — accepts all CFLs</td>
</tr>
<tr>
<td><strong>DPDA</strong></td>
<td>Deterministic PDA — accepts only some CFLs</td>
</tr>
</tbody>
</table>
</div>
<p>Not all context-free languages can be recognized by a deterministic PDA.</p>
<p>🔬 <strong>Applications</strong></p>
<ul>
<li><strong>Parsing</strong> expressions in compilers</li>
<li><strong>Syntax checking</strong> in programming languages (e.g., bracket matching)</li>
<li>Modeling <strong>recursive structures</strong></li>
<li><strong>Natural language processing</strong> (nested phrase structures)</li>
</ul>
<hr>
<h3 id="Ambiguity-of-Grammar"><a href="#Ambiguity-of-Grammar" class="headerlink" title="Ambiguity of Grammar"></a>Ambiguity of Grammar</h3><p>In formal language theory, a <strong>grammar is said to be ambiguous</strong> if there exists <strong>at least one string</strong> that can be generated by the grammar in <strong>more than one way</strong> — specifically, it has <strong>more than one parse tree (or derivation)</strong>.</p>
<p><strong>📚 Definition</strong></p>
<p>A <strong>context-free grammar (CFG)</strong> $G$ is <strong>ambiguous</strong> if <strong>there exists a string</strong> $w \in L(G)$ such that:</p>
<ul>
<li>$w$ has <strong>two or more different parse trees</strong>, or</li>
<li>$w$ has <strong>two or more leftmost (or rightmost) derivations</strong></li>
</ul>
<p><strong>🧠 Why Does Ambiguity Matter?</strong></p>
<ul>
<li><strong>Ambiguous grammars</strong> are problematic in <strong>programming language design</strong>, especially during <strong>parsing</strong>, because a compiler may not know which interpretation is correct.</li>
<li>Some context-free languages are <strong>inherently ambiguous</strong> — no unambiguous CFG can generate them.</li>
</ul>
<p><strong>🧮 Example: An Ambiguous Grammar</strong></p>
<p>Let’s define a simple grammar for arithmetic expressions:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">E → E + E  
E → E * E  
E → (E)  
E → id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>This grammar generates expressions like <code>id + id * id</code>, but it is <strong>ambiguous</strong> because:</p>
<ul>
<li>It can be parsed as <code>(id + id) * id</code></li>
<li>Or as <code>id + (id * id)</code></li>
</ul>
<p>Both are valid interpretations but <strong>yield different parse trees</strong>.</p>
<p><strong>🌲 Two Different Parse Trees for <code>id + id * id</code></strong></p>
<p><strong>1. Left-associative (Addition first)</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">    E
   &#x2F;|\
  E + E
 |    |
id   E * E
     |   |
    id  id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p><strong>2. Right-associative (Multiplication first)</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">       E
      &#x2F;|\
     E * E
    |    |
   E + E id
  |   |
id  id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>This shows <strong>ambiguity</strong> in structure and meaning.</p>
<p><strong>🛠 Disambiguating a Grammar</strong></p>
<p>To <strong>remove ambiguity</strong>, you can:</p>
<ul>
<li><strong>Introduce precedence and associativity rules</strong> (e.g., make <code>*</code> bind tighter than <code>+</code>)</li>
<li><strong>Refactor the grammar</strong> to eliminate conflicting derivations</li>
</ul>
<p>For example:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">E  → E + T | T  
T  → T * F | F  
F  → (E) | id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure>
<p>Now:</p>
<ul>
<li><code>*</code> has higher precedence than <code>+</code></li>
<li>Left associativity is enforced</li>
<li>This grammar is <strong>unambiguous</strong></li>
</ul>
<p><strong>🔥 Inherently Ambiguous Languages</strong></p>
<p>Some CFLs are <strong>inherently ambiguous</strong>, meaning <strong>no matter how you write the grammar</strong>, some strings will always have multiple parse trees.</p>
<p>Example language:</p>
<script type="math/tex; mode=display">
L = \{ a^i b^j c^k \mid i = j \text{ or } j = k \}</script><p>This language is <strong>not inherently unambiguous</strong> because you can’t write a CFG for it that avoids ambiguity in all cases.</p>
<p><strong>✅ Summary</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Concept</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ambiguity</strong></td>
<td>A string has multiple parse trees or derivations in a grammar</td>
</tr>
<tr>
<td><strong>Unambiguous CFG</strong></td>
<td>A CFG where every string has <strong>only one</strong> parse tree</td>
</tr>
<tr>
<td><strong>Inherently Ambiguous Language</strong></td>
<td>A CFL for which <strong>no unambiguous grammar exists</strong></td>
</tr>
<tr>
<td><strong>Solution</strong></td>
<td>Rewrite grammar with precedence/associativity or restructure rules</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="Turing-Machine"><a href="#Turing-Machine" class="headerlink" title="Turing Machine"></a>Turing Machine</h3><p>A <strong>Turing Machine</strong> is a powerful abstract computational model introduced by <strong>Alan Turing</strong> in 1936. It forms the foundation of modern computer science and helps define the limits of what can be computed.</p>
<p><strong>🧱 Definition</strong></p>
<p>A <strong>Turing Machine (TM)</strong> is a 7-tuple:</p>
<script type="math/tex; mode=display">
M = (Q, \Sigma, \Gamma, \delta, q_0, q_{\text{accept}}, q_{\text{reject}})</script><p>Where:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>$Q$</td>
<td>A finite set of <strong>states</strong></td>
</tr>
<tr>
<td>$\Sigma$</td>
<td>The <strong>input alphabet</strong> (does not include the blank symbol <code>□</code>)</td>
</tr>
<tr>
<td>$\Gamma$</td>
<td>The <strong>tape alphabet</strong> (includes <code>□</code>, the blank symbol)</td>
</tr>
<tr>
<td>$\delta$</td>
<td>The <strong>transition function</strong>: $Q \times \Gamma \rightarrow Q \times \Gamma \times {L, R}$</td>
</tr>
<tr>
<td>$q_0$</td>
<td>The <strong>start state</strong></td>
</tr>
<tr>
<td>$q_{\text{accept}}$</td>
<td>The <strong>accepting state</strong></td>
</tr>
<tr>
<td>$q_{\text{reject}}$</td>
<td>The <strong>rejecting state</strong> (≠ $q_{\text{accept}}$)</td>
</tr>
</tbody>
</table>
</div>
<p><strong>🧠 How It Works</strong></p>
<ol>
<li><p>The machine has an <strong>infinite tape</strong> divided into cells, each holding one symbol from $\Gamma$.</p>
</li>
<li><p>A <strong>tape head</strong> reads and writes symbols on the tape and moves <strong>left (L)</strong> or <strong>right (R)</strong>.</p>
</li>
<li><p>The machine starts in the <strong>start state</strong> $q_0$, with the tape containing the input string and blanks elsewhere.</p>
</li>
<li><p>Based on the current state and the symbol under the head, the <strong>transition function</strong> determines:</p>
<ul>
<li>The next state</li>
<li>The symbol to write</li>
<li>The direction to move the head</li>
</ul>
</li>
<li><p>The machine halts when it enters either the <strong>accept state</strong> or the <strong>reject state</strong>.</p>
</li>
</ol>
<p><strong>📋 Example Transition</strong></p>
<p>If:</p>
<script type="math/tex; mode=display">
\delta(q_1, 1) = (q_2, 0, R)</script><p>It means:</p>
<ul>
<li>In state $q_1$, if reading symbol <code>1</code></li>
<li>Write <code>0</code>, move <strong>right</strong>, and go to state $q_2$</li>
</ul>
<p><strong>✅ Acceptance Criteria</strong></p>
<p>A string is <strong>accepted</strong> by the Turing Machine if, starting from the initial configuration, the machine <strong>eventually reaches the accept state</strong>.</p>
<p><strong>🧮 Example Language</strong></p>
<p>Language:</p>
<script type="math/tex; mode=display">
L = \{ w \in \{0,1\}^* \mid w \text{ has an even number of 0s} \}</script><p>A Turing Machine for this language could:</p>
<ul>
<li>Track even/odd count using states</li>
<li>Scan the tape and change state upon reading <code>0</code></li>
<li>Halt in the accept state if the final state indicates even count</li>
</ul>
<p><strong>🧰 Types of Turing Machines</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Deterministic TM (DTM)</strong></td>
<td>One possible action per state-symbol pair</td>
</tr>
<tr>
<td><strong>Nondeterministic TM (NTM)</strong></td>
<td>Multiple possible transitions (theoretical model)</td>
</tr>
<tr>
<td><strong>Multi-tape TM</strong></td>
<td>Multiple tapes (still equivalent in power to DTM)</td>
</tr>
<tr>
<td><strong>Universal TM</strong></td>
<td>Simulates any other Turing Machine (like real computers!)</td>
</tr>
</tbody>
</table>
</div>
<p><strong>🔬 Power of Turing Machines</strong></p>
<p>Turing Machines can simulate:</p>
<ul>
<li>Finite automata</li>
<li>Pushdown automata</li>
<li>Real programming languages</li>
</ul>
<p>They can compute anything that is <strong>computable</strong>, but <strong>some problems are undecidable</strong>, like the <strong>halting problem</strong>.</p>
<p><strong>🔒 Limitations</strong></p>
<ul>
<li><strong>Not all languages are Turing-decidable</strong></li>
<li><strong>Undecidable problems</strong> exist (e.g., Halting Problem, Post Correspondence Problem)</li>
</ul>
<p><strong>✅ Summary</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Turing Machine</th>
</tr>
</thead>
<tbody>
<tr>
<td>Memory</td>
<td>Infinite tape</td>
</tr>
<tr>
<td>Acceptance</td>
<td>By entering accept state</td>
</tr>
<tr>
<td>More powerful than</td>
<td>FA, PDA, CFG</td>
</tr>
<tr>
<td>Can simulate real CPUs</td>
<td>✅ Yes</td>
</tr>
<tr>
<td>Can solve all problems</td>
<td>❌ No (some problems are undecidable)</td>
</tr>
</tbody>
</table>
</div>
<h2 id="5-Programming-Language"><a href="#5-Programming-Language" class="headerlink" title="5. Programming Language"></a>5. Programming Language</h2><h2 id="6-Machine-Learning"><a href="#6-Machine-Learning" class="headerlink" title="6. Machine Learning"></a>6. Machine Learning</h2><h3 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h3><p><strong>Random Forest</strong> 是一种基于 <strong>集成学习（Ensemble Learning）</strong> 的分类或回归算法，它将多个 <strong>决策树（Decision Tree）</strong> 组合在一起，通过“投票”或“平均”的方式得到最终结果。</p>
<blockquote>
<p>它是一种 <strong>Bagging（Bootstrap Aggregation）</strong> 方法，用于减少过拟合、提升泛化能力。</p>
</blockquote>
<p><strong>📦 应用于场景</strong></p>
<ul>
<li><strong>分类任务</strong>：判断邮件是否垃圾</li>
<li><strong>回归任务</strong>：预测房价</li>
<li><strong>特征重要性分析</strong>：哪些变量对预测结果影响最大？</li>
</ul>
<p><strong>🧠 核心思想</strong></p>
<p><strong>多个“弱学习器”</strong>（即单棵决策树）在数据子集上独立训练，然后<strong>集成</strong>它们的预测结果。</p>
<p><strong>⚙️ 构造过程（算法流程）</strong></p>
<p>Step 1️⃣：Bootstrap 采样（有放回抽样）</p>
<p>从训练数据集中<strong>有放回地随机抽样</strong> $N$ 次，构成若干个训练子集（每棵树用一份）</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">原始数据 D = &#123;x1, x2, ..., xn&#125;
→ 样本子集 D1, D2, ..., Dk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p>Step 2️⃣：训练多棵决策树（树的多样性来源之一）</p>
<p>对每个子集 $D_i$ 训练一棵<strong>决策树</strong>，但每个节点划分时只使用<strong>随机选择的部分特征</strong>（通常 $\sqrt{M}$ 个特征）</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">例如：总共有 100 个特征，每个节点只从随机选出的 10 个特征中选择最佳划分<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Step 3️⃣：集成预测结果</p>
<ul>
<li><strong>分类任务</strong>：采用<strong>多数投票</strong>（majority vote）</li>
<li><strong>回归任务</strong>：采用<strong>平均值</strong>（average）</li>
</ul>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 分类投票</span>
final_class <span class="token operator">=</span> most_common<span class="token punctuation">(</span><span class="token punctuation">[</span>tree<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> tree <span class="token keyword">in</span> forest<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 回归平均</span>
final_value <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>tree<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> tree <span class="token keyword">in</span> forest<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>forest<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>🧩 为什么 Random Forest 有效？</p>
<p>🎯 降低过拟合</p>
<ul>
<li>单棵树容易对噪声拟合（高方差）</li>
<li>多棵树平均可以“相互抵消”过拟合的部分</li>
</ul>
<p>🎯 提高泛化能力</p>
<ul>
<li>利用数据和特征的随机性，使得每棵树不太相同，整体更强大</li>
</ul>
<p>🎯 可并行训练（每棵树相互独立）</p>
<p><strong>🔍 特征重要性评估</strong></p>
<p>每棵树训练后可计算各特征在信息增益或 Gini 指数上的贡献<br>→ 可以评估哪些变量对模型影响最大</p>
<p>📊 时间与空间复杂度</p>
<p>设：</p>
<ul>
<li>$n$：样本数量</li>
<li>$m$：特征数量</li>
<li>$k$：树的数量</li>
<li>$d$：树的平均深度</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>复杂度</th>
</tr>
</thead>
<tbody>
<tr>
<td>训练时间</td>
<td>$O(k \cdot n \cdot \log n \cdot m’)$（$m’ \ll m$）</td>
</tr>
<tr>
<td>推理时间</td>
<td>$O(k \cdot d)$</td>
</tr>
<tr>
<td>空间复杂度</td>
<td>$O(k \cdot n)$（每棵树存储路径）</td>
</tr>
</tbody>
</table>
</div>
<p> ✅ 优点总结</p>
<ul>
<li>不容易过拟合</li>
<li>可处理高维数据</li>
<li>对异常值不敏感</li>
<li>支持特征重要性排序</li>
<li>适合并行处理</li>
</ul>
<p>⚠️ 缺点</p>
<ul>
<li>相比单棵树可解释性较差</li>
<li>训练时间较长</li>
<li>若样本不平衡，分类性能可能下降</li>
</ul>
<p>📌 Python示例（使用 <code>sklearn</code>）</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment"># 加载数据</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> load_iris<span class="token punctuation">(</span>return_X_y<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span>

<span class="token comment"># 训练随机森林</span>
clf <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> max_features<span class="token operator">=</span><span class="token string">'sqrt'</span><span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token comment"># 预测</span>
y_pred <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p><strong>📖 总结表格</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>项目</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>模型类型</td>
<td>集成学习（Bagging）</td>
</tr>
<tr>
<td>基学习器</td>
<td>决策树</td>
</tr>
<tr>
<td>多样性来源</td>
<td>数据采样 + 特征子集选择</td>
</tr>
<tr>
<td>聚合方式</td>
<td>多数投票（分类） / 平均（回归）</td>
</tr>
<tr>
<td>优点</td>
<td>抗过拟合、稳定、能评估特征重要性</td>
</tr>
<tr>
<td>常用库</td>
<td><code>scikit-learn</code>、<code>xgboost</code>、<code>lightgbm</code>（变种）</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/img/concepts/random.svg" srcset="/img/loading.gif" lazyload alt="随机森林" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="线性回归（Linear-Regression）"><a href="#线性回归（Linear-Regression）" class="headerlink" title="线性回归（Linear Regression）"></a>线性回归（Linear Regression）</h3><p><strong>线性回归</strong>是一种基础的监督学习算法，用于建立<strong>特征变量（自变量）</strong> 与 <strong>目标变量（因变量）</strong> 之间的<strong>线性关系</strong>模型：</p>
<script type="math/tex; mode=display">
\hat{y} = w_1x_1 + w_2x_2 + \dots + w_nx_n + b = \mathbf{w}^\top \mathbf{x} + b</script><ul>
<li>$\hat{y}$：预测值</li>
<li>$\mathbf{x}$：输入特征向量（如 $[x_1, x_2, …, x_n]$）</li>
<li>$\mathbf{w}$：权重向量（参数）</li>
<li>$b$：偏置项（intercept）</li>
</ul>
<p>🎯 目标</p>
<p>找到一组参数 $(\mathbf{w}, b)$，使得预测值 $\hat{y}$ <strong>尽可能接近真实值 $y$</strong>。</p>
<p>📐 损失函数（Loss Function）</p>
<p>我们最常用的是<strong>均方误差（Mean Squared Error, MSE）</strong>：</p>
<script type="math/tex; mode=display">
J(\mathbf{w}, b) = \frac{1}{m} \sum_{i=1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right)^2
= \frac{1}{m} \sum_{i=1}^{m} \left( \mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)} \right)^2</script><ul>
<li>$m$：样本数</li>
<li>最小化 $J(\mathbf{w}, b)$ 就是训练过程的目标</li>
</ul>
<p>⚙️ 求解方法</p>
<p>1️⃣ <strong>正规方程法（Normal Equation）</strong> —— 精确解法</p>
<p>直接对损失函数求导并解方程：</p>
<script type="math/tex; mode=display">
\mathbf{w} = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{y}</script><ul>
<li>$\mathbf{X}$：$m \times n$ 的特征矩阵</li>
<li>$\mathbf{y}$：$m \times 1$ 的目标值向量</li>
<li>要求 $\mathbf{X}^\top \mathbf{X}$ 可逆（数值稳定性差时需用伪逆）</li>
</ul>
<blockquote>
<p>优点：计算精确<br>缺点：复杂度高 $O(n^3)$，不适合高维大数据</p>
</blockquote>
<p>2️⃣ <strong>梯度下降法（Gradient Descent）</strong> —— 近似解法</p>
<p>对损失函数求偏导，使用迭代方式逼近最优：</p>
<p>参数更新公式：</p>
<ul>
<li><p>对权重：</p>
<script type="math/tex; mode=display">
w_j \leftarrow w_j - \alpha \cdot \frac{\partial J}{\partial w_j}</script></li>
<li><p>对偏置：</p>
<script type="math/tex; mode=display">
b \leftarrow b - \alpha \cdot \frac{\partial J}{\partial b}</script></li>
</ul>
<p>导数计算结果：</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial w_j} = \frac{2}{m} \sum_{i=1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right) x_j^{(i)}</script><script type="math/tex; mode=display">
\frac{\partial J}{\partial b} = \frac{2}{m} \sum_{i=1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right)</script><p>梯度下降伪代码：</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">repeat until converge<span class="token punctuation">:</span>
    w <span class="token operator">-=</span> alpha <span class="token operator">*</span> gradient_w
    b <span class="token operator">-=</span> alpha <span class="token operator">*</span> gradient_b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure>
<blockquote>
<p>优点：适用于大数据集；可在线学习<br>缺点：需调学习率 $\alpha$，收敛较慢</p>
</blockquote>
<p>📊 时间复杂度对比</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>时间复杂度</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>正规方程法</td>
<td>$O(n^3)$</td>
<td>精确但慢</td>
</tr>
<tr>
<td>梯度下降</td>
<td>$O(knm)$（$k$ 次迭代）</td>
<td>可调，适合大数据</td>
</tr>
</tbody>
</table>
</div>
<p>📚 Python 示例代码（使用 sklearn）</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_regression

X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_regression<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> n_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> noise<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"权重:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"偏置:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>📈 可视化例子</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">房价预测：
x = 面积（㎡），y = 房价（万）
训练后模型为：y = 1.5x + 20

→ 当输入 x = 100㎡，预测 y = 170万<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p> ✅ 总结</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>项目</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>输入</td>
<td>多维特征 $\mathbf{x}$</td>
</tr>
<tr>
<td>输出</td>
<td>连续变量 $\hat{y}$</td>
</tr>
<tr>
<td>模型形式</td>
<td>线性函数：$\hat{y} = \mathbf{w}^\top \mathbf{x} + b$</td>
</tr>
<tr>
<td>损失函数</td>
<td>均方误差 MSE</td>
</tr>
<tr>
<td>求解方式</td>
<td>正规方程 or 梯度下降</td>
</tr>
<tr>
<td>适用场景</td>
<td>预测问题（价格、评分、趋势）</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/img/concepts/linear.svg" srcset="/img/loading.gif" lazyload alt="线性回归" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="逻辑回归（Logistic-Regression）"><a href="#逻辑回归（Logistic-Regression）" class="headerlink" title="逻辑回归（Logistic Regression）"></a>逻辑回归（Logistic Regression）</h3><p>逻辑回归用于预测事件发生的<strong>概率</strong>，并将其映射为 0 或 1 等类别。</p>
<blockquote>
<p><strong>目标</strong>：学习一个模型，输入特征 $\mathbf{x}$，输出 $\mathbb{P}(y = 1 \mid \mathbf{x})$。</p>
</blockquote>
<p>⚙️ 模型结构</p>
<p>逻辑回归的基本模型是：</p>
<script type="math/tex; mode=display">
\hat{y} = \sigma(\mathbf{w}^\top \mathbf{x} + b)</script><p>其中：</p>
<ul>
<li>$\mathbf{x}$ 是输入特征向量</li>
<li>$\mathbf{w}$ 是权重向量</li>
<li>$b$ 是偏置项</li>
<li>$\sigma(z)$ 是<strong>sigmoid 激活函数</strong>，将任意实数压缩到 $(0,1)$ 区间</li>
</ul>
<p>🔁 Sigmoid 函数定义：</p>
<script type="math/tex; mode=display">
\sigma(z) = \frac{1}{1 + e^{-z}}</script><p>图像如下：</p>
<ul>
<li>当 $z \gg 0$，$\sigma(z) \approx 1$</li>
<li>当 $z \ll 0$，$\sigma(z) \approx 0$</li>
<li>当 $z = 0$，$\sigma(z) = 0.5$</li>
</ul>
<p>🎯 输出解释</p>
<p>逻辑回归输出的是一个<strong>概率</strong>：</p>
<script type="math/tex; mode=display">
\hat{y} = \mathbb{P}(y = 1 \mid \mathbf{x})</script><p>决策规则（threshold）：</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">if 𝑃(y=1 | x) ≥ 0.5 → 预测为类1
else → 预测为类0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><img src="/img/concepts/logistic.svg" srcset="/img/loading.gif" lazyload alt="逻辑回归" style="max-width: 100%; height: auto;" /></p>
<p>📉 损失函数（对数似然损失）</p>
<p>使用的是<strong>对数损失函数（Log Loss）</strong>，源自最大似然估计：</p>
<script type="math/tex; mode=display">
\mathcal{L}(\mathbf{w}, b) = -\frac{1}{m} \sum_{i=1}^{m} \left[
y^{(i)} \log \hat{y}^{(i)} + (1 - y^{(i)}) \log (1 - \hat{y}^{(i)})
\right]</script><blockquote>
<ul>
<li>如果预测 $\hat{y} \to y$，损失很小；</li>
<li>如果预测相反，损失急剧上升（比如预测为 0.01 实际为 1）</li>
</ul>
</blockquote>
<p>🔁 参数求解方法：梯度下降</p>
<p>由于损失函数非线性，无法用正规方程解，需使用<strong>数值优化方法</strong>：</p>
<p>梯度更新公式（对损失函数求偏导）：</p>
<ul>
<li>对 $w_j$ 的梯度：</li>
</ul>
<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}}{\partial w_j} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)}) x_j^{(i)}</script><ul>
<li>对 $b$ 的梯度：</li>
</ul>
<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}}{\partial b} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})</script><p>更新方法：</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">w <span class="token operator">-=</span> alpha <span class="token operator">*</span> grad_w
b <span class="token operator">-=</span> alpha <span class="token operator">*</span> grad_b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p>📊 举例</p>
<p>假设我们要预测一个人是否患糖尿病：</p>
<ul>
<li>$x_1$ = 年龄，$x_2$ = BMI</li>
<li>$y \in {0, 1}$ 表示是否患病</li>
</ul>
<p>训练后模型为：</p>
<script type="math/tex; mode=display">
\hat{y} = \sigma(0.8x_1 + 1.2x_2 - 15)</script><p>✅ 优点</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>优点</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>简单高效</td>
<td>算法易于实现，计算代价低</td>
</tr>
<tr>
<td>输出概率</td>
<td>可用于风险建模、排序等任务</td>
</tr>
<tr>
<td>可解释性强</td>
<td>系数可表示每个特征对结果的影响方向与强度</td>
</tr>
<tr>
<td>可扩展为多分类 Softmax</td>
<td>支持逻辑回归的多类扩展</td>
</tr>
</tbody>
</table>
</div>
<p>⚠️ 缺点</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>缺点</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>线性可分性假设</td>
<td>不能处理复杂非线性关系</td>
</tr>
<tr>
<td>对异常值敏感</td>
<td>特征未归一化时，模型不稳定</td>
</tr>
<tr>
<td>容易欠拟合</td>
<td>如果数据不是线性可分，拟合效果差</td>
</tr>
</tbody>
</table>
</div>
<p>📚 Python 示例代码（<code>sklearn</code>）</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment"># 加载数据（仅用前两个类别做二分类）</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> load_iris<span class="token punctuation">(</span>return_X_y<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> X<span class="token punctuation">[</span>y <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span>y <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">]</span>

X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测概率:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测结果:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>🔄 与线性回归的区别</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>项目</th>
<th>线性回归</th>
<th>逻辑回归</th>
</tr>
</thead>
<tbody>
<tr>
<td>输出</td>
<td>实数</td>
<td>概率值 $\in (0, 1)$</td>
</tr>
<tr>
<td>用途</td>
<td>回归问题（连续值）</td>
<td>分类问题（二分类/多分类）</td>
</tr>
<tr>
<td>激活函数</td>
<td>无</td>
<td>Sigmoid / Softmax</td>
</tr>
<tr>
<td>损失函数</td>
<td>均方误差 MSE</td>
<td>对数损失 Log Loss</td>
</tr>
<tr>
<td>拟合方式</td>
<td>最小二乘或梯度下降</td>
<td>最大似然估计（MLE） + 梯度下降</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="Reinforcement-Learning-RL"><a href="#Reinforcement-Learning-RL" class="headerlink" title="Reinforcement Learning (RL)"></a>Reinforcement Learning (RL)</h3><p>Reinforcement Learning (RL) is a type of machine learning method whose core idea is <strong>learning the optimal policy through interaction with the environment</strong>. In simple terms, an agent interacts with an environment by taking actions, receives rewards or penalties based on the outcomes, and continuously adjusts its behavior to maximize the long-term cumulative reward.</p>
<p>Key components include:</p>
<ol>
<li><strong>Agent</strong>: The entity that performs actions.</li>
<li><strong>Environment</strong>: The external system in which the agent operates, providing feedback on actions.</li>
<li><strong>State (s)</strong>: A description of the environment at a given time.</li>
<li><strong>Action (a)</strong>: The choices the agent can make.</li>
<li><strong>Reward (r)</strong>: Immediate feedback from the environment, used to evaluate the quality of actions.</li>
<li><strong>Policy (π)</strong>: The rule the agent follows to select actions based on the state.</li>
<li><strong>Value Function (V)</strong>: Evaluates the expected future cumulative reward of a state or state-action pair.</li>
</ol>
<p>The main goal of reinforcement learning is <strong>to learn an optimal policy that allows the agent to maximize its long-term cumulative reward</strong>.</p>
<hr>
<h3 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q Learning"></a>Q Learning</h3><p>Q-Learning is a <strong>model-free</strong> algorithm in Reinforcement Learning used to learn the optimal policy. It works by learning a <strong>Q-function (Q-Value Function)</strong> that evaluates the value of each state-action pair, guiding the agent to choose actions that maximize long-term rewards.</p>
<p>Core ideas:</p>
<ol>
<li><p><strong>Q-function (Q(s, a))</strong>: Represents the <strong>expected cumulative reward</strong> of taking action <code>a</code> in state <code>s</code>.</p>
</li>
<li><p><strong>Update formula (Bellman equation)</strong>:</p>
<script type="math/tex; mode=display">
Q(s, a) \gets Q(s, a) + \alpha \big[ r + \gamma \max_{a'} Q(s', a') - Q(s, a) \big]</script><ul>
<li>$\alpha$: learning rate, controlling the update step</li>
<li>$\gamma$: discount factor, balancing immediate and future rewards</li>
<li>$r$: immediate reward received from the action</li>
<li>$s’$: the new state after taking the action</li>
</ul>
</li>
<li><p><strong>Learning process</strong>: The agent explores the environment and continuously updates the Q-values. Eventually, it converges to the optimal Q-function, allowing the agent to <strong>select the action with the maximum expected reward in each state</strong>.</p>
</li>
</ol>
<p>In short, Q-Learning is a method that enables an agent to learn the best decisions in each state through trial-and-error experience.</p>
<hr>
<h3 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h3><p>Cross validation is a method in machine learning used to <strong>evaluate model performance and prevent overfitting</strong>. It works by <strong>splitting the dataset into multiple parts, training the model on some parts, and validating it on the remaining parts</strong>, providing a more reliable estimate of how the model will perform on unseen data.</p>
<p>Core ideas:</p>
<ol>
<li><strong>Data splitting</strong>: Divide the dataset into $k$ parts (folds), commonly called <strong>k-fold cross validation</strong>.</li>
<li><p><strong>Training and validation</strong>:</p>
<ul>
<li>In each iteration, use $k-1$ folds as the training set and the remaining fold as the validation set.</li>
<li>Train the model and evaluate its performance on the validation set (e.g., accuracy, mean squared error).</li>
</ul>
</li>
<li><strong>Repeat $k$ times</strong>: Each fold serves as the validation set once.</li>
<li><strong>Aggregate results</strong>: Average the performance metrics over the $k$ iterations to get a reliable estimate of the model’s overall performance.</li>
</ol>
<p>Advantages:</p>
<ul>
<li>Provides a more stable assessment of model performance, reducing bias from a single train-test split.</li>
<li>Helps in model selection and hyperparameter tuning.</li>
</ul>
<p>Common variants:</p>
<ul>
<li><strong>Leave-One-Out CV (LOOCV)</strong>: Each iteration leaves one sample for validation.</li>
<li><strong>Stratified k-Fold CV</strong>: Maintains the proportion of each class in classification problems.</li>
</ul>
<p>In short, cross validation allows the model to <strong>“practice and test” on different data splits multiple times, yielding a more robust estimate of performance</strong>.</p>
<hr>
<h3 id="Policy-based-and-Value-based-methods"><a href="#Policy-based-and-Value-based-methods" class="headerlink" title="Policy-based and Value-based methods"></a>Policy-based and Value-based methods</h3><p>In Reinforcement Learning (RL), <strong>Policy-based</strong> and <strong>Value-based</strong> methods are two core approaches. The main difference lies in what they learn: one learns the policy directly, while the other learns the value function.</p>
<p><strong>Value-based Methods</strong></p>
<p><strong>Core idea</strong>: Learn the <strong>value function</strong> and derive the optimal policy indirectly.</p>
<ul>
<li><p><strong>Types of value functions</strong>:</p>
<ul>
<li><strong>State value function $V(s)$</strong>: Expected cumulative reward starting from state $s$.</li>
<li><strong>Action value function $Q(s, a)$</strong>: Expected cumulative reward of taking action $a$ in state $s$.</li>
</ul>
</li>
<li><p><strong>Typical algorithms</strong>:</p>
<ul>
<li>Q-Learning</li>
<li>Deep Q-Network (DQN)</li>
</ul>
</li>
<li><p><strong>Characteristics</strong>:</p>
<ul>
<li><p>Does not directly output a policy. The policy is obtained by selecting the action with the highest value in each state:</p>
<script type="math/tex; mode=display">
\pi(s) = \arg\max_a Q(s, a)</script></li>
<li>Better suited for discrete action spaces.</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Policy-based Methods</strong></p>
<p><strong>Core idea</strong>: Learn the <strong>policy function $\pi(a|s)$</strong> directly, which outputs the probability of taking each action in a given state.</p>
<ul>
<li><p><strong>Characteristics</strong>:</p>
<ul>
<li>Optimizes the policy directly without first learning a value function.</li>
<li>Naturally handles continuous action spaces.</li>
<li><p>Often uses gradient-based methods to optimize the policy:</p>
<script type="math/tex; mode=display">
\nabla_\theta J(\theta) = \mathbb{E}_{s,a \sim \pi_\theta} \Big[ \nabla_\theta \log \pi_\theta(a|s) \, Q^{\pi_\theta}(s, a) \Big]</script></li>
</ul>
</li>
<li><p><strong>Typical algorithms</strong>:</p>
<ul>
<li>REINFORCE</li>
<li>Actor-Critic (combines policy and value approaches)</li>
</ul>
</li>
</ul>
<hr>
<p>Summary Comparison</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Value-based</th>
<th>Policy-based</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Learning target</td>
<td>Value function $V$ or $Q$</td>
<td>Policy (\pi(a</td>
<td>s))</td>
</tr>
<tr>
<td>Output</td>
<td>Optimal action or action values</td>
<td>Action probability distribution</td>
<td></td>
</tr>
<tr>
<td>Action space</td>
<td>Discrete</td>
<td>Discrete or continuous</td>
<td></td>
</tr>
<tr>
<td>Advantages</td>
<td>Stable, easy to understand</td>
<td>Handles continuous actions, more flexible</td>
<td></td>
</tr>
<tr>
<td>Disadvantages</td>
<td>Hard to handle continuous actions</td>
<td>Slower convergence, higher variance</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>In short:</p>
<ul>
<li><strong>Value-based</strong>: First learn “which actions are good,” then select actions.</li>
<li><strong>Policy-based</strong>: Directly learn “what action to take in each state.”</li>
</ul>
<hr>
<h3 id="Supervised-Learning-VS-Unsupervised-Learning"><a href="#Supervised-Learning-VS-Unsupervised-Learning" class="headerlink" title="Supervised Learning VS Unsupervised Learning"></a>Supervised Learning VS Unsupervised Learning</h3><p>In Machine Learning, <strong>Supervised Learning</strong> and <strong>Unsupervised Learning</strong> are two fundamental paradigms. The main difference lies in whether the training data includes labels.</p>
<hr>
<p><strong>Supervised Learning</strong></p>
<p><strong>Definition:</strong><br>Supervised learning uses <strong>labeled data</strong> for training, allowing the model to learn the mapping between input and output. The goal is for the model to correctly predict outputs for new, unseen inputs.</p>
<p><strong>Key characteristics:</strong></p>
<ul>
<li>Training data contains inputs $X$ and corresponding labels $Y$</li>
<li>The model learns by minimizing the error between predicted outputs and true labels</li>
</ul>
<p><strong>Common tasks:</strong></p>
<ul>
<li><strong>Classification</strong>: Output is a discrete label, e.g., spam detection (spam/ham), sentiment analysis (positive/negative)</li>
<li><strong>Regression</strong>: Output is a continuous value, e.g., house price prediction, stock price forecasting</li>
</ul>
<p><strong>Typical algorithms:</strong></p>
<ul>
<li>Logistic Regression</li>
<li>Support Vector Machines (SVM)</li>
<li>Decision Trees, Random Forests</li>
<li>Neural Networks</li>
</ul>
<hr>
<p><strong>Unsupervised Learning</strong></p>
<p><strong>Definition:</strong><br>Unsupervised learning uses <strong>unlabeled data</strong> for training. The model must discover patterns, structures, or distributions in the data on its own.</p>
<p><strong>Key characteristics:</strong></p>
<ul>
<li>Training data only contains input $X$, no corresponding output</li>
<li>The model identifies patterns, similarities, or clusters in the data</li>
</ul>
<p><strong>Common tasks:</strong></p>
<ul>
<li><strong>Clustering</strong>: Grouping similar data points, e.g., customer segmentation, image grouping</li>
<li><strong>Dimensionality Reduction</strong>: Simplifying data representation, e.g., PCA, t-SNE, for visualization or feature extraction</li>
<li><strong>Anomaly Detection</strong>: Identifying outlier data points</li>
</ul>
<p><strong>Typical algorithms:</strong></p>
<ul>
<li>K-Means</li>
<li>Hierarchical Clustering</li>
<li>Principal Component Analysis (PCA)</li>
<li>Autoencoders</li>
</ul>
<hr>
<p>Summary Comparison</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Supervised Learning</th>
<th>Unsupervised Learning</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data type</td>
<td>Labeled data</td>
<td>Unlabeled data</td>
</tr>
<tr>
<td>Goal</td>
<td>Learn input-output mapping</td>
<td>Discover data structure or patterns</td>
</tr>
<tr>
<td>Output</td>
<td>Class labels or continuous values</td>
<td>Clusters, feature representations, or anomalies</td>
</tr>
<tr>
<td>Example</td>
<td>Spam detection, house price prediction</td>
<td>Customer segmentation, dimensionality reduction</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Simple intuition:</p>
<ul>
<li><strong>Supervised Learning</strong>: A teacher provides the “correct answers,” and you learn to predict.</li>
<li><strong>Unsupervised Learning</strong>: No teacher; you discover patterns on your own.</li>
</ul>
<h2 id="7-Digital-Circuit"><a href="#7-Digital-Circuit" class="headerlink" title="7. Digital Circuit"></a>7. Digital Circuit</h2><h2 id="8-Computer-Networks"><a href="#8-Computer-Networks" class="headerlink" title="8. Computer Networks"></a>8. Computer Networks</h2><h3 id="Distributed-Hash-Table-DHT"><a href="#Distributed-Hash-Table-DHT" class="headerlink" title="Distributed Hash Table (DHT)"></a>Distributed Hash Table (DHT)</h3><p>A <strong>Distributed Hash Table (DHT)</strong> is a decentralized system that provides a lookup service similar to a hash table: it stores <strong>(key, value)</strong> pairs and allows efficient retrieval of the value given a key. Instead of relying on a central server, DHT distributes the data across a network of nodes (often used in <strong>peer-to-peer networks</strong> and <strong>IoT</strong> systems).</p>
<p>Key Features:</p>
<ul>
<li><strong>Scalable</strong>: Works well even with thousands of nodes.</li>
<li><strong>Fault-tolerant</strong>: Data is replicated, so the system can handle node failures.</li>
<li><strong>Efficient</strong>: Most DHTs (like Chord or Kademlia) can find data in <strong>O(log n)</strong> time.</li>
</ul>
<p>DHTs are often used in applications like <strong>BitTorrent</strong> and <strong>distributed file systems</strong>, and are relevant in wireless and digital communication contexts, which aligns well with your research interests in IoT.</p>
<p><img src="/img/concepts/dht.svg" srcset="/img/loading.gif" lazyload alt="DHT" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Ethernet"><a href="#Ethernet" class="headerlink" title="Ethernet"></a>Ethernet</h3><p>Ethernet is a communication technology used for local area networks (LANs). It defines how computers and network devices send and receive data over a wired medium, typically twisted-pair cables or fiber optics. In brief:</p>
<ol>
<li><p><strong>Basic Principle</strong>: Ethernet uses <strong>frames</strong> as the basic unit of data transmission. Each frame contains the destination address, source address, data, and a checksum (CRC) for error detection.</p>
</li>
<li><p><strong>Communication Method</strong>: Traditional Ethernet uses <strong>CSMA/CD (Carrier Sense Multiple Access with Collision Detection)</strong> to avoid data collisions. Modern switched Ethernet largely eliminates the need for collision detection, as each port has a dedicated communication channel.</p>
</li>
<li><p><strong>Speed and Evolution</strong>: The original Ethernet speed was <strong>10 Mbps</strong>, later evolving to <strong>100 Mbps (Fast Ethernet), 1 Gbps (Gigabit Ethernet), 10 Gbps</strong>, and even higher.</p>
</li>
<li><p><strong>Applications</strong>: Ethernet is the most widely used wired LAN standard, connecting computers, servers, routers, and switches to enable data transmission within a local network.</p>
</li>
</ol>
<hr>
<h3 id="Mac-Address"><a href="#Mac-Address" class="headerlink" title="Mac Address"></a>Mac Address</h3><p>A MAC address (<strong>Media Access Control Address</strong>) is an address that uniquely identifies a network device within a <strong>local area network (LAN)</strong>. It is used in network technologies like <strong>Ethernet and Wi-Fi</strong>, operating at the <strong>data link layer (Layer 2 of the OSI model)</strong>.</p>
<p><strong>Key Points:</strong></p>
<ol>
<li><p><strong>Uniqueness</strong></p>
<ul>
<li>Each network interface card (NIC) or wireless module has a unique MAC address, usually assigned by the manufacturer.</li>
<li>It is typically 48 bits long and represented as <strong>six hexadecimal pairs</strong>, for example: <code>00:1A:2B:3C:4D:5E</code>.</li>
</ul>
</li>
<li><p><strong>Function</strong></p>
<ul>
<li>Identifies devices within a LAN.</li>
<li>Used as the <strong>source and destination address</strong> in Ethernet frames, ensuring data reaches the correct device.</li>
</ul>
</li>
<li><p><strong>Difference from IP Address</strong></p>
<ul>
<li><strong>MAC Address</strong>: Hardware address, fixed and unique within a LAN.</li>
<li><strong>IP Address</strong>: Logical address, can change with the network environment, used for routing across networks.</li>
</ul>
</li>
</ol>
<hr>
<p>💡 <strong>Analogy</strong>:</p>
<ul>
<li>A MAC address is like a <strong>house number</strong>, used to locate a specific house within a neighborhood (LAN).</li>
<li>An IP address is like the <strong>street and city address</strong>, used to find the house across cities or networks.</li>
</ul>
<hr>
<h3 id="Time-Division-Multiple-Access-TDMA"><a href="#Time-Division-Multiple-Access-TDMA" class="headerlink" title="Time Division Multiple Access (TDMA)"></a>Time Division Multiple Access (TDMA)</h3><p>In computer networks and communication systems, <strong>Time Division Multiple Access (TDMA)</strong> is a technique that allows <strong>multiple users to share the same frequency resource</strong> by dividing time into separate slots for each user.</p>
<hr>
<p><strong>Basic Concept</strong></p>
<ul>
<li><strong>TDMA principle</strong>: A frequency channel is divided into several consecutive <strong>time slots</strong>, and each user transmits data exclusively during its assigned slot.</li>
<li><strong>Core idea</strong>: Different users use the same frequency at <strong>different times</strong> to avoid collisions.</li>
</ul>
<hr>
<p><strong>Working Process</strong></p>
<ol>
<li><p><strong>Frame structure</strong>:</p>
<ul>
<li>TDMA divides the communication cycle into <strong>frames</strong>, and each frame is further divided into several <strong>time slots</strong>.</li>
<li>Each user is assigned one or more fixed time slots.</li>
</ul>
</li>
<li><p><strong>Transmission and reception</strong>:</p>
<ul>
<li>When a user’s time slot arrives, it sends data while other users remain idle or receive.</li>
<li>After the time slot ends, the next user transmits.</li>
</ul>
</li>
<li><p><strong>Synchronization requirement</strong>:</p>
<ul>
<li>Precise time synchronization is needed to ensure users transmit strictly within their own slots (via synchronization signals or clocks).</li>
</ul>
</li>
</ol>
<hr>
<p><strong>Characteristics</strong></p>
<ul>
<li><p><strong>Advantages</strong>:</p>
<ul>
<li>No interference: Users transmit at different times without colliding.</li>
<li>High spectrum efficiency: The same frequency can be shared by multiple users.</li>
<li>Simple and easy to implement, suitable for systems with a fixed number of users.</li>
</ul>
</li>
<li><p><strong>Disadvantages</strong>:</p>
<ul>
<li>High requirement for time synchronization, increasing hardware complexity.</li>
<li>If a user has no data to send, the time slot is wasted (low efficiency).</li>
<li>Not ideal for bursty traffic with unpredictable data.</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Applications</strong></p>
<ul>
<li><strong>GSM cellular networks</strong>: Each user occupies a different time slot for voice or data transmission.</li>
<li><strong>Satellite communication</strong>: Multiple users share the same uplink/downlink frequency channel.</li>
<li><strong>Industrial control networks</strong>: Periodic data collection and transmission.</li>
</ul>
<hr>
<p>Simple analogy:</p>
<blockquote>
<p>TDMA is like taking turns on a single-lane road—each person drives during their assigned time slot to avoid congestion.</p>
</blockquote>
<hr>
<h3 id="ALOHA"><a href="#ALOHA" class="headerlink" title="ALOHA"></a>ALOHA</h3><p><strong>ALOHA</strong> is an early wireless multiple access protocol that allows multiple terminals to share the same channel. Its core idea is <strong>transmit whenever you have data, and retransmit if a collision occurs</strong>.</p>
<hr>
<p><strong>Basic Principle</strong></p>
<ul>
<li>Each terminal <strong>sends a data frame immediately</strong> when it has data.</li>
<li>If two terminals transmit simultaneously, a <strong>collision</strong> occurs.</li>
<li>After a collision, the terminal waits for a random time before <strong>retransmitting</strong> the data.</li>
</ul>
<hr>
<p><strong>Characteristics</strong></p>
<ul>
<li><p><strong>Advantages</strong>:</p>
<ul>
<li>Simple and easy to implement</li>
<li>No complex scheduling mechanism required</li>
</ul>
</li>
<li><p><strong>Disadvantages</strong>:</p>
<ul>
<li>Low spectrum efficiency (high collision rate)</li>
<li>Efficiency drops significantly as the number of terminals increases</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Improved Versions</strong></p>
<ul>
<li><strong>Pure ALOHA</strong>: Terminals transmit whenever they have data; if a collision occurs, they retransmit after a random delay.</li>
<li><strong>Slotted ALOHA</strong>: Time is divided into fixed slots, and terminals can only transmit at the beginning of a slot, reducing the collision probability by half.</li>
</ul>
<hr>
<p>Simple analogy:</p>
<blockquote>
<p>Pure ALOHA is like everyone speaking on the same channel whenever they want—if they speak at the same time, a collision occurs and they retry. Slotted ALOHA is like everyone taking turns speaking in time slots, reducing the chance of collisions.</p>
</blockquote>
<h2 id="9-Cryptography"><a href="#9-Cryptography" class="headerlink" title="9. Cryptography"></a>9. Cryptography</h2><h3 id="🔐-Digital-Signatures"><a href="#🔐-Digital-Signatures" class="headerlink" title="🔐 Digital Signatures"></a>🔐 Digital Signatures</h3><p>A <strong>digital signature</strong> is a <strong>cryptographic technique</strong> used to <strong>verify the authenticity and integrity</strong> of a digital message or document.<br>It is a <strong>secure form of electronic signature</strong> based on <strong>public-key cryptography</strong>.</p>
<p><strong>🛠️ How It Works</strong></p>
<ol>
<li>The sender signs the document using a <strong>private key</strong>.</li>
<li>The recipient verifies the signature using the sender’s <strong>public key</strong>.</li>
<li><p>If the verification succeeds, the document:</p>
<ul>
<li><strong>Came from the sender</strong></li>
<li><strong>Was not altered</strong> in transit</li>
</ul>
</li>
</ol>
<p><strong>✅ Key Properties</strong></p>
<ul>
<li><strong>Authentication</strong>: Confirms the sender’s identity</li>
<li><strong>Integrity</strong>: Ensures the content has not been tampered with</li>
<li><strong>Non-repudiation</strong>: The sender cannot deny having signed it</li>
</ul>
<p><strong>📌 Common Use Cases</strong></p>
<ul>
<li>Signing software and updates</li>
<li>Securing emails (e.g., with S/MIME or PGP)</li>
<li>Digital contracts and government forms</li>
<li>Blockchain and cryptocurrencies (e.g., Bitcoin transactions)</li>
</ul>
<h2 id="10-Digital-Signal-Processing"><a href="#10-Digital-Signal-Processing" class="headerlink" title="10. Digital Signal Processing"></a>10. Digital Signal Processing</h2><h2 id="11-Control-Engineering"><a href="#11-Control-Engineering" class="headerlink" title="11. Control Engineering"></a>11. Control Engineering</h2><h2 id="12-Software-Development"><a href="#12-Software-Development" class="headerlink" title="12. Software Development"></a>12. Software Development</h2><h2 id="13-Robotics"><a href="#13-Robotics" class="headerlink" title="13. Robotics"></a>13. Robotics</h2><h2 id="14-Numerical-Computing"><a href="#14-Numerical-Computing" class="headerlink" title="14. Numerical Computing"></a>14. Numerical Computing</h2><h3 id="💥-Loss-of-Significance"><a href="#💥-Loss-of-Significance" class="headerlink" title="💥 Loss of Significance"></a>💥 Loss of Significance</h3><p><strong>Definition</strong>:<br>Loss of significance occurs when <strong>two nearly equal numbers are subtracted</strong>, causing the <strong>most significant digits to cancel out</strong>, leaving behind only less significant digits. This results in a <strong>large relative error</strong> due to the limited precision of floating-point arithmetic.</p>
<p><strong>Example</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Let a = 123456.78
    b = 123456.71
Then a - b = 0.07 (correct result)

However, in floating-point representation (with limited digits):
    a ≈ 1.2345678 × 10^5
    b ≈ 1.2345671 × 10^5

The subtraction may cause significant digit loss!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p><strong>Why it matters</strong>:</p>
<ul>
<li>It reduces <strong>numerical accuracy</strong>.</li>
<li>It’s especially dangerous in algorithms involving derivatives, roots, or iterative methods.</li>
</ul>
<p><strong>Typical scenario</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">f(x) = (1 - cos(x)) / x^2, when x → 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>This can lead to significant errors because <code>1 - cos(x)</code> is a subtraction of two nearly equal numbers.</p>
<hr>
<h3 id="🧮-Loss-of-Trailing-Digits"><a href="#🧮-Loss-of-Trailing-Digits" class="headerlink" title="🧮 Loss of Trailing Digits"></a>🧮 Loss of Trailing Digits</h3><p><strong>Definition</strong>:<br>Loss of trailing digits occurs when a <strong>large and a small number are added together</strong>, and the <strong>small number is too small to affect the sum</strong> due to the limits of floating-point precision.</p>
<p><strong>Example</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Let a = 1.000000000000000
    b = 0.000000000000001

In floating-point (double precision), a + b ≈ 1.000000000000000
The small value of b is 'lost' — this is loss of trailing digits.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p><strong>Why it matters</strong>:</p>
<ul>
<li>It causes <strong>rounding errors</strong> in accumulation.</li>
<li>In long summation processes (e.g., numerical integration), many small contributions may be <strong>entirely ignored</strong>.</li>
</ul>
<hr>
<p><strong>🧠 Summary Table</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Concept</th>
<th>Trigger</th>
<th>Effect</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Loss of Significance</strong></td>
<td>Subtraction of close numbers</td>
<td>Large <strong>relative error</strong></td>
<td><code>(1 - cos(x)) / x^2</code></td>
</tr>
<tr>
<td><strong>Loss of Trailing Digits</strong></td>
<td>Addition of large + small number</td>
<td>Small number gets ignored</td>
<td><code>1.0 + 1e-15 = 1.0</code></td>
</tr>
</tbody>
</table>
</div>
<h2 id="15-Information-Theory"><a href="#15-Information-Theory" class="headerlink" title="15. Information Theory"></a>15. Information Theory</h2><h3 id="📦-Run-Length-Encoding-RLE"><a href="#📦-Run-Length-Encoding-RLE" class="headerlink" title="📦 Run-Length Encoding (RLE)"></a>📦 Run-Length Encoding (RLE)</h3><p><strong>🧠 What is it?</strong></p>
<p><strong>Run-Length Encoding</strong> is a <strong>lossless compression algorithm</strong> that works by compressing sequences of repeated data elements (called <strong>runs</strong>) into a single value and a count.</p>
<p><strong>⚙️ How it works</strong></p>
<p>When the same character appears multiple times in a row, RLE replaces it with a single character and the number of repetitions.</p>
<p><strong>✅ Example</strong></p>
<p>Original data:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">AAAAABBBCCDAA<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>RLE encoded:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">5A3B2C1D2A<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>This means:</p>
<ul>
<li>5 A’s</li>
<li>3 B’s</li>
<li>2 C’s</li>
<li>1 D</li>
<li>2 A’s</li>
</ul>
<p><strong>📌 Use Cases</strong></p>
<ul>
<li>Bitmap image compression (e.g., simple black and white images)</li>
<li>Fax machines</li>
<li>Data with lots of repetition</li>
</ul>
<p><strong>⚠️ Limitation</strong></p>
<ul>
<li>Not efficient if the data doesn’t have many repeated characters (may even increase size).</li>
</ul>
<hr>
<h3 id="🌲-Huffman-Encoding"><a href="#🌲-Huffman-Encoding" class="headerlink" title="🌲 Huffman Encoding"></a>🌲 Huffman Encoding</h3><p><strong>🧠 What is it?</strong></p>
<p><strong>Huffman Encoding</strong> is a <strong>lossless compression technique</strong> that assigns <strong>variable-length binary codes</strong> to characters based on their <strong>frequency</strong>. More frequent characters get <strong>shorter codes</strong>, while less frequent ones get <strong>longer codes</strong>.</p>
<p><strong>⚙️ How it works</strong></p>
<ol>
<li>Count the frequency of each character.</li>
<li>Build a <strong>Huffman Tree</strong> using a greedy algorithm.</li>
<li>Assign binary codes to characters by traversing the tree.</li>
</ol>
<p><strong>✅ Example</strong></p>
<p>Given character frequencies:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">A: 45%, B: 13%, C: 12%, D: 16%, E: 14%<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Possible Huffman codes:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">A: 0
B: 101
C: 100
D: 111
E: 110<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>More frequent characters like <code>A</code> get shorter codes.</p>
<p><strong>📌 Use Cases</strong></p>
<ul>
<li>JPEG and PNG image compression</li>
<li>MP3 and audio compression</li>
<li>ZIP file compression</li>
<li>Data transmission and storage</li>
</ul>
<p><strong>⚠️ Limitation</strong></p>
<ul>
<li>Needs to store or transmit the code table (or tree structure).</li>
<li>Slightly more complex to implement than RLE.</li>
</ul>
<p><strong>🧾 Comparison Table</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Run-Length Encoding</th>
<th>Huffman Encoding</th>
</tr>
</thead>
<tbody>
<tr>
<td>Type</td>
<td>Lossless</td>
<td>Lossless</td>
</tr>
<tr>
<td>Strategy</td>
<td>Compress repeated values</td>
<td>Compress based on frequency</td>
</tr>
<tr>
<td>Best for</td>
<td>Repetitive data</td>
<td>Skewed frequency distributions</td>
</tr>
<tr>
<td>Efficiency</td>
<td>Very simple, fast</td>
<td>More efficient, more complex</td>
</tr>
<tr>
<td>Limitation</td>
<td>Ineffective for random data</td>
<td>Tree must be constructed</td>
</tr>
</tbody>
</table>
</div>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%B8%93%E4%B8%9A%E7%A7%91%E7%9B%AE%E7%AC%94%E8%AE%B0/" class="category-chain-item">专业科目笔记</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E4%BF%AE%E8%80%83/" class="print-no-link">#修考</a>
      
        <a href="/tags/CS-Concepts/" class="print-no-link">#CS Concepts</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CS Concepts</div>
      <div>http://toutou.zeabur.app/2025/02/09/CS-Concepts/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>toutou</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>February 9, 2025</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - Non-commercial">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - Share-alike">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/02/21/Calculus/" title="Calculus">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Calculus</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/02/09/computer-networks/" title="Computer Networks">
                        <span class="hidden-mobile">Computer Networks</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://www.instagram.com/hanni_rio/" target="_blank" rel="nofollow noopener"><span>Hanni Rio</span></a> <i class="iconfont icon-copyright"></i> <a href="https://toutou.pro/" target="_blank" rel="nofollow noopener"><span>toutou</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script  src="https://lib.baomitu.com/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.js" ></script>

  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
