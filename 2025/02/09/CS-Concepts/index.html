

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/logo.png">
  <link rel="icon" href="/img/logo.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="toutou">
  <meta name="keywords" content="">
  
    <meta name="description" content="CS ConceptsÊú¨Á´†Á¨îËÆ∞ÁùÄÈáçÂØπCSÁõ∏ÂÖ≥‰∏ì‰∏öÁßëÁõÆÁöÑÂêçËØçËøõË°åËß£ÈáäÔºåÂú®‰øÆËÄÉÈóÆÁ≠îÈ¢òÂíåÈù¢ËØïÂÖ´ËÇ°ÊñáÂú∫ÊôØ‰∏ãÈÄÇÁî®„ÄÇËøô‰∫õÂêçËØçÈÉΩÊù•Ê∫ê‰∫éCSÁõ∏ÂÖ≥Â≠¶Áßë„ÄÇÊú¨ÁØáÁ¨îËÆ∞ÂÜÖÂÆπÊåâÁßëÁõÆÂàíÂàÜÔºåÊØè‰∏™ÁßëÁõÆ‰∏ãÈù¢ÊúâÂØπÂ∫îÁöÑÂ∏∏ËßÅÈ´òÈ¢ëÂêçËØçËß£ÈáäÔºà‰∏≠&#x2F;Ëã±Ôºâ„ÄÇ 1. Data Stucture &amp; AlgorithmsHash TableA Hash Table is a data structure that maps keys to va">
<meta property="og:type" content="article">
<meta property="og:title" content="CS Concepts">
<meta property="og:url" content="http://toutou.zeabur.app/2025/02/09/CS-Concepts/index.html">
<meta property="og:site_name" content="ÂÅ∑ÂÅ∑ÊòüÁêÉ">
<meta property="og:description" content="CS ConceptsÊú¨Á´†Á¨îËÆ∞ÁùÄÈáçÂØπCSÁõ∏ÂÖ≥‰∏ì‰∏öÁßëÁõÆÁöÑÂêçËØçËøõË°åËß£ÈáäÔºåÂú®‰øÆËÄÉÈóÆÁ≠îÈ¢òÂíåÈù¢ËØïÂÖ´ËÇ°ÊñáÂú∫ÊôØ‰∏ãÈÄÇÁî®„ÄÇËøô‰∫õÂêçËØçÈÉΩÊù•Ê∫ê‰∫éCSÁõ∏ÂÖ≥Â≠¶Áßë„ÄÇÊú¨ÁØáÁ¨îËÆ∞ÂÜÖÂÆπÊåâÁßëÁõÆÂàíÂàÜÔºåÊØè‰∏™ÁßëÁõÆ‰∏ãÈù¢ÊúâÂØπÂ∫îÁöÑÂ∏∏ËßÅÈ´òÈ¢ëÂêçËØçËß£ÈáäÔºà‰∏≠&#x2F;Ëã±Ôºâ„ÄÇ 1. Data Stucture &amp; AlgorithmsHash TableA Hash Table is a data structure that maps keys to va">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/hash.jpg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/hash2.jpg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/pnp.jpg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/tsp.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/bnb.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/btree.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/astar.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/minimax.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/process.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/dynamic_branch.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/parallelism.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/wb.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/multicache.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/cache3.jpg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/superscalar.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/tlb.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/random.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/linear.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/logistic.svg">
<meta property="og:image" content="http://toutou.zeabur.app/img/concepts/dht.svg">
<meta property="article:published_time" content="2025-02-09T15:25:17.000Z">
<meta property="article:modified_time" content="2025-08-17T17:39:06.135Z">
<meta property="article:author" content="toutou">
<meta property="article:tag" content="‰øÆËÄÉ">
<meta property="article:tag" content="CS Concepts">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://toutou.zeabur.app/img/concepts/hash.jpg">
  
  
  
  <title>CS Concepts - ÂÅ∑ÂÅ∑ÊòüÁêÉ</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ‰∏ªÈ¢ò‰æùËµñÁöÑÂõæÊ†áÂ∫ìÔºå‰∏çË¶ÅËá™Ë°å‰øÆÊîπ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"toutou.zeabur.app","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ÂÅ∑ÂÅ∑ÊòüÁêÉ</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/wall.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="CS Concepts"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-02-09 23:25" pubdate>
          February 9, 2025 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.1k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          60 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">CS Concepts</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="CS-Concepts"><a href="#CS-Concepts" class="headerlink" title="CS Concepts"></a>CS Concepts</h1><p>Êú¨Á´†Á¨îËÆ∞ÁùÄÈáçÂØπCSÁõ∏ÂÖ≥‰∏ì‰∏öÁßëÁõÆÁöÑÂêçËØçËøõË°åËß£ÈáäÔºåÂú®‰øÆËÄÉÈóÆÁ≠îÈ¢òÂíåÈù¢ËØïÂÖ´ËÇ°ÊñáÂú∫ÊôØ‰∏ãÈÄÇÁî®„ÄÇËøô‰∫õÂêçËØçÈÉΩÊù•Ê∫ê‰∫éCSÁõ∏ÂÖ≥Â≠¶Áßë„ÄÇÊú¨ÁØáÁ¨îËÆ∞ÂÜÖÂÆπÊåâÁßëÁõÆÂàíÂàÜÔºåÊØè‰∏™ÁßëÁõÆ‰∏ãÈù¢ÊúâÂØπÂ∫îÁöÑÂ∏∏ËßÅÈ´òÈ¢ëÂêçËØçËß£ÈáäÔºà‰∏≠/Ëã±Ôºâ„ÄÇ</p>
<h2 id="1-Data-Stucture-amp-Algorithms"><a href="#1-Data-Stucture-amp-Algorithms" class="headerlink" title="1. Data Stucture &amp; Algorithms"></a>1. Data Stucture &amp; Algorithms</h2><h3 id="Hash-Table"><a href="#Hash-Table" class="headerlink" title="Hash Table"></a>Hash Table</h3><p>A Hash Table is a data structure that maps keys to values using a hash function. It stores data in an array-like structure, where each key is hashed to an index. Collisions (when different keys map to the same index) are handled using techniques like chaining or open addressing. Hash tables provide average O(1) time complexity for insertion, deletion, and lookup. They are widely used in databases, caching, and symbol tables.<br><img src="/img/concepts/hash.jpg" srcset="/img/loading.gif" lazyload alt="Hash Table" style="max-width: 70%; height: auto;" /></p>
<hr>
<h3 id="Hash-Collision-Hash-Clash"><a href="#Hash-Collision-Hash-Clash" class="headerlink" title="Hash Collision / Hash Clash"></a>Hash Collision / Hash Clash</h3><p>A <strong>hash collision (hash clash)</strong> occurs when two different inputs produce the same hash value in a hash function. Since hash functions map a large input space to a smaller output space, collisions are inevitable due to the <strong>pigeonhole principle</strong>. Collisions can weaken security in cryptographic hashes (e.g., MD5, SHA-1) and reduce efficiency in hash tables. Techniques like <strong>chaining, open addressing, and better hash functions</strong> help mitigate collisions. Stronger cryptographic hashes (e.g., SHA-256) minimize the risk of intentional hash clashes (collision attacks).</p>
<hr>
<h3 id="Open-Addressing-Closed-Hashing"><a href="#Open-Addressing-Closed-Hashing" class="headerlink" title="Open Addressing / Closed Hashing"></a>Open Addressing / Closed Hashing</h3><p><strong>Open addressing</strong> is a collision resolution technique in hash tables where all elements are stored directly in the table without external chaining. When a collision occurs, the algorithm searches for the next available slot using a probing sequence (e.g., <strong>linear probing, quadratic probing, or double hashing</strong>). <strong>Linear probing</strong> checks the next slot sequentially, <strong>quadratic probing</strong> uses a quadratic function to find slots, and <strong>double hashing</strong> applies a second hash function for probing. Open addressing avoids linked lists, reducing memory overhead but may suffer from clustering. It works best when the load factor is kept low to maintain efficient lookups.</p>
<hr>
<h3 id="Seperate-Chaining"><a href="#Seperate-Chaining" class="headerlink" title="Seperate Chaining"></a>Seperate Chaining</h3><p><strong>Separate chaining</strong> is a collision resolution technique in hash tables where each bucket stores multiple values using a linked list (or another data structure like a BST). When a collision occurs, the new element is simply added to the linked list at that index. This method allows the table to handle an unlimited number of collisions but increases memory usage. Performance depends on the length of the chains; with a well-distributed hash function, the average lookup time remains <strong>O(1) in best case</strong> and <strong>O(n) in worst case</strong>. <strong>Rehashing</strong> or using a larger table can help maintain efficiency.</p>
<p><img src="/img/concepts/hash2.jpg" srcset="/img/loading.gif" lazyload alt="Hash Table" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="P-‚â†-NP"><a href="#P-‚â†-NP" class="headerlink" title="P ‚â† NP"></a>P ‚â† NP</h3><p><strong>P ‚â† NP</strong> means that not all problems whose solutions can be <em>verified quickly</em> (in polynomial time) can also be <em>solved quickly</em>.<br><strong>P</strong> is the class of problems that can be <strong>solved</strong> in polynomial time.<br><strong>NP</strong> is the class of problems whose solutions can be <strong>verified</strong> in polynomial time.<br>The question is: if a problem‚Äôs solution can be verified quickly, can it also be found quickly?<br>Most experts believe <strong>P ‚â† NP</strong>, but it has not been proven yet.</p>
<p><img src="/img/concepts/pnp.jpg" srcset="/img/loading.gif" lazyload alt="Hash Table" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="NP-Hard-Problems"><a href="#NP-Hard-Problems" class="headerlink" title="NP Hard Problems"></a>NP Hard Problems</h3><p>NP-Hard problems are computational problems that are at least as difficult as the hardest problems in NP (nondeterministic polynomial time). Solving an NP-Hard problem quickly would mean we could solve every NP problem quickly too, but no such efficient solution is known. These problems may not even have verifiable solutions in polynomial time. They often involve optimization or decision-making with many possibilities, like scheduling, routing, or packing.Examples include the Traveling Salesman Problem and Knapsack Problem.</p>
<hr>
<h3 id="NP-Complete-Problems"><a href="#NP-Complete-Problems" class="headerlink" title="NP-Complete Problems"></a>NP-Complete Problems</h3><p><strong>NP-Complete problems</strong> are a special class of problems that are both:</p>
<ol>
<li><strong>In NP</strong> ‚Äì their solutions can be verified in polynomial time, and</li>
<li><strong>NP-Hard</strong> ‚Äì as hard as the hardest problems in NP.</li>
</ol>
<p>If you can solve any NP-Complete problem quickly (in polynomial time), you can solve <em>all</em> NP problems quickly. Famous examples include the <strong>Boolean Satisfiability Problem (SAT)</strong> and <strong>Traveling Salesman Problem (decision version)</strong>.</p>
<hr>
<h3 id="The-Travelling-Salesman-Problem"><a href="#The-Travelling-Salesman-Problem" class="headerlink" title="The Travelling Salesman Problem"></a>The Travelling Salesman Problem</h3><p>The <strong>Travelling Salesman Problem (TSP)</strong> asks for the shortest possible route that visits each city once and returns to the starting city.<br>It is a classic <strong>combinatorial optimization</strong> problem in computer science and operations research.<br>TSP is <strong>NP-hard</strong>, meaning there‚Äôs no known efficient algorithm to solve all cases quickly.<br>Exact solutions use methods like <strong>brute force</strong>, <strong>dynamic programming</strong>, or <strong>branch and bound</strong>.<br>Approximation and heuristic algorithms (e.g. genetic algorithms, simulated annealing) are used for large instances.</p>
<p><img src="/img/concepts/tsp.svg" srcset="/img/loading.gif" lazyload alt="TSP" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="The-Knapsack-Problem"><a href="#The-Knapsack-Problem" class="headerlink" title="The Knapsack Problem"></a>The Knapsack Problem</h3><p>The <strong>Knapsack Problem</strong> asks how to choose items with given weights and values to maximize total value without exceeding a weight limit.<br>Each item can be either included or excluded (0-1 Knapsack).<br>It‚Äôs a classic <strong>NP-hard</strong> optimization problem.<br>Dynamic programming is commonly used for exact solutions.<br>Greedy or approximation methods are used for large instances.</p>
<hr>
<h3 id="The-SAT-Boolean-Satisfiability-problem"><a href="#The-SAT-Boolean-Satisfiability-problem" class="headerlink" title="The SAT (Boolean Satisfiability) problem"></a>The SAT (Boolean Satisfiability) problem</h3><p>The <strong>SAT (Boolean Satisfiability)</strong> problem asks whether there exists an assignment of true/false values to variables that makes a Boolean formula true.<br>It‚Äôs the <strong>first problem proven to be NP-complete</strong>.<br>The formula is usually given in <strong>CNF (Conjunctive Normal Form)</strong>.<br>SAT solvers use techniques like backtracking and clause learning.<br>Many real-world problems (e.g. planning, verification) can be reduced to SAT.</p>
<hr>
<h3 id="Divide-and-Conquer"><a href="#Divide-and-Conquer" class="headerlink" title="Divide and Conquer"></a>Divide and Conquer</h3><p><strong>Divide and Conquer</strong> is a problem-solving strategy that works in three main steps:</p>
<ol>
<li><strong>Divide</strong> the problem into smaller sub-problems of the same type.</li>
<li><strong>Conquer</strong> each sub-problem by solving them recursively.</li>
<li><strong>Combine</strong> the solutions of sub-problems to get the final result.</li>
</ol>
<p>Classic examples include <strong>Merge Sort</strong>, <strong>Quick Sort</strong>, and <strong>Binary Search</strong>.</p>
<hr>
<h3 id="Branch-and-Bound"><a href="#Branch-and-Bound" class="headerlink" title="Branch and Bound"></a>Branch and Bound</h3><p>Branch and Bound is an algorithmic paradigm for solving combinatorial optimization problems efficiently. It systematically divides the solution space into smaller subproblems (branching) and computes bounds to eliminate unpromising branches early (pruning). The method maintains an upper bound from feasible solutions and a lower bound from relaxed problems, allowing it to discard branches that cannot contain the optimal solution. This approach significantly reduces the search space compared to exhaustive enumeration, making it effective for problems like integer programming, traveling salesman, and knapsack problems.</p>
<p><img src="/img/concepts/bnb.svg" srcset="/img/loading.gif" lazyload alt="Branch and Bound" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="B-tree"><a href="#B-tree" class="headerlink" title="B-tree"></a>B-tree</h3><p>A <strong>B-tree</strong> is a self-balancing search tree that maintains sorted data for efficient insertion, deletion, and search in <strong>O(log n)</strong> time.<br>It allows each node to have <strong>multiple keys and children</strong>, making it wider and shallower than binary trees.<br>All leaf nodes are at the same level, ensuring the tree stays balanced.<br>It‚Äôs widely used in <strong>databases and file systems</strong> for fast disk-based access.</p>
<p><img src="/img/concepts/btree.svg" srcset="/img/loading.gif" lazyload alt="Hash Table" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Heap-Sort"><a href="#Heap-Sort" class="headerlink" title="Heap Sort"></a>Heap Sort</h3><p><strong>Heap Sort</strong> is a comparison-based sorting algorithm that uses a <strong>binary heap</strong> data structure. It works in two main steps:</p>
<ol>
<li><strong>Build a Max Heap</strong> from the input data so that the largest element is at the root.</li>
<li><strong>Extract the root (maximum element)</strong>, swap it with the last item, reduce the heap size, and <strong>heapify</strong> the root to maintain the max heap. Repeat until the heap is empty.</li>
</ol>
<p>Time Complexity: <strong>Best, Average, Worst:</strong> O(n log n)</p>
<p>Key Characteristics:</p>
<ul>
<li><strong>In-place</strong> sorting (no extra space needed)</li>
<li><strong>Not stable</strong></li>
<li>Good for scenarios where memory is limited and performance is important.</li>
</ul>
<hr>
<h3 id="Merge-Sort"><a href="#Merge-Sort" class="headerlink" title="Merge Sort"></a>Merge Sort</h3><p><strong>Merge Sort</strong> is a <strong>divide and conquer</strong> sorting algorithm that divides the input array into smaller parts, sorts them, and then merges the sorted parts.</p>
<p>Steps:</p>
<ol>
<li><strong>Divide</strong> the array into two halves.</li>
<li><strong>Recursively sort</strong> each half.</li>
<li><strong>Merge</strong> the two sorted halves into one sorted array.</li>
</ol>
<p>Time Complexity:</p>
<ul>
<li><strong>Best, Average, Worst:</strong> O(n log n)</li>
</ul>
<p>Key Characteristics:</p>
<ul>
<li><strong>Stable</strong> sort</li>
<li><strong>Not in-place</strong> (uses extra space for merging)</li>
<li>Great for sorting linked lists or large datasets with consistent performance.</li>
</ul>
<hr>
<h3 id="Quick-Sort"><a href="#Quick-Sort" class="headerlink" title="Quick Sort"></a>Quick Sort</h3><p><strong>Quick Sort</strong> is a <strong>divide and conquer</strong> sorting algorithm that works by selecting a <strong>pivot</strong> element and partitioning the array into two parts:</p>
<p>Steps:</p>
<ol>
<li><strong>Choose a pivot</strong> (e.g., first, last, or random element).</li>
<li><strong>Partition</strong> the array: elements less than pivot go left, greater go right.</li>
<li><strong>Recursively apply</strong> Quick Sort to the left and right parts.</li>
</ol>
<p>Time Complexity:</p>
<ul>
<li><strong>Best &amp; Average:</strong> O(n log n)</li>
<li><strong>Worst (unbalanced partition):</strong> O(n¬≤)</li>
</ul>
<p>Key Characteristics:</p>
<ul>
<li><strong>In-place</strong></li>
<li><strong>Not stable</strong></li>
<li>Very fast in practice with good pivot selection</li>
</ul>
<hr>
<h3 id="A-Algorithm"><a href="#A-Algorithm" class="headerlink" title="A* Algorithm"></a>A* Algorithm</h3><p>The A* algorithm finds the shortest path by combining actual cost from the start (g) and estimated cost to the goal (h).<br>It selects nodes with the lowest total cost <code>f(n) = g(n) + h(n)</code>.<br>It uses a priority queue to explore the most promising paths first.<br>The heuristic <code>h(n)</code> must not overestimate to ensure optimality.<br>It‚Äôs widely used in games, maps, and AI for efficient pathfinding.</p>
<p><img src="/img/concepts/astar.svg" srcset="/img/loading.gif" lazyload alt="A* Algorithm" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Minimax-Algorithm"><a href="#Minimax-Algorithm" class="headerlink" title="Minimax Algorithm"></a>Minimax Algorithm</h3><p>The <strong>Minimax algorithm</strong> is used in two-player games to find the optimal move by assuming both players play optimally.<br>It recursively explores all possible moves, maximizing the player‚Äôs score and minimizing the opponent‚Äôs.<br>‚ÄúMax‚Äù tries to get the highest score; ‚ÄúMin‚Äù tries to get the lowest.<br>The game tree is evaluated using a scoring function at terminal states.<br>It‚Äôs often optimized with <strong>alpha-beta pruning</strong> to skip unnecessary branches.</p>
<p><img src="/img/concepts/minimax.svg" srcset="/img/loading.gif" lazyload alt="Minimax Algorithm" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="ü§ñ-Alpha-Beta-Pruning"><a href="#ü§ñ-Alpha-Beta-Pruning" class="headerlink" title="ü§ñ Alpha-Beta Pruning"></a>ü§ñ Alpha-Beta Pruning</h3><p><strong>Alpha-Beta Pruning</strong> is an <strong>optimization technique</strong> for the <strong>Minimax algorithm</strong> used in <strong>two-player games</strong> (like chess or tic-tac-toe).<br>It <strong>reduces the number of nodes</strong> evaluated in the game tree <strong>without affecting the final result</strong>.</p>
<p><strong>üß† How It Works</strong></p>
<ul>
<li><strong>Alpha (Œ±):</strong> the best <strong>already explored</strong> value for the <strong>maximizing</strong> player.</li>
<li><strong>Beta (Œ≤):</strong> the best <strong>already explored</strong> value for the <strong>minimizing</strong> player.</li>
</ul>
<p>While traversing the tree:</p>
<ul>
<li>If the <strong>current branch</strong> cannot possibly influence the final decision (because it‚Äôs worse than previously examined branches), it is <strong>pruned</strong> (skipped).</li>
</ul>
<p><strong>‚úÖ Benefits</strong></p>
<ul>
<li>Same result as Minimax, but faster</li>
<li>Reduces time complexity from <strong>O(b^d)</strong> to <strong>O(b^(d/2))</strong> in the best case<br>(where <code>b</code> is branching factor, <code>d</code> is depth)</li>
</ul>
<p><strong>üìå Example</strong></p>
<p>In a minimax tree:</p>
<ul>
<li>If a <strong>max node</strong> finds a value <strong>‚â• Œ≤</strong>, it <strong>stops</strong> exploring further children.</li>
<li>If a <strong>min node</strong> finds a value <strong>‚â§ Œ±</strong>, it <strong>prunes</strong> the remaining branches.</li>
</ul>
<p><strong>üéØ Use Cases</strong></p>
<ul>
<li>AI game engines</li>
<li>Decision-making in adversarial environments</li>
<li>Game tree search optimization</li>
</ul>
<h2 id="2-Operating-System"><a href="#2-Operating-System" class="headerlink" title="2. Operating System"></a>2. Operating System</h2><h3 id="Procss-amp-Thread"><a href="#Procss-amp-Thread" class="headerlink" title="Procss &amp; Thread"></a>Procss &amp; Thread</h3><p>A process is the basic unit of resource allocation and scheduling in an operating system, with its own independent address space and resources. A thread is the basic unit of CPU scheduling, and a process can contain multiple threads that share the process‚Äôs memory and resources. Threads switch faster and have lower overhead, making them suitable for concurrent execution. In contrast, processes are independent of each other, with higher switching overhead but greater stability. While multithreading improves execution efficiency, it also introduces challenges such as synchronization and mutual exclusion.</p>
<p><img src="/img/concepts/process.svg" srcset="/img/loading.gif" lazyload alt="Process & Thread" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h3><p>A <strong>semaphore</strong> in an operating system is a synchronization tool used to manage <strong>concurrent access to shared resources</strong> by multiple processes or threads.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li>It is an <strong>integer variable</strong> that controls access based on its value.</li>
<li><p>There are two main operations:</p>
<ul>
<li><strong>wait (P)</strong>: Decreases the semaphore value. If the result is negative, the process is blocked.</li>
<li><strong>signal (V)</strong>: Increases the semaphore value. If there are blocked processes, one is unblocked.</li>
</ul>
</li>
</ul>
<p><strong>Types:</strong></p>
<ol>
<li><strong>Binary Semaphore</strong>: Takes values 0 or 1, similar to a mutex.</li>
<li><strong>Counting Semaphore</strong>: Can take non-negative integer values, used to control access to a resource with multiple instances.</li>
</ol>
<p><strong>Use Case:</strong></p>
<p>Semaphores help <strong>avoid race conditions</strong>, <strong>deadlocks</strong>, and ensure <strong>mutual exclusion</strong> in critical sections.</p>
<p>Example use: Controlling access to a printer shared by multiple processes.</p>
<hr>
<h3 id="Critical-Section"><a href="#Critical-Section" class="headerlink" title="Critical Section"></a>Critical Section</h3><p>A <strong>Critical Section</strong> in an operating system is a part of a program where a <strong>shared resource</strong> (like a variable, file, or device) is accessed. Since shared resources can be corrupted if accessed by multiple processes or threads simultaneously, <strong>only one process should enter the critical section at a time</strong>.</p>
<p><strong>Key Concepts:</strong></p>
<ul>
<li><strong>Mutual Exclusion</strong>: Ensures that only one process is in the critical section at any given time.</li>
<li><strong>Entry Section</strong>: Code that requests entry to the critical section.</li>
<li><strong>Exit Section</strong>: Code that signals the process is leaving the critical section.</li>
<li><strong>Remainder Section</strong>: All other code outside the critical section.</li>
</ul>
<blockquote>
<p>Goals of Critical Section Management:</p>
</blockquote>
<ol>
<li><strong>Mutual Exclusion</strong> ‚Äì Only one process in the critical section at a time.</li>
<li><strong>Progress</strong> ‚Äì If no process is in the critical section, one of the waiting processes should be allowed to enter.</li>
<li><strong>Bounded Waiting</strong> ‚Äì A process should not wait forever to enter the critical section.</li>
</ol>
<p><strong>Tools Used:</strong></p>
<ul>
<li><strong>Semaphores</strong></li>
<li><strong>Mutexes</strong></li>
<li><strong>Monitors</strong></li>
<li><strong>Locks</strong></li>
</ul>
<p>These tools help implement and manage access to critical sections safely.</p>
<hr>
<h2 id="3-Computer-Architecture"><a href="#3-Computer-Architecture" class="headerlink" title="3. Computer Architecture"></a>3. Computer Architecture</h2><h3 id="Pipeline-hazard"><a href="#Pipeline-hazard" class="headerlink" title="Pipeline hazard"></a>Pipeline hazard</h3><p>A <strong>pipeline hazard</strong> in computer architecture refers to a situation that <strong>prevents the next instruction in the pipeline from executing at its expected time</strong>, causing delays.</p>
<p><strong>Types of Pipeline Hazards:</strong></p>
<ol>
<li><p><strong>Data Hazard</strong>:<br>Occurs when instructions <strong>depend on the result of a previous instruction</strong> that hasn‚Äôt completed yet.<br>Example:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-pgsql" data-language="pgsql"><code class="language-pgsql">ADD R1, R2, R3  
SUB R4, R1, R5  ‚Üê depends on R1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
</li>
<li><p><strong>Control Hazard</strong> (Branch Hazard):<br>Happens when the pipeline makes <strong>wrong predictions about instruction flow</strong>, such as branches or jumps.</p>
</li>
<li><p><strong>Structural Hazard</strong>:<br>Arises when <strong>hardware resources are insufficient</strong> to support all instructions in parallel (e.g., one memory unit shared by two stages).</p>
</li>
</ol>
<p><strong>Solution Techniques:</strong></p>
<ul>
<li><strong>Forwarding (data hazard)</strong></li>
<li><strong>Stalling (inserting bubbles)</strong></li>
<li><strong>Branch prediction (control hazard)</strong></li>
<li><strong>Adding hardware units (structural hazard)</strong></li>
</ul>
<p>Pipeline hazards reduce performance and must be carefully handled in modern CPUs.</p>
<hr>
<h3 id="Data-hazard"><a href="#Data-hazard" class="headerlink" title="Data hazard"></a>Data hazard</h3><p>A <strong>data hazard</strong> occurs in a pipelined processor when an instruction depends on the <strong>result of a previous instruction</strong> that has not yet completed, causing a conflict in data access.</p>
<p><strong>Types of Data Hazards:</strong></p>
<ol>
<li><p><strong>RAW (Read After Write)</strong> ‚Äì Most common<br>An instruction needs to <strong>read</strong> a register that a previous instruction will <strong>write</strong>, but the write hasn‚Äôt happened yet.<br>Example:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-pgsql" data-language="pgsql"><code class="language-pgsql">ADD R1, R2, R3  
SUB R4, R1, R5  ‚Üê needs R1 before it&#39;s written<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
</li>
<li><p><strong>WAR (Write After Read)</strong> ‚Äì Rare in simple pipelines<br>A later instruction writes to a register <strong>before</strong> an earlier instruction reads it.</p>
</li>
<li><p><strong>WAW (Write After Write)</strong> ‚Äì Happens in out-of-order execution<br>Two instructions write to the same register in the wrong order.</p>
</li>
</ol>
<p><strong>Solutions:</strong></p>
<ul>
<li><strong>Forwarding (bypassing)</strong> ‚Äì Pass result directly to the next instruction.</li>
<li><strong>Stalling</strong> ‚Äì Delay the dependent instruction until data is ready.</li>
</ul>
<p>Data hazards can slow down pipeline performance if not properly managed.</p>
<hr>
<h3 id="Control-hazard"><a href="#Control-hazard" class="headerlink" title="Control hazard"></a>Control hazard</h3><p>A <strong>control hazard</strong> (also called a <strong>branch hazard</strong>) occurs in pipelined processors when the <strong>flow of instruction execution changes</strong>, typically due to <strong>branch or jump instructions</strong>.</p>
<p><strong>Cause:</strong></p>
<p>The processor <strong>doesn‚Äôt know early enough</strong> whether a branch will be taken, so it may <strong>fetch the wrong instructions</strong>.</p>
<p><strong>Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">BEQ R1, R2, LABEL   ; Branch if R1 &#x3D;&#x3D; R2
ADD R3, R4, R5      ; May be wrongly fetched if branch is taken<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>Solutions:</strong></p>
<ul>
<li><strong>Branch Prediction</strong> ‚Äì Guess whether the branch will be taken.</li>
<li><strong>Branch Delay Slot</strong> ‚Äì Always execute the instruction after the branch.</li>
<li><strong>Pipeline Flushing</strong> ‚Äì Discard wrongly fetched instructions.</li>
<li><strong>Early Branch Resolution</strong> ‚Äì Move branch decision to earlier pipeline stage.</li>
</ul>
<p>Control hazards can reduce pipeline efficiency by introducing <strong>stalls or flushes</strong>.</p>
<hr>
<h3 id="Structural-hazard"><a href="#Structural-hazard" class="headerlink" title="Structural hazard"></a>Structural hazard</h3><p>A <strong>structural hazard</strong> occurs in a pipelined processor when <strong>two or more instructions compete for the same hardware resource</strong> at the same time, and the hardware <strong>cannot handle all of them simultaneously</strong>.</p>
<p><strong>Example:</strong></p>
<p>If the CPU has <strong>one memory unit</strong> shared for both <strong>instruction fetch</strong> and <strong>data access</strong>, a conflict arises when:</p>
<ul>
<li>One instruction is being <strong>fetched</strong>, and</li>
<li>Another instruction needs to <strong>read/write data</strong> from memory at the same time.</li>
</ul>
<p><strong>Solution:</strong></p>
<ul>
<li><strong>Add more hardware resources</strong> (e.g. separate instruction and data memory ‚Äì like in Harvard architecture)</li>
<li><strong>Stall one of the instructions</strong> to resolve the conflict</li>
</ul>
<p>Structural hazards are <strong>less common</strong> in modern CPUs due to better hardware design but can still occur in resource-limited systems.</p>
<hr>
<h3 id="Dynamic-Branch-Prediction"><a href="#Dynamic-Branch-Prediction" class="headerlink" title="Dynamic Branch Prediction"></a>Dynamic Branch Prediction</h3><p><strong>Dynamic Branch Prediction</strong> is a technique used in modern CPUs to <strong>predict the outcome of branch instructions (e.g., if-else, loops) at runtime</strong>, based on the <strong>history of previous executions</strong>.</p>
<p><strong>Key Features:</strong></p>
<ul>
<li><strong>Learns from past behavior</strong> of branches.</li>
<li><strong>Updates prediction</strong> as the program runs.</li>
<li>More accurate than static prediction (which always predicts taken/not taken).</li>
</ul>
<p><strong>Common Methods:</strong></p>
<ol>
<li><p><strong>1-bit predictor</strong>:<br>Remembers the last outcome (taken or not taken).</p>
</li>
<li><p><strong>2-bit predictor</strong>:<br>More stable; uses a state machine to change prediction only after two mispredictions.</p>
</li>
<li><p><strong>Branch History Table (BHT)</strong>:<br>Stores past branch outcomes and uses them for prediction.</p>
</li>
<li><p><strong>Global History &amp; Pattern History Table (PHT)</strong>:<br>Tracks patterns of multiple branches for more accuracy (used in <strong>two-level predictors</strong>).</p>
</li>
</ol>
<p><strong>Benefit:</strong></p>
<p>Improves <strong>pipeline efficiency</strong> by reducing <strong>control hazards</strong> and minimizing <strong>stall cycles</strong> caused by branch mispredictions.</p>
<p><img src="/img/concepts/dynamic_branch.svg" srcset="/img/loading.gif" lazyload alt="Dynamic Branch Prediction" style="max-width: 100%; height: auto;" /></p>
<p>‚Äî</p>
<h3 id="Instruction-level-Parallelsim"><a href="#Instruction-level-Parallelsim" class="headerlink" title="Instruction-level Parallelsim"></a>Instruction-level Parallelsim</h3><p><strong>Instruction-Level Parallelism (ILP)</strong> refers to the ability of a CPU to <strong>execute multiple instructions simultaneously</strong> during a single clock cycle.</p>
<p><strong>Key Idea:</strong></p>
<p>Many instructions in a program are <strong>independent</strong> and can be executed in <strong>parallel</strong>, rather than strictly one after another.</p>
<p><strong>Types of ILP:</strong></p>
<ol>
<li><p><strong>Compiler-Level ILP (Static ILP)</strong><br>The <strong>compiler rearranges instructions</strong> at compile time to exploit parallelism (e.g., instruction scheduling).</p>
</li>
<li><p><strong>Hardware-Level ILP (Dynamic ILP)</strong><br>The <strong>CPU detects parallelism at runtime</strong>, using features like:</p>
<ul>
<li><strong>Pipelining</strong></li>
<li><strong>Superscalar execution</strong> (multiple execution units)</li>
<li><strong>Out-of-order execution</strong></li>
<li><strong>Speculative execution</strong></li>
</ul>
</li>
</ol>
<p><strong>Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">ADD R1, R2, R3  
MUL R4, R5, R6   ; Independent ‚Üí can run in parallel with ADD<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>Benefits:</strong></p>
<ul>
<li>Increases CPU performance <strong>without increasing clock speed</strong></li>
<li>Makes better use of CPU resources</li>
</ul>
<p><strong>Limitations:</strong></p>
<ul>
<li><strong>Data, control, and structural hazards</strong> limit ILP</li>
<li><strong>Dependence between instructions</strong> reduces parallelism</li>
</ul>
<p>Modern processors heavily rely on ILP for high-speed performance.</p>
<p><img src="/img/concepts/parallelism.svg" srcset="/img/loading.gif" lazyload alt="Instruction-level Parallelsim" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Clock-frequency"><a href="#Clock-frequency" class="headerlink" title="Clock frequency"></a>Clock frequency</h3><p><strong>Clock frequency</strong> (also called <strong>clock speed</strong>) is the rate at which a processor executes instructions, measured in <strong>Hertz (Hz)</strong> ‚Äî typically in <strong>gigahertz (GHz)</strong> for modern CPUs.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>1 GHz = 1 billion cycles per second</strong></li>
<li>Each <strong>clock cycle</strong> is a tick of the CPU‚Äôs internal clock, during which it can perform basic operations (like fetch, decode, execute).</li>
<li>A <strong>higher clock frequency</strong> generally means the CPU can <strong>perform more operations per second</strong>.</li>
</ul>
<blockquote>
<p>Example: A CPU with <strong>3.0 GHz</strong> can perform <strong>3 billion clock cycles per second</strong>.</p>
</blockquote>
<p>Higher clock speed <strong>doesn‚Äôt always mean better performance</strong>, because:</p>
<ul>
<li>Other factors like <strong>Instruction-Level Parallelism (ILP)</strong>, <strong>number of cores</strong>, <strong>cache</strong>, and <strong>architecture efficiency</strong> also matter.</li>
<li>Very high clock speeds can cause <strong>more heat and power consumption</strong>.</li>
</ul>
<p><strong>Clock frequency = speed of instruction processing</strong>, but <strong>not the only factor</strong> in CPU performance.</p>
<hr>
<h3 id="Register-renaming"><a href="#Register-renaming" class="headerlink" title="Register renaming"></a>Register renaming</h3><p><strong>Register renaming</strong> is a technique used in modern CPUs to <strong>eliminate false data dependencies</strong> (also called <em>name dependencies</em>) between instructions, allowing for more <strong>instruction-level parallelism (ILP)</strong> and better performance.</p>
<blockquote>
<p>Why It‚Äôs Needed?</p>
</blockquote>
<p>In pipelined or out-of-order execution, instructions may appear dependent due to <strong>using the same register name</strong>, even when there‚Äôs <strong>no real data dependency</strong>.</p>
<p>There are two main false dependencies:</p>
<ol>
<li><strong>Write After Write (WAW)</strong></li>
<li><strong>Write After Read (WAR)</strong></li>
</ol>
<p><strong>Example (with false dependency):</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-assembly" data-language="assembly"><code class="language-assembly">1. ADD R1, R2, R3  
2. SUB R1, R4, R5  ‚Üê falsely depends on instruction 1 (WAW)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p>Both write to <code>R1</code>, but they‚Äôre unrelated operations. Register renaming removes this conflict.</p>
<blockquote>
<p>How It Works:</p>
</blockquote>
<ul>
<li>The CPU maintains a <strong>larger set of physical registers</strong> than the number of logical (visible) registers.</li>
<li>It dynamically assigns <strong>different physical registers</strong> to each instruction, even if they use the same logical name.</li>
<li>This avoids name-based conflicts, enabling <strong>out-of-order</strong> and <strong>parallel execution</strong>.</li>
</ul>
<p>Benefits:</p>
<ul>
<li><strong>Eliminates false dependencies</strong></li>
<li><strong>Increases parallelism</strong></li>
<li><strong>Improves CPU throughput</strong></li>
</ul>
<p>Summary:</p>
<p><strong>Register renaming</strong> helps CPUs <strong>run more instructions in parallel</strong> by resolving unnecessary register name conflicts, boosting performance.</p>
<hr>
<h3 id="Sign-Magnitude-Representation-ÂéüÁ†Å"><a href="#Sign-Magnitude-Representation-ÂéüÁ†Å" class="headerlink" title="Sign-Magnitude Representation (ÂéüÁ†Å)"></a>Sign-Magnitude Representation (ÂéüÁ†Å)</h3><p><strong>Sign-Magnitude Representation (ÂéüÁ†Å)</strong> is a binary method for representing signed integers.</p>
<ul>
<li><strong>Sign bit</strong>: The most significant bit indicates the sign ‚Äî <code>0</code> for positive, <code>1</code> for negative.</li>
<li><strong>Magnitude bits</strong>: The remaining bits represent the absolute value of the number in binary.</li>
</ul>
<p><strong>Example (using 8 bits):</strong></p>
<ul>
<li><code>+5</code> in sign-magnitude: <code>00000101</code></li>
<li><code>-5</code> in sign-magnitude: <code>10000101</code></li>
</ul>
<p><strong>Features:</strong></p>
<ul>
<li>Symmetrical representation for positive and negative numbers</li>
<li>Has <strong>two representations of zero</strong>: <code>00000000</code> (+0) and <code>10000000</code> (‚àí0)</li>
</ul>
<p>Since arithmetic operations with sign-magnitude require handling the sign separately, it is less efficient in hardware compared to two‚Äôs complement.</p>
<hr>
<h3 id="One‚Äôs-Complement-ÂèçÁ†Å"><a href="#One‚Äôs-Complement-ÂèçÁ†Å" class="headerlink" title="One‚Äôs Complement (ÂèçÁ†Å)"></a><strong>One‚Äôs Complement (ÂèçÁ†Å)</strong></h3><p><strong>One‚Äôs Complement (ÂèçÁ†Å)</strong> is a binary method for representing signed integers.</p>
<ul>
<li><strong>Positive numbers</strong>: Same as in regular binary.</li>
<li><strong>Negative numbers</strong>: Invert all bits of the positive number (i.e., change 0 to 1 and 1 to 0).</li>
</ul>
<p><strong>Example (using 8 bits):</strong></p>
<ul>
<li><code>+5</code>: <code>00000101</code></li>
<li><code>-5</code>: <code>11111010</code> (one‚Äôs complement of <code>00000101</code>)</li>
</ul>
<p><strong>Features:</strong></p>
<ul>
<li>Two representations of zero: <code>00000000</code> (+0) and <code>11111111</code> (‚àí0)</li>
<li>Subtraction can be done using addition, but still needs end-around carry handling.</li>
</ul>
<p>Less efficient than two‚Äôs complement for arithmetic operations.</p>
<hr>
<h3 id="Two‚Äôs-Complement-Ë°•Á†Å"><a href="#Two‚Äôs-Complement-Ë°•Á†Å" class="headerlink" title="Two‚Äôs Complement (Ë°•Á†Å)"></a>Two‚Äôs Complement (Ë°•Á†Å)</h3><p><strong>Two‚Äôs Complement (Ë°•Á†Å)</strong> is the most common binary method for representing signed integers.</p>
<ul>
<li><strong>Positive numbers</strong>: Same as regular binary.</li>
<li><strong>Negative numbers</strong>: Invert all bits of the positive number (get the one‚Äôs complement), then add 1.</li>
</ul>
<p><strong>Example (using 8 bits):</strong></p>
<ul>
<li><code>+5</code>: <code>00000101</code></li>
<li><code>-5</code>: <code>11111011</code> (one‚Äôs complement of <code>00000101</code> is <code>11111010</code>, plus 1 gives <code>11111011</code>)</li>
</ul>
<p><strong>Features:</strong></p>
<ul>
<li>Only <strong>one zero</strong>: <code>00000000</code></li>
<li>Arithmetic operations (addition and subtraction) are simple and efficient</li>
<li>Widely used in modern computers for signed integer representation</li>
</ul>
<hr>
<h3 id="Benchmark"><a href="#Benchmark" class="headerlink" title="Benchmark"></a>Benchmark</h3><p><strong>Benchmark</strong> refers to a <strong>standardized test or reference</strong> used to evaluate the performance or quality of a system, device, program, or product.</p>
<p>A <strong>benchmark</strong> is a method of assessing the performance of an object by running a set of standard tests and comparing the results to others. It helps measure efficiency and identify areas for improvement.</p>
<p><strong>Common Use Cases</strong></p>
<ol>
<li><p><strong>Computer Hardware:</strong></p>
<ul>
<li>Benchmarking CPUs, GPUs, SSDs, etc., by running performance tests and comparing scores.</li>
<li>Common tools: Cinebench, Geekbench, PCMark.</li>
</ul>
</li>
<li><p><strong>Software Development:</strong></p>
<ul>
<li>Measuring the speed or efficiency of code or algorithms to optimize performance.</li>
</ul>
</li>
<li><p><strong>Business Management:</strong></p>
<ul>
<li>Comparing business performance to industry best practices to find room for improvement.</li>
</ul>
</li>
</ol>
<hr>
<h3 id="Big-endian"><a href="#Big-endian" class="headerlink" title="Big-endian"></a>Big-endian</h3><p><strong>Big-endian</strong> is a type of <strong>byte order</strong> where the <strong>most significant byte (MSB)</strong> is stored at the <strong>lowest memory address</strong>, and the least significant byte is stored at the highest address.</p>
<p>Suppose we have a 32-bit hexadecimal number: <code>0x12345678</code></p>
<p>In <strong>Big-endian</strong> format, it would be stored in memory like this (from low to high address):</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Address</th>
<th>Byte Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>0x00</td>
<td>0x12</td>
</tr>
<tr>
<td>0x01</td>
<td>0x34</td>
</tr>
<tr>
<td>0x02</td>
<td>0x56</td>
</tr>
<tr>
<td>0x03</td>
<td>0x78</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Commonly used in <strong>network protocols</strong> (e.g., TCP/IP), hence also known as <strong>network byte order</strong>.</li>
<li>The opposite of Big-endian is <strong>Little-endian</strong>, where the least significant byte comes first.</li>
</ul>
<hr>
<h3 id="Little-endian-Brief-Explanation"><a href="#Little-endian-Brief-Explanation" class="headerlink" title="Little-endian (Brief Explanation)"></a>Little-endian (Brief Explanation)</h3><p><strong>Little-endian</strong> is a type of <strong>byte order</strong> where the <strong>least significant byte (LSB)</strong> is stored at the <strong>lowest memory address</strong>, and the most significant byte is stored at the highest address.</p>
<p>Suppose we have a 32-bit hexadecimal number: <code>0x12345678</code></p>
<p>In <strong>Little-endian</strong> format, it would be stored in memory like this (from low to high address):</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Address</th>
<th>Byte Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>0x00</td>
<td>0x78</td>
</tr>
<tr>
<td>0x01</td>
<td>0x56</td>
</tr>
<tr>
<td>0x02</td>
<td>0x34</td>
</tr>
<tr>
<td>0x03</td>
<td>0x12</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Characteristics:</strong></p>
<ul>
<li>Commonly used in <strong>x86 architecture</strong> (Intel and AMD CPUs).</li>
<li>It is the <strong>opposite of Big-endian</strong>, which stores the most significant byte first.</li>
<li>Easier for some CPUs to handle arithmetic operations on varying byte lengths.</li>
</ul>
<hr>
<h3 id="Temporal-Locality-Êó∂Èó¥Â±ÄÈÉ®ÊÄß"><a href="#Temporal-Locality-Êó∂Èó¥Â±ÄÈÉ®ÊÄß" class="headerlink" title="Temporal Locality (Êó∂Èó¥Â±ÄÈÉ®ÊÄß)"></a>Temporal Locality (Êó∂Èó¥Â±ÄÈÉ®ÊÄß)</h3><p><strong>Temporal locality</strong> is a common program behavior in computer systems that means:</p>
<blockquote>
<p><strong>‚ÄúIf a data item is accessed, it is likely to be accessed again in the near future.‚Äù</strong></p>
</blockquote>
<p>Consider the following code snippet:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    sum <span class="token operator">+=</span> array<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure>
<ul>
<li>When <code>array[0]</code> is accessed, the program will soon access <code>array[1]</code>, <code>array[2]</code>, etc.</li>
<li>The variable <code>sum</code> is also accessed repeatedly.</li>
<li>This demonstrates <strong>temporal locality</strong>.</li>
</ul>
<p><strong>Additional Notes:</strong></p>
<ul>
<li><strong>Caches</strong> take advantage of temporal locality to improve performance.</li>
<li><p>Temporal locality commonly appears in:</p>
<ul>
<li>Loop variables</li>
<li>Frequently called functions</li>
<li>Intermediate computation results</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Spatial-Locality-Á©∫Èó¥Â±ÄÈÉ®ÊÄß"><a href="#Spatial-Locality-Á©∫Èó¥Â±ÄÈÉ®ÊÄß" class="headerlink" title="Spatial Locality (Á©∫Èó¥Â±ÄÈÉ®ÊÄß)"></a>Spatial Locality (Á©∫Èó¥Â±ÄÈÉ®ÊÄß)</h3><p><strong>Spatial locality</strong> is a common program behavior in computer systems that means:</p>
<blockquote>
<p><strong>‚ÄúIf a data item is accessed, nearby data items (in memory) are likely to be accessed soon.‚Äù</strong></p>
</blockquote>
<p>Consider the following code snippet:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">&#123;</span>
    sum <span class="token operator">+=</span> array<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure>
<ul>
<li>When <code>array[0]</code> is accessed, the program will likely access <code>array[1]</code>, <code>array[2]</code>, ‚Ä¶, <code>array[99]</code> shortly after.</li>
<li>These elements are stored in <strong>adjacent memory locations</strong>, so this illustrates <strong>spatial locality</strong>.</li>
</ul>
<p><strong>Additional Notes:</strong></p>
<ul>
<li><strong>Caches</strong> use spatial locality by loading not just a single data item but also <strong>nearby memory blocks</strong> (called a cache line).</li>
<li><p>Spatial locality commonly appears in:</p>
<ul>
<li>Sequential array access</li>
<li>Traversal of linked lists or other data structures with contiguous memory</li>
<li>Instruction fetches during linear code execution</li>
</ul>
</li>
</ul>
<hr>
<h3 id="Hardware-Prefetching-a-k-a-Prefetch"><a href="#Hardware-Prefetching-a-k-a-Prefetch" class="headerlink" title="Hardware Prefetching (a.k.a. Prefetch)"></a>Hardware Prefetching (a.k.a. Prefetch)</h3><p><strong>Hardware Prefetching</strong> is a technique where the CPU automatically predicts and loads data into the cache <strong>before</strong> it is actually needed.<br>It helps reduce memory latency by exploiting <strong>spatial</strong> and <strong>temporal locality</strong>.<br>For example, if a program accesses memory sequentially, the hardware may prefetch the next few addresses.<br>Prefetched data is stored in the cache, making future access faster.<br>This improves overall CPU performance, especially in data-intensive workloads.</p>
<hr>
<h3 id="Write-ThroughÔºàÂÜôÁõ¥ËææÔºâ"><a href="#Write-ThroughÔºàÂÜôÁõ¥ËææÔºâ" class="headerlink" title="Write ThroughÔºàÂÜôÁõ¥ËææÔºâ"></a>Write ThroughÔºàÂÜôÁõ¥ËææÔºâ</h3><p><strong>Write Through</strong> is a <strong>cache writing policy</strong> used in computer architecture to manage how data is written to the memory hierarchy, specifically between the <strong>cache</strong> and <strong>main memory</strong>.</p>
<p><strong>üîß Definition:</strong><br>In a <strong>Write Through</strong> policy, <strong>every write operation</strong> to the cache is <strong>immediately and simultaneously written to main memory</strong>. This ensures that the main memory always holds the most up-to-date data.</p>
<p><strong>‚úÖ Advantages:</strong></p>
<ul>
<li><strong>Data consistency</strong>: Main memory always reflects the latest data written by the CPU.</li>
<li><strong>Simple to implement</strong>: Because memory and cache are always in sync, it simplifies memory coherence in multi-processor systems.</li>
</ul>
<p><strong>‚ùå Disadvantages:</strong></p>
<ul>
<li><strong>Slower write performance</strong>: Every write operation must access main memory, which is slower than just writing to cache.</li>
<li><strong>Higher memory traffic</strong>: Frequent memory writes can increase bus usage and reduce overall system performance.</li>
</ul>
<p><strong>üß† Example:</strong><br>If a CPU writes value <code>42</code> to memory address <code>0xA0</code>:</p>
<ul>
<li>The value is written to <strong>L1 cache</strong>.</li>
<li>At the same time, the value is also written to <strong>main memory</strong>.</li>
</ul>
<p><strong>üí° Related Concept:</strong></p>
<ul>
<li>Compare with <strong>Write Back</strong> policy, where updates are only made to the cache and written to memory <strong>later</strong>, often when the cache block is replaced.</li>
</ul>
<p><strong>Summary:</strong><br>Write Through provides <strong>strong consistency</strong> between cache and memory at the cost of <strong>write speed and efficiency</strong>.</p>
<hr>
<h3 id="Write-BackÔºàÂÜôÂõûÔºâ"><a href="#Write-BackÔºàÂÜôÂõûÔºâ" class="headerlink" title="Write BackÔºàÂÜôÂõûÔºâ"></a>Write BackÔºàÂÜôÂõûÔºâ</h3><p><strong>Write Back</strong> is a <strong>cache writing policy</strong> used in computer architecture to manage how data is written between the <strong>CPU cache</strong> and <strong>main memory</strong>.</p>
<p><strong>üîß Definition:</strong><br>In a <strong>Write Back</strong> policy, data is written <strong>only to the cache</strong> at first. The updated data is written to <strong>main memory only when the cache block is replaced</strong> (i.e., evicted). Until then, the main memory may hold stale data.</p>
<p><strong>‚úÖ Advantages:</strong></p>
<ul>
<li><strong>Faster write performance</strong>: Since writes are done only in cache, it reduces the latency of write operations.</li>
<li><strong>Reduced memory traffic</strong>: Multiple writes to the same memory location are performed only once to main memory when the block is evicted.</li>
</ul>
<p><strong>‚ùå Disadvantages:</strong></p>
<ul>
<li><strong>Data inconsistency risk</strong>: Main memory may not reflect the latest data, which complicates memory coherence in multi-core systems.</li>
<li><strong>More complex control logic</strong>: Needs a <strong>dirty bit</strong> to track whether a cache block has been modified.</li>
</ul>
<p><strong>üß† Example:</strong><br>If the CPU writes value <code>42</code> to memory address <code>0xA0</code>:</p>
<ul>
<li>The value is written <strong>only to the cache</strong> (marked as dirty).</li>
<li>When the cache block containing <code>0xA0</code> is later evicted, <strong>then</strong> the value is written to <strong>main memory</strong>.</li>
</ul>
<p><strong>üí° Related Concept:</strong></p>
<ul>
<li>Compare with <strong>Write Through</strong>, where every write updates both the cache and main memory <strong>simultaneously</strong>.</li>
</ul>
<p><strong>Summary:</strong><br>Write Back improves <strong>write efficiency and performance</strong>, but introduces <strong>complexity and consistency challenges</strong>.</p>
<p><img src="/img/concepts/wb.svg" srcset="/img/loading.gif" lazyload alt="Write Back VS Write Through" style="max-width: 100%; height: auto;" /></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>ÁâπÊÄß</th>
<th>ÂÜôÂõûÔºàWrite BackÔºâ</th>
<th>ÂÜôÁõ¥ËææÔºàWrite ThroughÔºâ</th>
</tr>
</thead>
<tbody>
<tr>
<td>ÂÜôÂÖ•‰ΩçÁΩÆ</td>
<td>Âè™ÂÜôÁºìÂ≠òÔºàÂÖàÁºìÂ≠òÔºåÂêé‰∏ªÂ≠òÔºâ</td>
<td>ÂêåÊó∂ÂÜôÂÖ•ÁºìÂ≠òÂíå‰∏ªÂ≠ò</td>
</tr>
<tr>
<td>ÂÜôÂÖ•‰∏ªÂ≠òÊó∂Êú∫</td>
<td>ÁºìÂ≠òÂùóË¢´ÊõøÊç¢Êó∂ÊâçÂÜôÂõû‰∏ªÂ≠ò</td>
<td>ÊØèÊ¨°ÂÜôÊìç‰ΩúÈÉΩÁ´ãÂç≥ÂÜôÂÖ•‰∏ªÂ≠ò</td>
</tr>
<tr>
<td>ÊÄßËÉΩ</td>
<td>È´òÊÄßËÉΩÔºåÂáèÂ∞ë‰∏ªÂ≠òËÆøÈóÆÔºåÂª∂ËøüÊõ¥‰Ωé</td>
<td>ÂÜôÂÖ•ÊÖ¢ÔºåÂõ†È¢ëÁπÅËÆøÈóÆ‰∏ªÂ≠ò</td>
</tr>
<tr>
<td>‰∏ªÂ≠òÊï∞ÊçÆ‰∏ÄËá¥ÊÄß</td>
<td>Â§çÊùÇÔºåÈúÄË¶Å‰ΩøÁî®‚ÄúËÑè‰Ωç‚ÄùÁ≠â‰∏ÄËá¥ÊÄßÊú∫Âà∂ÁÆ°ÁêÜ</td>
<td>ÁÆÄÂçïÔºå‰∏ªÂ≠òÊÄªÊòØÊúÄÊñ∞Êï∞ÊçÆ</td>
</tr>
<tr>
<td>Á≥ªÁªüÊÄªÁ∫øË¥üËΩΩ</td>
<td>ËæÉ‰ΩéÔºåÂáèÂ∞ëÂÜôÊìç‰ΩúÂ∏¶Êù•ÁöÑÊÄªÁ∫øÊµÅÈáè</td>
<td>ËæÉÈ´òÔºåÂÜôÊìç‰ΩúÊÄªÊòØÂêåÊ≠•‰∏ªÂ≠òÔºåÂ¢ûÂä†ÊÄªÁ∫øÂéãÂäõ</td>
</tr>
<tr>
<td>ÁºìÂ≠ò‰∏ÄËá¥ÊÄßÁª¥Êä§</td>
<td>ËæÉÂõ∞ÈöæÔºåÂ§öÊ†∏Á≥ªÁªü‰∏≠ÈúÄÈ¢ùÂ§ñ‰∏ÄËá¥ÊÄßÂçèËÆÆÊîØÊåÅ</td>
<td>ËæÉÁÆÄÂçïÔºå‰∏ªÂ≠ò‰Ωú‰∏∫ÊùÉÂ®ÅÊï∞ÊçÆÊ∫ê</td>
</tr>
<tr>
<td>ÈÄÇÁî®Âú∫ÊôØ</td>
<td>ÂÜôÊìç‰ΩúÈ¢ëÁπÅ„ÄÅÂØπÊÄßËÉΩË¶ÅÊ±ÇÈ´òÁöÑÁ≥ªÁªü</td>
<td>ÂØπ‰∏ÄËá¥ÊÄßË¶ÅÊ±ÇÈ´ò„ÄÅÁ≥ªÁªüÁªìÊûÑÁÆÄÂçïÁöÑÂú∫ÊôØ</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="Multicache-Multi-level-Cache"><a href="#Multicache-Multi-level-Cache" class="headerlink" title="Multicache (Multi-level Cache)"></a>Multicache (Multi-level Cache)</h3><p><strong>Multicache</strong>, or <strong>Multi-level Cache</strong>, refers to a hierarchical(ÂàÜÂ±ÇÁöÑ) caching system used in modern CPUs to bridge the speed gap between the fast processor and the slower main memory. It typically consists of <strong>multiple levels of cache</strong>, such as <strong>L1</strong>, <strong>L2</strong>, and <strong>L3</strong>, each with different sizes, speeds, and purposes.</p>
<p><strong>üîß Definition:</strong> A <strong>multi-level cache</strong> system includes:</p>
<ul>
<li><strong>L1 Cache</strong>: Closest to the CPU core, smallest and fastest.</li>
<li><strong>L2 Cache</strong>: Larger than L1, slower, and may be shared or private per core.</li>
<li><strong>L3 Cache</strong>: Even larger and slower, typically shared across all CPU cores.</li>
</ul>
<p>This layered structure allows faster access to frequently used data while reducing latency and improving CPU efficiency.</p>
<p><strong>üèóÔ∏è Structure Example:</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Level</th>
<th>Size</th>
<th>Speed</th>
<th>Shared</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td>L1</td>
<td>~32KB</td>
<td>Very fast</td>
<td>No</td>
<td>Immediate access for the CPU</td>
</tr>
<tr>
<td>L2</td>
<td>~256KB</td>
<td>Fast</td>
<td>Maybe</td>
<td>Secondary buffer</td>
</tr>
<tr>
<td>L3</td>
<td>~8MB</td>
<td>Slower</td>
<td>Yes</td>
<td>Shared cache for all cores</td>
</tr>
</tbody>
</table>
</div>
<p><strong>‚úÖ Advantages:</strong></p>
<ul>
<li><strong>Improved performance</strong>: Reduces average memory access time.</li>
<li><strong>Lower latency</strong>: L1 and L2 caches are much faster than main memory.</li>
<li><strong>Better scalability</strong>: Helps in multi-core systems where data sharing and access times are critical.</li>
</ul>
<p><strong>‚ùå Disadvantages:</strong></p>
<ul>
<li><strong>Complex design</strong>: Managing coherence and consistency across multiple levels is challenging.</li>
<li><strong>Increased cost and power</strong>: More hardware and logic are required.</li>
<li><strong>Cache misses</strong>: Still possible, especially if working sets exceed cache sizes.</li>
</ul>
<p><strong>üí° Notes:</strong></p>
<ul>
<li>Most modern processors use <strong>inclusiveÔºàÂåÖÂÆπÔºâ</strong>, <strong>exclusiveÔºàÊéí‰ªñÔºâ</strong>, or <strong>non-inclusiveÔºàÈùûÂåÖÂÆπÔºâ</strong> cache strategies to determine how data is stored across cache levels.</li>
<li>Multi-level cache systems often work in tandem with <strong>cache coherence protocols</strong> like MESI in multi-core CPUs.</li>
</ul>
<p><strong>üìå Summary</strong></p>
<p><strong>Multicache systems</strong> provide a hierarchical buffer between the CPU and main memory, optimizing performance and efficiency by leveraging fast, small caches for frequently accessed data and larger, slower caches for broader access.</p>
<p><img src="/img/concepts/multicache.svg" srcset="/img/loading.gif" lazyload alt="multicache" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Direct-MappingÔºàÁõ¥Êé•Êò†Â∞ÑÔºâ"><a href="#Direct-MappingÔºàÁõ¥Êé•Êò†Â∞ÑÔºâ" class="headerlink" title="Direct MappingÔºàÁõ¥Êé•Êò†Â∞ÑÔºâ"></a>Direct MappingÔºàÁõ¥Êé•Êò†Â∞ÑÔºâ</h3><p><strong>Direct Mapping</strong> is a simple cache mapping technique used in computer architecture to determine where a memory block will be placed in the cache.</p>
<p><strong>üîß Definition:</strong><br>In <strong>Direct Mapping</strong>, each block of main memory maps to <strong>exactly one</strong> cache line. The mapping is usually done using:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Cache Line Index &#x3D; (Main Memory Block Address) mod (Number of Cache Lines)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>This makes it easy and fast to locate data in the cache, but can lead to many <strong>conflicts</strong> if multiple blocks map to the same cache line.</p>
<p><strong>‚úÖ Advantages:</strong></p>
<ul>
<li><strong>Simple and fast</strong> implementation</li>
<li><strong>Low hardware complexity</strong></li>
</ul>
<p><strong>‚ùå Disadvantages:</strong></p>
<ul>
<li><strong>High conflict rate</strong>: Two different memory blocks mapping to the same line will continuously evict each other</li>
<li><strong>Low flexibility</strong> compared to other mapping techniques (e.g., set-associative)</li>
</ul>
<p><strong>üß† Example:</strong><br>If a cache has 8 lines (0 to 7), and a block from main memory has address 24:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Cache Line &#x3D; 24 mod 8 &#x3D; 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>So this block will always be placed in cache line 0.</p>
<p><strong>Summary:</strong><br>Direct Mapping provides fast and simple cache access, but is prone to frequent conflicts.</p>
<hr>
<h3 id="Set-Associative-MappingÔºàÁªÑÁõ∏ËøûÊò†Â∞ÑÔºâ"><a href="#Set-Associative-MappingÔºàÁªÑÁõ∏ËøûÊò†Â∞ÑÔºâ" class="headerlink" title="Set- Associative MappingÔºàÁªÑÁõ∏ËøûÊò†Â∞ÑÔºâ"></a>Set- Associative MappingÔºàÁªÑÁõ∏ËøûÊò†Â∞ÑÔºâ</h3><p><strong>Set-Associative Mapping</strong> is a cache mapping technique that combines the benefits of both <strong>Direct Mapping</strong> and <strong>Fully Associative Mapping</strong> to balance performance and complexity.</p>
<p><strong>üîß Definition:</strong><br>In <strong>Set-Associative Mapping</strong>, the cache is divided into multiple <strong>sets</strong>, and each set contains <strong>multiple cache lines (ways)</strong>. A block from main memory maps to <strong>exactly one set</strong>, but <strong>can be placed in any line (way) within that set</strong>.</p>
<p>The set is selected using:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Set Index &#x3D; (Main Memory Block Address) mod (Number of Sets)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Within the set, placement and replacement follow policies like <strong>Least Recently Used (LRU)</strong> or <strong>Random</strong>.</p>
<p><strong>‚úÖ Advantages:</strong></p>
<ul>
<li><strong>Lower conflict rate</strong> than Direct Mapping</li>
<li><strong>More flexible</strong> placement within sets</li>
<li><strong>Good balance</strong> between speed and cache hit rate</li>
</ul>
<p><strong>‚ùå Disadvantages:</strong></p>
<ul>
<li><strong>More complex</strong> hardware than Direct Mapping</li>
<li><strong>Slightly slower</strong> lookup due to checking multiple lines in a set</li>
</ul>
<p><strong>üß† Example:</strong><br>If a cache has <strong>4 sets</strong>, each with <strong>2 lines (2-way set-associative)</strong>, and a memory block with address 12:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">Set Index &#x3D; 12 mod 4 &#x3D; 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>The block can be placed in <strong>either of the 2 lines in Set 0</strong>.</p>
<p><strong>Summary:</strong><br>Set-Associative Mapping provides a <strong>balanced approach</strong> with better conflict resolution than Direct Mapping and <strong>less complexity</strong> than Fully Associative Mapping.</p>
<hr>
<h3 id="Full-Associative-MappingÔºàÂÖ®Áõ∏ËÅîÊò†Â∞ÑÔºâ"><a href="#Full-Associative-MappingÔºàÂÖ®Áõ∏ËÅîÊò†Â∞ÑÔºâ" class="headerlink" title="Full Associative MappingÔºàÂÖ®Áõ∏ËÅîÊò†Â∞ÑÔºâ"></a>Full Associative MappingÔºàÂÖ®Áõ∏ËÅîÊò†Â∞ÑÔºâ</h3><p><strong>Full Associative Mapping</strong> is a cache mapping technique in which <strong>a memory block can be placed in any cache line</strong>, offering maximum flexibility and minimal conflict.</p>
<p><strong>üîß Definition:</strong><br>In <strong>Full Associative Mapping</strong>, there are <strong>no restrictions</strong> on where a block can be placed in the cache. Any block from main memory can be stored in <strong>any cache line</strong>.</p>
<p>To find a block, the cache must <strong>search all lines</strong> using <strong>comparators</strong> that match tags.</p>
<p><strong>‚úÖ Advantages:</strong></p>
<ul>
<li><strong>No conflict misses</strong> (except when cache is full)</li>
<li><strong>Best flexibility</strong> in placement</li>
<li><strong>Highest cache hit potential</strong></li>
</ul>
<p><strong>‚ùå Disadvantages:</strong></p>
<ul>
<li><strong>Complex hardware</strong>: Requires searching the entire cache in parallel</li>
<li><strong>Slower access time</strong> due to tag comparisons</li>
<li><strong>Expensive</strong> in terms of power and chip area</li>
</ul>
<p><strong>üß† Example:</strong><br>If a cache has <strong>8 lines</strong>, and a block from memory has address <code>0x2F</code>, it can be placed in <strong>any one</strong> of the 8 lines. When checking for a hit, the cache must compare the block‚Äôs tag with the tags of <strong>all 8 lines</strong>.</p>
<p><strong>Summary:</strong><br>Full Associative Mapping provides <strong>maximum flexibility</strong> and <strong>minimal conflict</strong>, but comes with <strong>higher hardware cost</strong> and <strong>slower lookup times</strong>.</p>
<hr>
<h3 id="Comparison-of-Cache-Mapping-Techniques"><a href="#Comparison-of-Cache-Mapping-Techniques" class="headerlink" title="Comparison of Cache Mapping Techniques"></a>Comparison of Cache Mapping Techniques</h3><div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Direct Mapping</th>
<th>Set-Associative Mapping</th>
<th>Full Associative Mapping</th>
</tr>
</thead>
<tbody>
<tr>
<td>Placement Rule</td>
<td>Each block maps to <strong>one line</strong></td>
<td>Each block maps to <strong>one set</strong>, can go into <strong>any line</strong> in that set</td>
<td>Each block can go into <strong>any line</strong> in the cache</td>
</tr>
<tr>
<td>Flexibility</td>
<td>Low</td>
<td>Medium</td>
<td>High</td>
</tr>
<tr>
<td>Hardware Complexity</td>
<td>Low (simplest)</td>
<td>Medium</td>
<td>High (most complex)</td>
</tr>
<tr>
<td>Access Speed</td>
<td>Fast</td>
<td>Slightly slower</td>
<td>Slowest (due to parallel comparisons)</td>
</tr>
<tr>
<td>Conflict Misses</td>
<td>High</td>
<td>Lower than Direct Mapping</td>
<td>None (except capacity misses)</td>
</tr>
<tr>
<td>Replacement Policy</td>
<td>Not needed (only one line)</td>
<td>Needed within each set (e.g., LRU)</td>
<td>Needed for the entire cache (e.g., LRU)</td>
</tr>
<tr>
<td>Cost (Power/Area)</td>
<td>Low</td>
<td>Moderate</td>
<td>High</td>
</tr>
<tr>
<td>Use Case Suitability</td>
<td>Simple, low-power systems</td>
<td>General-purpose CPUs</td>
<td>High-performance or critical systems</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/img/concepts/cache3.jpg" srcset="/img/loading.gif" lazyload alt="‰∏âÁßçcacheÊò†Â∞Ñ" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Cache"><a href="#Cache" class="headerlink" title="Cache"></a>Cache</h3><p><strong>Cache</strong> is a small, high-speed memory that stores frequently used data to speed up access. It sits between the CPU and main memory to reduce latency. It enables fast program access to frequently used addresses.</p>
<hr>
<h3 id="Non-blocking-CacheÔºàÈùûÈòªÂ°ûÁºìÂ≠òÔºâ"><a href="#Non-blocking-CacheÔºàÈùûÈòªÂ°ûÁºìÂ≠òÔºâ" class="headerlink" title="Non-blocking CacheÔºàÈùûÈòªÂ°ûÁºìÂ≠òÔºâ"></a>Non-blocking CacheÔºàÈùûÈòªÂ°ûÁºìÂ≠òÔºâ</h3><p>A <strong>Non-blocking Cache</strong> allows the CPU to continue processing other instructions <strong>while waiting for a cache miss</strong> to be resolved.<br>It supports <strong>multiple outstanding memory requests</strong> simultaneously.<br>This improves overall system performance by reducing CPU idle time.<br>Non-blocking caches are especially useful in <strong>out-of-order execution</strong> and <strong>superscalar processors</strong>.<br>They often use structures like <strong>Miss Status Handling Registers (MSHRs)</strong> to track pending requests.</p>
<p><strong>ÈùûÈòªÂ°ûÁºìÂ≠ò</strong>ÂÖÅËÆ∏ CPU Âú®<strong>Á≠âÂæÖÁºìÂ≠òÊú™ÂëΩ‰∏≠ÔºàCache MissÔºâÂ§ÑÁêÜÂÆåÊàêÁöÑÂêåÊó∂ÁªßÁª≠ÊâßË°åÂÖ∂‰ªñÊåá‰ª§</strong>„ÄÇ<br>ÂÆÉÊîØÊåÅ<strong>Â§ö‰∏™Êú™ÂÆåÊàêÁöÑÂÜÖÂ≠òËØ∑Ê±Ç</strong>ÂêåÊó∂Â≠òÂú®„ÄÇ<br>ËøôÈÄöËøáÂáèÂ∞ë CPU Á©∫Èó≤Êó∂Èó¥Êù•ÊèêÂçáÁ≥ªÁªüÊï¥‰ΩìÊÄßËÉΩ„ÄÇ<br>ÈùûÈòªÂ°ûÁºìÂ≠òÂú®<strong>‰π±Â∫èÊâßË°å</strong>Âíå<strong>Ë∂ÖÊ†áÈáèÂ§ÑÁêÜÂô®</strong>‰∏≠Â∞§‰∏∫ÈáçË¶Å„ÄÇ<br>ÂÆÉÈÄöÂ∏∏‰ΩøÁî®Â¶Ç <strong>Êú™ÂëΩ‰∏≠Áä∂ÊÄÅÂ§ÑÁêÜÂØÑÂ≠òÂô®ÔºàMiss Status Handling Registers, MSHRsÔºâ</strong> ÁöÑÁªìÊûÑÊù•ËøΩË∏™Êú™ÂÆåÊàêÁöÑËØ∑Ê±Ç„ÄÇ</p>
<hr>
<h3 id="Superscalar-ArchitectureÔºàË∂ÖÊ†áÈáèÊû∂ÊûÑÔºâ"><a href="#Superscalar-ArchitectureÔºàË∂ÖÊ†áÈáèÊû∂ÊûÑÔºâ" class="headerlink" title="Superscalar ArchitectureÔºàË∂ÖÊ†áÈáèÊû∂ÊûÑÔºâ"></a>Superscalar ArchitectureÔºàË∂ÖÊ†áÈáèÊû∂ÊûÑÔºâ</h3><p><strong>Superscalar Architecture</strong> is a CPU design that allows the processor to <strong>fetch, decode, and execute multiple instructions simultaneously</strong> during each clock cycle.<br>It achieves this by using <strong>multiple pipelines</strong> and <strong>parallel execution units</strong> (e.g., ALUs, FPUs).<br>This architecture increases <strong>instruction-level parallelism (ILP)</strong>, boosting performance without raising the clock speed.<br>Superscalar CPUs include features like <strong>out-of-order execution</strong>, <strong>register renaming</strong>, and <strong>branch prediction</strong> to handle dependencies and control flow efficiently.<br>Examples of superscalar processors include modern Intel and AMD CPUs.</p>
<p><img src="/img/concepts/superscalar.svg" srcset="/img/loading.gif" lazyload alt="Ë∂ÖÊ†áÈáèÊû∂ÊûÑ" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="üîç-TLB-Translation-Lookaside-Buffer"><a href="#üîç-TLB-Translation-Lookaside-Buffer" class="headerlink" title="üîç TLB (Translation Lookaside Buffer)"></a>üîç TLB (Translation Lookaside Buffer)</h3><p><strong>TLB</strong> stands for <strong>Translation Lookaside Buffer</strong>. It is a small, fast cache used in the memory management unit (MMU) of a computer‚Äôs CPU to improve the speed of <strong>virtual-to-physical address translation</strong>.</p>
<p><strong>üìå Why is TLB needed?</strong></p>
<p>When a CPU accesses memory using a virtual address, it must be translated into a physical address using the <strong>page table</strong>. This translation is time-consuming. The TLB stores recent translations, so if the virtual address has been accessed recently, the translation can be retrieved quickly without accessing the full page table.</p>
<p><strong>‚úÖ Key Characteristics</strong></p>
<ul>
<li><strong>Cache for page table entries</strong></li>
<li><strong>Reduces page table access time</strong></li>
<li>Typically contains <strong>64 to 512 entries</strong></li>
<li>Can be <strong>fully associative</strong>, <strong>set-associative</strong>, or <strong>direct-mapped</strong></li>
</ul>
<p><strong>üìà How it works</strong></p>
<ol>
<li><strong>CPU generates a virtual address</strong></li>
<li><strong>MMU checks the TLB</strong> for the virtual page number (VPN)</li>
<li>If found (<strong>TLB hit</strong>): use the cached physical page number (PPN)</li>
<li>If not found (<strong>TLB miss</strong>): access the page table, then update the TLB</li>
</ol>
<p><strong>üß† TLB Hit vs TLB Miss</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Event</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>TLB Hit</td>
<td>The virtual address is found in the TLB ‚Üí Fast address translation</td>
</tr>
<tr>
<td>TLB Miss</td>
<td>The virtual address is not found in the TLB ‚Üí Page table lookup is required</td>
</tr>
</tbody>
</table>
</div>
<p><strong>üßÆ Example</strong></p>
<p>Let‚Äôs say the CPU wants to access virtual address <code>0x00403ABC</code>:</p>
<ul>
<li>VPN = top bits of address ‚Üí check if TLB has entry</li>
<li>If yes ‚Üí get PPN and combine with offset ‚Üí access physical memory</li>
<li>If no ‚Üí consult page table ‚Üí update TLB ‚Üí then access memory</li>
</ul>
<p><strong>üîÑ TLB Replacement Policy</strong></p>
<p>When the TLB is full, and a new entry must be loaded, a <strong>replacement policy</strong> is used, such as:</p>
<ul>
<li><strong>Least Recently Used (LRU)</strong></li>
<li><strong>Random replacement</strong></li>
</ul>
<p><strong>üöÄ Summary</strong> </p>
<ul>
<li>TLB significantly <strong>improves performance</strong> of memory access.</li>
<li>Acts as a <strong>fast cache</strong> for recent address translations.</li>
<li>Helps bridge the speed gap between the CPU and memory systems.</li>
</ul>
<hr>
<h3 id="Page-Table"><a href="#Page-Table" class="headerlink" title="Page Table"></a>Page Table</h3><p>In computer architecture, a <strong>Page Table</strong> is a data structure used by the <strong>virtual memory system</strong> to manage the mapping between <strong>virtual addresses</strong> and <strong>physical addresses</strong>.</p>
<p><strong>üß† What is Virtual Memory?</strong></p>
<p>Virtual memory allows a program to use a large, continuous address space even if the physical memory (RAM) is smaller. The CPU generates <strong>virtual addresses</strong>, which must be translated into <strong>physical addresses</strong> before accessing actual memory.</p>
<p><strong>üìò What is a Page Table?</strong></p>
<p>A <strong>Page Table</strong> stores the mapping between <strong>virtual pages</strong> and <strong>physical frames</strong>. Each entry in the page table is called a <strong>Page Table Entry (PTE)</strong> and contains information such as:</p>
<ul>
<li><strong>Frame Number</strong>: the physical frame corresponding to the virtual page.</li>
<li><strong>Valid/Invalid Bit</strong>: indicates if the mapping is valid.</li>
<li><strong>Protection Bits</strong>: control read/write permissions.</li>
<li><strong>Dirty Bit</strong>: indicates if the page has been modified.</li>
<li><strong>Accessed Bit</strong>: indicates if the page has been accessed recently.</li>
</ul>
<p><strong>üßæ Example Structure</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Virtual Page Number</th>
<th>Physical Frame Number</th>
<th>Valid Bit</th>
<th>Protection</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>5</td>
<td>1</td>
<td>Read/Write</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>1</td>
<td>Read-only</td>
</tr>
<tr>
<td>2</td>
<td>-</td>
<td>0</td>
<td>-</td>
</tr>
</tbody>
</table>
</div>
<p><strong>üßÆ Address Translation Steps</strong></p>
<ol>
<li>The CPU generates a <strong>virtual address</strong>.</li>
<li><p>The virtual address is divided into:</p>
<ul>
<li><strong>Page Number</strong></li>
<li><strong>Offset</strong></li>
</ul>
</li>
<li>The <strong>Page Number</strong> is used to index into the Page Table.</li>
<li>The Page Table Entry provides the <strong>Frame Number</strong>.</li>
<li>The <strong>Physical Address</strong> is formed by combining the Frame Number and the Offset.</li>
</ol>
<p><strong>üõë Page Fault</strong></p>
<p>If the <strong>Valid Bit</strong> is 0, the page is not currently in memory. This triggers a <strong>Page Fault</strong>, and the operating system must load the page from disk into RAM.</p>
<p><strong>üß≠ Types of Page Tables</strong></p>
<ul>
<li><strong>Single-Level Page Table</strong>: Simple but not scalable for large address spaces.</li>
<li><strong>Multi-Level Page Table</strong>: Reduces memory usage by using a tree-like structure.</li>
<li><strong>Inverted Page Table</strong>: Indexes by physical frame instead of virtual page.</li>
<li><strong>Hashed Page Table</strong>: Used in systems with large address spaces (like 64-bit).</li>
</ul>
<p><strong>üìå Summary</strong></p>
<ul>
<li>Page Tables are essential for translating virtual to physical addresses.</li>
<li>They enable <strong>memory protection</strong>, <strong>process isolation</strong>, and <strong>efficient memory use</strong>.</li>
<li>Optimized with techniques like <strong>TLB</strong> (Translation Lookaside Buffer) to speed up address translation.</li>
</ul>
<p><img src="/img/concepts/tlb.svg" srcset="/img/loading.gif" lazyload alt="ËôöÂÆûÂú∞ÂùÄËΩ¨Êç¢" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="üß©-3-Types-of-Cache-Misses"><a href="#üß©-3-Types-of-Cache-Misses" class="headerlink" title="üß© 3 Types of Cache Misses"></a>üß© 3 Types of Cache Misses</h3><p>In computer architecture, a <strong>cache miss</strong> occurs when the data requested by the CPU is <strong>not found in the cache</strong>, requiring access to a slower memory level (like RAM). There are <strong>three main types</strong> of cache misses:</p>
<p><strong>üß† Summary Table</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>Cause</th>
<th>Possible Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Compulsory Miss</td>
<td>First-time access to a block</td>
<td>Prefetching, larger block size</td>
</tr>
<tr>
<td>Capacity Miss</td>
<td>Cache too small for working set</td>
<td>Larger cache, better algorithms</td>
</tr>
<tr>
<td>Conflict Miss</td>
<td>Blocks map to the same cache location</td>
<td>Higher associativity, alignment</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="1-Compulsory-Miss-a-k-a-Cold-Miss"><a href="#1-Compulsory-Miss-a-k-a-Cold-Miss" class="headerlink" title="1. Compulsory Miss (a.k.a. Cold Miss)"></a>1. <strong>Compulsory Miss</strong> (a.k.a. Cold Miss)</h3><p><strong>üîπ What is it?</strong></p>
<p>Occurs the <strong>first time</strong> a block is accessed and <strong>has never been loaded into the cache</strong> before.</p>
<p><strong>üß† Cause:</strong></p>
<ul>
<li>Cache is empty or data is accessed for the first time.</li>
</ul>
<p><strong>üìå Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Accessing array A[0] for the first time ‚Üí not in cache ‚Üí compulsory miss<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p><strong>‚úÖ Solution:</strong></p>
<ul>
<li>Prefetching</li>
<li>Larger block size (to bring in more adjacent data)</li>
</ul>
<hr>
<h3 id="2-Capacity-Miss"><a href="#2-Capacity-Miss" class="headerlink" title="2. Capacity Miss"></a>2. <strong>Capacity Miss</strong></h3><p><strong>üîπ What is it?</strong></p>
<p>Happens when the <strong>cache cannot contain all the needed data</strong>, and a previously loaded block gets evicted due to <strong>limited size</strong>.</p>
<p><strong>üß† Cause:</strong></p>
<ul>
<li>The working set is <strong>larger than the cache</strong>.</li>
</ul>
<p><strong>üìå Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Looping through a large dataset that exceeds cache size ‚Üí older blocks are evicted ‚Üí miss<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p><strong>‚úÖ Solution:</strong></p>
<ul>
<li>Increase cache size</li>
<li>Optimize algorithm locality</li>
</ul>
<hr>
<h3 id="3-Conflict-Miss-a-k-a-Collision-Miss"><a href="#3-Conflict-Miss-a-k-a-Collision-Miss" class="headerlink" title="3. Conflict Miss (a.k.a. Collision Miss)"></a><strong>3. Conflict Miss</strong> (a.k.a. Collision Miss)</h3><p><strong>üîπ What is it?</strong></p>
<p>Occurs when <strong>multiple blocks map to the same cache line</strong> (in set-associative or direct-mapped caches), causing <strong>unnecessary evictions</strong>.</p>
<p><strong>üß† Cause:</strong></p>
<ul>
<li>Limited associativity in the cache</li>
<li>Poor address mapping</li>
</ul>
<p><strong>üìå Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Accessing addresses A and B that both map to cache set 3 ‚Üí one evicts the other ‚Üí conflict miss<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p><strong>‚úÖ Solution:</strong></p>
<ul>
<li>Increase associativity</li>
<li>Use fully associative cache</li>
<li>Better hash functions or memory alignment</li>
</ul>
<hr>
<h3 id="üîó-Four-Types-of-Data-Dependencies-in-Computer-Architecture"><a href="#üîó-Four-Types-of-Data-Dependencies-in-Computer-Architecture" class="headerlink" title="üîó Four Types of Data Dependencies in Computer Architecture"></a>üîó Four Types of Data Dependencies in Computer Architecture</h3><p>In pipelined processors, <strong>data dependencies</strong> occur when instructions depend on the results of previous instructions. These dependencies can cause <strong>pipeline hazards</strong> and impact instruction-level parallelism.</p>
<p>There are <strong>four types</strong> of data dependencies:</p>
<p><strong>üìä Summary Table</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>Abbreviation</th>
<th>Cause</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Flow Dependency</td>
<td>RAW</td>
<td>Read after write</td>
<td>Forwarding, Stall</td>
</tr>
<tr>
<td>Anti Dependency</td>
<td>WAR</td>
<td>Write after read</td>
<td>Register renaming</td>
</tr>
<tr>
<td>Output Dependency</td>
<td>WAW</td>
<td>Write after write</td>
<td>Register renaming, in-order commit</td>
</tr>
<tr>
<td>Control Dependency</td>
<td>‚Äì</td>
<td>Depends on branch outcome</td>
<td>Branch prediction, speculation</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="1-Flow-Dependency-Read-After-Write-RAW"><a href="#1-Flow-Dependency-Read-After-Write-RAW" class="headerlink" title="1. Flow Dependency (Read After Write, RAW)"></a>1. <strong>Flow Dependency</strong> (Read After Write, <strong>RAW</strong>)</h3><p><strong>üîπ What is it?</strong></p>
<p>Occurs when an instruction needs to <strong>read a value</strong> that has not yet been <strong>written</strong> by a previous instruction.</p>
<p><strong>üß† Cause:</strong></p>
<ul>
<li>The second instruction <strong>depends</strong> on the result of the first.</li>
</ul>
<p><strong>üìå Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">I1: R1 ‚Üê R2 + R3
I2: R4 ‚Üê R1 + R5   ; RAW: I2 reads R1 before I1 writes it<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>‚úÖ Solution:</strong></p>
<ul>
<li><strong>Forwarding/Bypassing</strong></li>
<li><strong>Stalling</strong> the pipeline</li>
</ul>
<hr>
<h3 id="2-Anti-Dependency-Write-After-Read-WAR"><a href="#2-Anti-Dependency-Write-After-Read-WAR" class="headerlink" title="2. Anti Dependency (Write After Read, WAR)"></a>2. <strong>Anti Dependency</strong> (Write After Read, <strong>WAR</strong>)</h3><p><strong>üîπ What is it?</strong></p>
<p>Occurs when a later instruction <strong>writes</strong> to a location that a previous instruction still needs to <strong>read</strong> from.</p>
<p><strong>üß† Cause:</strong></p>
<ul>
<li>The second instruction must <strong>not overwrite</strong> the value too early.</li>
</ul>
<p><strong>üìå Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">I1: R4 ‚Üê R1 + R2   ; Reads R1
I2: R1 ‚Üê R3 + R5   ; WAR: I2 writes R1 before I1 finishes reading<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>‚úÖ Solution:</strong></p>
<ul>
<li><strong>Register renaming</strong></li>
</ul>
<hr>
<h3 id="3-Output-Dependency-Write-After-Write-WAW"><a href="#3-Output-Dependency-Write-After-Write-WAW" class="headerlink" title="3. Output Dependency (Write After Write, WAW)"></a>3. <strong>Output Dependency</strong> (Write After Write, <strong>WAW</strong>)</h3><p><strong>üîπ What is it?</strong></p>
<p>Occurs when two instructions <strong>write</strong> to the <strong>same destination</strong>, and the final result must reflect the correct write order.</p>
<p><strong>üß† Cause:</strong></p>
<ul>
<li>Later instruction must not overwrite an earlier write <strong>out of order</strong>.</li>
</ul>
<p><strong>üìå Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">I1: R1 ‚Üê R2 + R3
I2: R1 ‚Üê R4 + R5   ; WAW: I2 writes R1 before I1 completes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>‚úÖ Solution:</strong></p>
<ul>
<li><strong>Register renaming</strong></li>
<li><strong>In-order commit</strong> in out-of-order execution</li>
</ul>
<hr>
<h3 id="4-Control-Dependency"><a href="#4-Control-Dependency" class="headerlink" title="4. Control Dependency"></a>4. <strong>Control Dependency</strong></h3><p><strong>üîπ What is it?</strong></p>
<p>Occurs when the <strong>execution</strong> of an instruction depends on the <strong>outcome of a branch</strong>.</p>
<p><strong>üß† Cause:</strong></p>
<ul>
<li>It‚Äôs not clear <strong>whether to execute</strong> the instruction until the branch is resolved.</li>
</ul>
<p><strong>üìå Example:</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-asm" data-language="asm"><code class="language-asm">I1: if (R1 &#x3D;&#x3D; 0) goto LABEL
I2: R2 ‚Üê R3 + R4   ; Control dependent on I1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><strong>‚úÖ Solution:</strong></p>
<ul>
<li><strong>Branch prediction</strong></li>
<li><strong>Speculative execution</strong></li>
</ul>
<hr>
<h3 id="MicroprogrammingÔºàÂæÆÁ®ãÂ∫èËÆæËÆ°Ôºâ"><a href="#MicroprogrammingÔºàÂæÆÁ®ãÂ∫èËÆæËÆ°Ôºâ" class="headerlink" title="MicroprogrammingÔºàÂæÆÁ®ãÂ∫èËÆæËÆ°Ôºâ"></a>MicroprogrammingÔºàÂæÆÁ®ãÂ∫èËÆæËÆ°Ôºâ</h3><p><strong>Microprogramming</strong> is a method of implementing a CPU‚Äôs control unit using <strong>a sequence of microinstructions</strong> stored in a special memory called <strong>control memory</strong>.<br>Each <strong>microinstruction</strong> specifies low-level operations like setting control signals, reading/writing registers, or ALU actions.<br>It acts as an intermediate layer between machine instructions and hardware control signals.<br>There are two types of control units: <strong>hardwired control</strong> and <strong>microprogrammed control</strong> ‚Äî the latter is easier to modify and extend.<br>Microprogramming was widely used in classic CISC architectures like IBM System/360.</p>
<hr>
<h3 id="Snoopy-CacheÔºàÁõëÂê¨ÂºèÁºìÂ≠òÔºâ"><a href="#Snoopy-CacheÔºàÁõëÂê¨ÂºèÁºìÂ≠òÔºâ" class="headerlink" title="Snoopy CacheÔºàÁõëÂê¨ÂºèÁºìÂ≠òÔºâ"></a>Snoopy CacheÔºàÁõëÂê¨ÂºèÁºìÂ≠òÔºâ</h3><p><strong>Snoopy Cache</strong> is a cache coherence protocol used in <strong>multiprocessor systems</strong> to maintain data consistency among multiple caches.<br>Each cache monitors (or ‚Äúsnoops‚Äù) a shared communication bus to detect if other processors are reading or writing a memory block it has cached.<br>If a write is detected, the snooping cache can <strong>invalidate</strong> or <strong>update</strong> its own copy to keep data coherent.<br>This ensures that all processors work with the <strong>most recent version</strong> of data.<br>Common snoopy-based protocols include <strong>MSI</strong>, <strong>MESI</strong>, and <strong>MOESI</strong>.</p>
<p><strong>Snoopy CacheÔºàÁõëÂê¨ÂºèÁºìÂ≠òÔºâ</strong>ÊòØ‰∏ÄÁßçÁî®‰∫é<strong>Â§öÂ§ÑÁêÜÂô®Á≥ªÁªü</strong>ÁöÑÁºìÂ≠ò‰∏ÄËá¥ÊÄßÂçèËÆÆÔºåÁî®‰∫é‰øùÊåÅÂ§ö‰∏™ÁºìÂ≠ò‰πãÈó¥ÁöÑÊï∞ÊçÆ‰∏ÄËá¥ÊÄß„ÄÇ<br>ÊØè‰∏™ÁºìÂ≠ò‰ºöÁõëÂê¨ÔºàsnoopÔºâÂÖ±‰∫´ÊÄªÁ∫øÔºåÊ£ÄÊµãÂÖ∂‰ªñÂ§ÑÁêÜÂô®ÊòØÂê¶Âú®ËØªÂèñÊàñÂÜôÂÖ•ÂÆÉÁºìÂ≠ò‰∏≠ÁöÑÊï∞ÊçÆÂùó„ÄÇ<br>ÂΩìÊ£ÄÊµãÂà∞ÂÜôÊìç‰ΩúÊó∂ÔºåÁõëÂê¨ÁºìÂ≠ò‰ºö<strong>Êõ¥Êñ∞</strong>Êàñ<strong>Êó†ÊïàÂåñ</strong>Ëá™Â∑±ÁöÑÂâØÊú¨Ôºå‰ª•‰øùÊåÅÊï∞ÊçÆÁöÑ‰∏ÄËá¥ÊÄß„ÄÇ<br>ËøôÊ†∑ÂèØ‰ª•Á°Æ‰øùÊâÄÊúâÂ§ÑÁêÜÂô®‰ΩøÁî®ÁöÑÈÉΩÊòØ<strong>ÊúÄÊñ∞ÁâàÊú¨ÁöÑÊï∞ÊçÆ</strong>„ÄÇ<br>Â∏∏ËßÅÁöÑÁõëÂê¨ÂºèÂçèËÆÆÂåÖÊã¨ <strong>MSI</strong>„ÄÅ<strong>MESI</strong> Âíå <strong>MOESI</strong> ÂçèËÆÆ„ÄÇ</p>
<hr>
<h3 id="Out-of-order-Execution-‰π±Â∫èÊâßË°å"><a href="#Out-of-order-Execution-‰π±Â∫èÊâßË°å" class="headerlink" title="Out-of-order Execution (‰π±Â∫èÊâßË°å)"></a>Out-of-order Execution (‰π±Â∫èÊâßË°å)</h3><p><strong>Out-of-order execution</strong> is a technique used in modern processors to improve performance by allowing instructions to be executed <strong>out of the order they appear</strong> in the program.<br>Instead of waiting for earlier instructions to complete (which might be delayed due to data hazards or memory stalls), the CPU executes instructions that are ready and independent of others.<br>This reduces <strong>idle CPU time</strong> and <strong>increases throughput</strong> by utilizing all available execution units.<br>Dependencies between instructions are tracked, and results are committed in the correct order.<br>Out-of-order execution is common in <strong>superscalar processors</strong> and is part of <strong>dynamic instruction scheduling</strong>.</p>
<p><strong>‰π±Â∫èÊâßË°å</strong>ÊòØ‰∏ÄÁßçÁé∞‰ª£Â§ÑÁêÜÂô®‰∏≠Â∏∏Áî®ÁöÑÊäÄÊúØÔºåÈÄöËøáÂÖÅËÆ∏Êåá‰ª§<strong>ÊåâÈùûÈ°∫Â∫è</strong>ÁöÑÊñπÂºèÊâßË°åÊù•ÊèêÂçáÊÄßËÉΩ„ÄÇ<br>CPU ‰∏çÂøÖÁ≠âÂæÖÂâçÈù¢ÁöÑÊåá‰ª§ÂÆåÊàêÔºàËøô‰∫õÊåá‰ª§ÂèØËÉΩÂõ†‰∏∫Êï∞ÊçÆ‰æùËµñÊàñÂÜÖÂ≠òÂª∂ËøüËÄåË¢´ÊãñÊÖ¢ÔºâÔºåËÄåÊòØÊâßË°åÈÇ£‰∫õÂáÜÂ§áÂ•Ω‰∏îÁõ∏‰∫íÁã¨Á´ãÁöÑÊåá‰ª§„ÄÇ<br>ËøôÊ†∑ÂèØ‰ª•ÂáèÂ∞ë<strong>CPUÁ©∫Èó≤Êó∂Èó¥</strong>Âπ∂<strong>Â¢ûÂä†ÂêûÂêêÈáè</strong>ÔºåÂÖÖÂàÜÂà©Áî®ÊâÄÊúâÂèØÁî®ÁöÑÊâßË°åÂçïÂÖÉ„ÄÇ<br>Êåá‰ª§‰πãÈó¥ÁöÑ‰æùËµñÂÖ≥Á≥ª‰ºöË¢´ËøΩË∏™ÔºåÁªìÊûú‰ºöÊåâÊ≠£Á°ÆÁöÑÈ°∫Â∫èÊèê‰∫§„ÄÇ<br>‰π±Â∫èÊâßË°åÂú®<strong>Ë∂ÖÊ†áÈáèÂ§ÑÁêÜÂô®</strong>‰∏≠ÂæàÂ∏∏ËßÅÔºåÂπ∂‰∏îÊòØ<strong>Âä®ÊÄÅÊåá‰ª§Ë∞ÉÂ∫¶</strong>ÁöÑ‰∏ÄÈÉ®ÂàÜ„ÄÇ</p>
<hr>
<h3 id="DMA-Direct-Memory-Access"><a href="#DMA-Direct-Memory-Access" class="headerlink" title="DMA (Direct Memory Access)"></a>DMA (Direct Memory Access)</h3><p><strong>DMA</strong> stands for <strong>Direct Memory Access</strong>, a feature that allows certain hardware components (like disk controllers or network cards) to <strong>transfer data directly to/from main memory</strong> without involving the CPU.<br>This improves system efficiency by <strong>freeing the CPU</strong> from managing large or repetitive data transfers.<br>A <strong>DMA controller</strong> handles the data movement and signals the CPU when the transfer is complete.<br>DMA is commonly used for tasks like <strong>disk I/O</strong>, <strong>audio/video streaming</strong>, and <strong>network communication</strong>.<br>It helps achieve <strong>high-speed data transfer</strong> with minimal CPU overhead.</p>
<p><strong>DMA</strong> ÊòØ <strong>Áõ¥Êé•ÂÜÖÂ≠òËÆøÈóÆÔºàDirect Memory AccessÔºâ</strong> ÁöÑÁº©ÂÜôÔºåÊòØ‰∏ÄÁßçÂÖÅËÆ∏Êüê‰∫õÁ°¨‰ª∂ÁªÑ‰ª∂ÔºàÂ¶ÇÁ£ÅÁõòÊéßÂà∂Âô®ÊàñÁΩëÂç°Ôºâ<strong>Âú®‰∏çÁªèËøá CPU ÁöÑÊÉÖÂÜµ‰∏ãÁõ¥Êé•‰∏é‰∏ªÂ≠òËøõË°åÊï∞ÊçÆ‰º†Ëæì</strong>ÁöÑÊäÄÊúØ„ÄÇ<br>ÂÆÉÈÄöËøá<strong>ÂáèËΩª CPU ÁöÑÊï∞ÊçÆÊê¨ËøêË¥üÊãÖ</strong>ÔºåÊèêÈ´ò‰∫ÜÁ≥ªÁªüÊïàÁéá„ÄÇ<br>Êï∞ÊçÆ‰º†ËæìÁî±‰∏Ä‰∏™ <strong>DMA ÊéßÂà∂Âô®</strong>Ë¥üË¥£Ôºå‰º†ËæìÂÆåÊàêÂêé‰ºöÈÄöÁü• CPU„ÄÇ<br>DMA ÂπøÊ≥õÂ∫îÁî®‰∫é <strong>Á£ÅÁõò I/O</strong>„ÄÅ<strong>Èü≥ËßÜÈ¢ëÊµÅÂ§ÑÁêÜ</strong> Âíå <strong>ÁΩëÁªúÈÄö‰ø°</strong> Á≠âÈ¢ÜÂüü„ÄÇ<br>ÂÆÉËÉΩ‰ª•<strong>ÊûÅ‰ΩéÁöÑ CPU ÂºÄÈîÄÂÆûÁé∞È´òÈÄüÊï∞ÊçÆ‰º†Ëæì</strong>„ÄÇ</p>
<hr>
<h3 id="RISC-Reduced-Instruction-Set-Computing"><a href="#RISC-Reduced-Instruction-Set-Computing" class="headerlink" title="RISC (Reduced Instruction Set Computing)"></a>RISC (Reduced Instruction Set Computing)</h3><p><strong>RISC</strong> stands for <strong>Reduced Instruction Set Computing</strong>, a CPU design strategy that uses a <strong>small set of simple and fast instructions</strong>.<br>Each instruction typically executes in <strong>one clock cycle</strong>, allowing efficient pipelining and parallelism.<br>RISC emphasizes <strong>hardware simplicity</strong>, <strong>fixed instruction length</strong>, and <strong>a load/store architecture</strong>.<br>It is well-suited for modern compilers and high-performance applications.<br>Examples: <strong>ARM</strong>, <strong>RISC-V</strong>, <strong>MIPS</strong>.</p>
<p><strong>RISC</strong> ÊòØ <strong>Á≤æÁÆÄÊåá‰ª§ÈõÜËÆ°ÁÆóÔºàReduced Instruction Set ComputingÔºâ</strong> ÁöÑÁº©ÂÜôÔºåÊòØ‰∏ÄÁßç‰ΩøÁî®<strong>Â∞ëÈáèÁÆÄÂçïÊåá‰ª§</strong>ÁöÑ CPU ËÆæËÆ°ÁêÜÂøµ„ÄÇ<br>ÊØèÊù°Êåá‰ª§ÈÄöÂ∏∏Âú®<strong>‰∏Ä‰∏™Êó∂ÈíüÂë®ÊúüÂÜÖÂÆåÊàê</strong>Ôºå‰æø‰∫éÂÆûÁé∞ÊµÅÊ∞¥Á∫øÂíåÂπ∂Ë°åÂ§ÑÁêÜ„ÄÇ<br>RISC Âº∫Ë∞É<strong>Á°¨‰ª∂ÁÆÄÂåñ</strong>„ÄÅ<strong>Âõ∫ÂÆöÈïøÂ∫¶Êåá‰ª§</strong>‰ª•Âèä<strong>Load/Store Êû∂ÊûÑ</strong>„ÄÇ<br>ËøôÁßçÊû∂ÊûÑÈùûÂ∏∏ÈÄÇÂêàÁé∞‰ª£ÁºñËØëÂô®ÂíåÈ´òÊÄßËÉΩÂ∫îÁî®„ÄÇ<br>‰ª£Ë°®Êû∂ÊûÑÔºö<strong>ARM</strong>„ÄÅ<strong>RISC-V</strong>„ÄÅ<strong>MIPS</strong>„ÄÇ</p>
<hr>
<h3 id="CISC-Complex-Instruction-Set-Computing"><a href="#CISC-Complex-Instruction-Set-Computing" class="headerlink" title="CISC (Complex Instruction Set Computing)"></a>CISC (Complex Instruction Set Computing)</h3><p><strong>CISC</strong> stands for <strong>Complex Instruction Set Computing</strong>, which uses a <strong>large and versatile set of instructions</strong>, where some instructions perform <strong>multi-step operations</strong>.<br>This design reduces the number of instructions per program but increases the complexity of the CPU.<br>CISC instructions often have <strong>variable lengths</strong> and require <strong>multiple clock cycles</strong> to execute.<br>It was originally designed to minimize memory usage and support simpler compilers.<br>Example: <strong>x86 architecture</strong> (Intel, AMD).</p>
<p><strong>CISC</strong> ÊòØ <strong>Â§çÊùÇÊåá‰ª§ÈõÜËÆ°ÁÆóÔºàComplex Instruction Set ComputingÔºâ</strong> ÁöÑÁº©ÂÜôÔºåÈááÁî®<strong>Êï∞ÈáèÂ§ö„ÄÅÂäüËÉΩÂº∫ÁöÑÊåá‰ª§ÈõÜ</strong>ÔºåÂÖ∂‰∏≠‰∏Ä‰∫õÊåá‰ª§ËÉΩÂÆåÊàê<strong>Â§ö‰∏™‰ΩéÂ±ÇÊ¨°Êìç‰Ωú</strong>„ÄÇ<br>ËøôÁßçËÆæËÆ°ÂèØ‰ª•ÂáèÂ∞ëÁ®ãÂ∫è‰∏≠ÊâÄÈúÄÁöÑÊåá‰ª§Êï∞ÈáèÔºå‰ΩÜ‰ºöÂ¢ûÂä† CPU ÁöÑÂÆûÁé∞Â§çÊùÇÂ∫¶„ÄÇ<br>CISC Êåá‰ª§ÈÄöÂ∏∏ÊòØ<strong>‰∏çÂõ∫ÂÆöÈïøÂ∫¶</strong>ÔºåÂπ∂‰∏îÊâßË°åÊó∂<strong>ÂèØËÉΩÈúÄË¶ÅÂ§ö‰∏™Êó∂ÈíüÂë®Êúü</strong>„ÄÇ<br>ÂÆÉÊúÄÂàù‰∏∫‰∫ÜÂáèÂ∞ëÂÜÖÂ≠ò‰ΩøÁî®„ÄÅ‰æø‰∫éÊó©ÊúüÁºñËØëÂô®ËÆæËÆ°ËÄåÊèêÂá∫„ÄÇ<br>‰ª£Ë°®Êû∂ÊûÑÔºö<strong>x86 Êû∂ÊûÑ</strong>ÔºàÂ¶Ç Intel Âíå AMD Â§ÑÁêÜÂô®Ôºâ„ÄÇ</p>
<hr>
<h3 id="SIMD-Single-Instruction-Multiple-Data"><a href="#SIMD-Single-Instruction-Multiple-Data" class="headerlink" title="SIMD (Single Instruction, Multiple Data)"></a>SIMD (Single Instruction, Multiple Data)</h3><p><strong>SIMD</strong> stands for <strong>Single Instruction, Multiple Data</strong>, a parallel computing model where <strong>one instruction</strong> operates on <strong>multiple data elements simultaneously</strong>.<br>It is especially useful for tasks like <strong>image processing</strong>, <strong>audio/video encoding</strong>, <strong>machine learning</strong>, and <strong>scientific computing</strong>.<br>SIMD improves performance by exploiting <strong>data-level parallelism</strong>.<br>Modern CPUs include SIMD instruction sets such as <strong>SSE</strong>, <strong>AVX</strong> (Intel/AMD), and <strong>NEON</strong> (ARM).<br>It is a core concept in <strong>vector processing</strong> and used in <strong>GPUs</strong> as well.</p>
<p><strong>SIMD</strong> ÊòØ <strong>ÂçïÊåá‰ª§Â§öÊï∞ÊçÆÊµÅÔºàSingle Instruction, Multiple DataÔºâ</strong> ÁöÑÁº©ÂÜôÔºåÊòØ‰∏ÄÁßçÂπ∂Ë°åËÆ°ÁÆóÊ®°ÂûãÔºåÂÖ∂‰∏≠<strong>‰∏ÄÊù°Êåá‰ª§</strong>ÂèØ‰ª•ÂêåÊó∂‰ΩúÁî®‰∫é<strong>Â§ö‰∏™Êï∞ÊçÆÂÖÉÁ¥†</strong>„ÄÇ<br>ÂÆÉÈùûÂ∏∏ÈÄÇÁî®‰∫éÂõæÂÉèÂ§ÑÁêÜ„ÄÅÈü≥ËßÜÈ¢ëÁºñËß£Á†Å„ÄÅÊú∫Âô®Â≠¶‰π†ÂíåÁßëÂ≠¶ËÆ°ÁÆóÁ≠âÂú∫ÊôØ„ÄÇ<br>SIMD ÈÄöËøáÊåñÊéòÊï∞ÊçÆÁ∫ßÂπ∂Ë°åÊÄßÔºàData-level ParallelismÔºâÊù•ÊèêÂçáÊÄßËÉΩ„ÄÇ<br>Áé∞‰ª£ CPU Êèê‰æõ‰∫Ü SIMD Êåá‰ª§ÈõÜÔºåÂ¶Ç <strong>SSE</strong>„ÄÅ<strong>AVX</strong>ÔºàIntel/AMDÔºâÂíå <strong>NEON</strong>ÔºàARMÔºâ„ÄÇ<br>ÂÆÉÊòØÂêëÈáèÂ§ÑÁêÜÔºàVector ProcessingÔºâÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÔºåÂπ∂ÂπøÊ≥õÁî®‰∫é <strong>GPU</strong> ‰∏≠„ÄÇ</p>
<h2 id="4-Formal-Language-amp-Automata"><a href="#4-Formal-Language-amp-Automata" class="headerlink" title="4. Formal Language &amp; Automata"></a>4. Formal Language &amp; Automata</h2><h3 id="Regular-Grammar"><a href="#Regular-Grammar" class="headerlink" title="Regular Grammar"></a>Regular Grammar</h3><p>A <strong>Regular Grammar</strong> is the simplest type of grammar in the Chomsky hierarchy. It is used to define <strong>regular languages</strong>, which can also be recognized by <strong>finite automata</strong>. Regular grammars are widely used in lexical analysis, pattern matching, and simple parsing tasks.</p>
<p><strong>üìò Definition</strong></p>
<p>A <strong>Regular Grammar</strong> is a type of <strong>context-free grammar (CFG)</strong> with special restrictions on its production rules. It consists of:</p>
<ul>
<li>A finite set of <strong>non-terminal symbols</strong></li>
<li>A finite set of <strong>terminal symbols</strong></li>
<li>A <strong>start symbol</strong></li>
<li>A finite set of <strong>production rules</strong></li>
</ul>
<p><strong>üßæ Types of Regular Grammar</strong></p>
<p>There are <strong>two forms</strong> of regular grammars:</p>
<ol>
<li><strong>Right-Linear Grammar</strong></li>
</ol>
<p>All production rules are of the form:</p>
<ul>
<li>$A \rightarrow aB$</li>
<li>$A \rightarrow a$</li>
<li>$A \rightarrow \varepsilon$ (optional for generating empty string)</li>
</ul>
<p>Where:</p>
<ul>
<li>$A, B$ are non-terminal symbols</li>
<li>$a$ is a terminal symbol</li>
</ul>
<p>‚úÖ This is the <strong>most common</strong> form used to generate regular languages.</p>
<ol>
<li><strong>Left-Linear Grammar</strong></li>
</ol>
<p>All production rules are of the form:</p>
<ul>
<li>$A \rightarrow Ba$</li>
<li>$A \rightarrow a$</li>
<li>$A \rightarrow \varepsilon$</li>
</ul>
<p>Both right-linear and left-linear grammars generate <strong>regular languages</strong>, but <strong>mixing them is not allowed</strong> in regular grammar.</p>
<p><strong>üßÆ Example of a Right-Linear Grammar</strong></p>
<p>Let‚Äôs define a grammar for the regular language $L = { a^n b \mid n \geq 0 }$:</p>
<p><strong>Non-terminals</strong>: ${S, A}$<br><strong>Terminals</strong>: ${a, b}$<br><strong>Start symbol</strong>: $S$<br><strong>Production rules</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">S ‚Üí aS  
S ‚Üí b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p>This generates strings like:</p>
<ul>
<li><code>b</code></li>
<li><code>ab</code></li>
<li><code>aab</code></li>
<li><code>aaab</code>, etc.</li>
</ul>
<p><strong>ü§ñ Equivalent Automata</strong></p>
<p>Every regular grammar corresponds to a <strong>finite automaton</strong>, and vice versa:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Regular Grammar</td>
<td>Generates strings by rules</td>
</tr>
<tr>
<td>Finite Automaton</td>
<td>Accepts strings by state transitions</td>
</tr>
</tbody>
</table>
</div>
<p>So, regular grammar and finite automaton are <strong>equivalent in expressive power</strong>.</p>
<p><strong>üìä Closure Properties</strong></p>
<p>Regular grammars inherit all the closure properties of regular languages:</p>
<ul>
<li>‚úÖ Union</li>
<li>‚úÖ Concatenation</li>
<li>‚úÖ Kleene Star</li>
<li>‚úÖ Intersection with regular sets</li>
<li>‚úÖ Complement</li>
</ul>
<p><strong>üö´ Limitations</strong></p>
<ul>
<li>Cannot handle <strong>nested structures</strong> (e.g., balanced parentheses)</li>
<li>Cannot count or match multiple dependencies (e.g., $a^n b^n$)</li>
</ul>
<p><strong>‚úÖ Summary</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Regular Grammar</th>
</tr>
</thead>
<tbody>
<tr>
<td>Structure</td>
<td>Right- or left-linear rules</td>
</tr>
<tr>
<td>Generates</td>
<td>Regular languages</td>
</tr>
<tr>
<td>Equivalent to</td>
<td>Finite Automaton</td>
</tr>
<tr>
<td>Used in</td>
<td>Lexical analysis, pattern matching</td>
</tr>
<tr>
<td>Can generate $a^n$</td>
<td>‚úÖ Yes</td>
</tr>
<tr>
<td>Can generate $a^n b^n$</td>
<td>‚ùå No</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="Regular-Language"><a href="#Regular-Language" class="headerlink" title="Regular Language"></a>Regular Language</h3><p>A <strong>Regular Language</strong> is a class of formal languages that can be <strong>recognized by finite automata</strong>. It can be described by:</p>
<ul>
<li><strong>Deterministic Finite Automata (DFA)</strong></li>
<li><strong>Non-deterministic Finite Automata (NFA)</strong></li>
<li><strong>Regular expressions</strong></li>
</ul>
<p>If a language can be represented using any of the above methods, it is a <strong>regular language</strong>.</p>
<p><strong>üîπ Examples</strong></p>
<ol>
<li><p>Language of all strings over <code>&#123;a, b&#125;</code> that contain <strong>only</strong> <code>a</code>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">L &#x3D; &#123; Œµ, a, aa, aaa, ... &#125; &#x3D; a*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
</li>
<li><p>Language of all strings that start with <code>a</code> and end with <code>b</code>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">L &#x3D; a(a|b)*b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
</li>
<li><p>Language of all strings with even number of <code>0</code>s over <code>&#123;0,1&#125;</code>:</p>
<ul>
<li>This can be recognized by a DFA with two states toggling on <code>0</code>.</li>
</ul>
</li>
</ol>
<ul>
<li><p>They can be <strong>expressed using regular expressions</strong>, and there is an equivalence between:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">DFA ‚áÑ NFA ‚áÑ Regular Expression<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
</li>
</ul>
<hr>
<h3 id="Non-Regular-Languages"><a href="#Non-Regular-Languages" class="headerlink" title="Non-Regular Languages"></a>Non-Regular Languages</h3><p>Some languages <strong>cannot</strong> be described by regular expressions or finite automata. For example:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">L &#x3D; &#123; a‚Åøb‚Åø | n ‚â• 0 &#125;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>This language requires memory to keep track of the number of <code>a</code>s and <code>b</code>s, which finite automata do not have.</p>
<p>To prove that a language is <strong>not regular</strong>, we can use the <strong>Pumping Lemma</strong>, which states:</p>
<p>If a language <code>L</code> is regular, there exists an integer <code>p &gt; 0</code> (pumping length) such that any string <code>s ‚àà L</code> with length ‚â• <code>p</code> can be split into <code>s = xyz</code> such that:</p>
<ul>
<li>|y| &gt; 0</li>
<li>|xy| ‚â§ p</li>
<li>For all <code>i ‚â• 0</code>, the string <code>xy‚Å±z ‚àà L</code></li>
</ul>
<p>If no such decomposition exists for a string, the language is <strong>not regular</strong>.</p>
<hr>
<h3 id="Closure-Properties-of-Regular-Languages"><a href="#Closure-Properties-of-Regular-Languages" class="headerlink" title="Closure Properties of Regular Languages"></a>Closure Properties of Regular Languages</h3><blockquote>
<p>üîπ What is ‚ÄúClosure‚Äù?</p>
</blockquote>
<p>In automata theory, a class of languages is said to be <strong>closed under an operation</strong> if <strong>applying that operation</strong> to languages in the class <strong>results in a language that is also in the class</strong>.</p>
<p>For <strong>regular languages</strong>, they are closed under many operations. This means if you take <strong>regular languages</strong> and apply these operations, the result will <strong>still be a regular language</strong>.</p>
<blockquote>
<p>üîπ Closure Under Common Operations</p>
</blockquote>
<div class="table-container">
<table>
<thead>
<tr>
<th>Operation</th>
<th>Description</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Union</strong></td>
<td>If L‚ÇÅ and L‚ÇÇ are regular, then L‚ÇÅ ‚à™ L‚ÇÇ is also regular.</td>
<td>‚úÖ Regular</td>
</tr>
<tr>
<td><strong>Intersection</strong></td>
<td>If L‚ÇÅ and L‚ÇÇ are regular, then L‚ÇÅ ‚à© L‚ÇÇ is also regular.</td>
<td>‚úÖ Regular</td>
</tr>
<tr>
<td><strong>Complement</strong></td>
<td>If L is regular, then its complement ¬¨L is also regular.</td>
<td>‚úÖ Regular</td>
</tr>
<tr>
<td><strong>Concatenation</strong></td>
<td>If L‚ÇÅ and L‚ÇÇ are regular, then L‚ÇÅL‚ÇÇ is also regular.</td>
<td>‚úÖ Regular</td>
</tr>
<tr>
<td><strong>Kleene Star</strong></td>
<td>If L is regular, then L* (zero or more repetitions) is also regular.</td>
<td>‚úÖ Regular</td>
</tr>
<tr>
<td><strong>Reversal</strong></td>
<td>If L is regular, then the reverse of L is also regular.</td>
<td>‚úÖ Regular</td>
</tr>
<tr>
<td><strong>Difference</strong></td>
<td>If L‚ÇÅ and L‚ÇÇ are regular, then L‚ÇÅ - L‚ÇÇ is also regular.</td>
<td>‚úÖ Regular</td>
</tr>
<tr>
<td><strong>Homomorphism</strong></td>
<td>Applying a homomorphism to a regular language gives a regular language.</td>
<td>‚úÖ Regular</td>
</tr>
<tr>
<td><strong>Inverse Homomorphism</strong></td>
<td>Inverse images of regular languages under homomorphisms are regular.</td>
<td>‚úÖ Regular</td>
</tr>
<tr>
<td><strong>Substitution</strong></td>
<td>Regular languages are closed under substitution with regular languages.</td>
<td>‚úÖ Regular</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>üîπ Example: Union Closure</p>
</blockquote>
<p>Let:</p>
<ul>
<li>L‚ÇÅ = { w | w contains only a‚Äôs } = <code>a*</code></li>
<li>L‚ÇÇ = { w | w contains only b‚Äôs } = <code>b*</code></li>
</ul>
<p>Then:</p>
<ul>
<li>L‚ÇÅ ‚à™ L‚ÇÇ = { w | w contains only a‚Äôs or only b‚Äôs } = <code>a* ‚à™ b*</code></li>
<li>This is still a regular language.</li>
</ul>
<blockquote>
<p>üîπ Why Closure is Useful</p>
</blockquote>
<ul>
<li>Closure properties help us <strong>construct complex regular languages</strong> from simpler ones.</li>
<li>They are essential in <strong>proving properties</strong> of languages.</li>
<li>They are used in <strong>compiler design</strong>, <strong>regex engines</strong>, and <strong>automated verification</strong>.</li>
</ul>
<hr>
<h3 id="ü§ñ-DFA-Deterministic-Finite-Automaton"><a href="#ü§ñ-DFA-Deterministic-Finite-Automaton" class="headerlink" title="ü§ñ DFA (Deterministic Finite Automaton)"></a>ü§ñ DFA (Deterministic Finite Automaton)</h3><p><strong>üîπ Definition</strong></p>
<p>A <strong>DFA</strong> is a type of <strong>finite automaton</strong> used to <strong>recognize regular languages</strong>. It reads an input string <strong>symbol by symbol</strong>, and <strong>at any point</strong> in time, it is in <strong>exactly one state</strong>.</p>
<p>A DFA is defined as a <strong>5-tuple</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">DFA &#x3D; (Q, Œ£, Œ¥, q‚ÇÄ, F)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Where:</p>
<ul>
<li><code>Q</code> ‚Üí Finite set of <strong>states</strong></li>
<li><code>Œ£</code> ‚Üí Finite set of <strong>input symbols</strong> (alphabet)</li>
<li><code>Œ¥</code> ‚Üí <strong>Transition function</strong>: Œ¥ : Q √ó Œ£ ‚Üí Q</li>
<li><code>q‚ÇÄ</code> ‚Üí <strong>Start state</strong>, where the computation begins (<code>q‚ÇÄ ‚àà Q</code>)</li>
<li><code>F</code> ‚Üí Set of <strong>accepting/final states</strong> (<code>F ‚äÜ Q</code>)</li>
</ul>
<p><strong>üîπ Characteristics</strong></p>
<ul>
<li><strong>Deterministic</strong>: For every state <code>q ‚àà Q</code> and every input symbol <code>a ‚àà Œ£</code>, <strong>there is exactly one transition</strong> defined:<br>Œ¥(q, a) = q‚Äô</li>
<li><strong>No epsilon (Œµ) transitions</strong>: Input must be read <strong>one symbol at a time</strong></li>
<li>DFA <strong>always knows</strong> what to do next</li>
</ul>
<p><strong>üîπ Example DFA</strong></p>
<p>Let‚Äôs define a DFA that accepts all strings over <code>&#123;0,1&#125;</code> that end with <code>01</code>.</p>
<ul>
<li><code>Q = &#123;q0, q1, q2&#125;</code></li>
<li><code>Œ£ = &#123;0, 1&#125;</code></li>
<li><code>q‚ÇÄ = q0</code></li>
<li><code>F = &#123;q2&#125;</code></li>
</ul>
<p>Transition table:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Current State</th>
<th>Input</th>
<th>Next State</th>
</tr>
</thead>
<tbody>
<tr>
<td>q0</td>
<td>0</td>
<td>q1</td>
</tr>
<tr>
<td>q0</td>
<td>1</td>
<td>q0</td>
</tr>
<tr>
<td>q1</td>
<td>0</td>
<td>q1</td>
</tr>
<tr>
<td>q1</td>
<td>1</td>
<td>q2</td>
</tr>
<tr>
<td>q2</td>
<td>0</td>
<td>q1</td>
</tr>
<tr>
<td>q2</td>
<td>1</td>
<td>q0</td>
</tr>
</tbody>
</table>
</div>
<p>This DFA accepts strings like: <code>01</code>, <code>1001</code>, <code>1101</code>, etc.</p>
<p><strong>üîπ DFA vs NFA</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>DFA</th>
<th>NFA</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transition</td>
<td>One unique next state</td>
<td>May have multiple next states</td>
</tr>
<tr>
<td>Œµ-transitions</td>
<td>Not allowed</td>
<td>Allowed</td>
</tr>
<tr>
<td>Simplicity</td>
<td>Easier to implement</td>
<td>Easier to design</td>
</tr>
<tr>
<td>Power</td>
<td><strong>Same (both recognize regular languages)</strong></td>
</tr>
</tbody>
</table>
</div>
<p><strong>üîπ Applications</strong></p>
<ul>
<li>Lexical analysis (token recognition)</li>
<li>Pattern matching (e.g., <code>grep</code>, <code>regex</code>)</li>
<li>Protocol design</li>
<li>Digital circuits</li>
</ul>
<hr>
<h3 id="üîÑ-NFA-Nondeterministic-Finite-Automaton"><a href="#üîÑ-NFA-Nondeterministic-Finite-Automaton" class="headerlink" title="üîÑ NFA (Nondeterministic Finite Automaton)"></a>üîÑ NFA (Nondeterministic Finite Automaton)</h3><p><strong>üîπ Definition</strong></p>
<p>An <strong>NFA</strong> is a type of <strong>finite automaton</strong> used to recognize <strong>regular languages</strong>, just like a DFA. The key difference is that <strong>multiple transitions</strong> are allowed for the <strong>same input</strong> from a single state, and <strong>Œµ-transitions</strong> (transitions without consuming input) are permitted.</p>
<p>An NFA is formally defined as a <strong>5-tuple</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">NFA &#x3D; (Q, Œ£, Œ¥, q‚ÇÄ, F)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Where:</p>
<ul>
<li><code>Q</code> ‚Üí Finite set of <strong>states</strong></li>
<li><code>Œ£</code> ‚Üí Finite set of <strong>input symbols</strong> (alphabet)</li>
<li><code>Œ¥</code> ‚Üí <strong>Transition function</strong>: Œ¥ : Q √ó (Œ£ ‚à™ {Œµ}) ‚Üí 2^Q</li>
<li><code>q‚ÇÄ</code> ‚Üí <strong>Start state</strong>, <code>q‚ÇÄ ‚àà Q</code></li>
<li><code>F</code> ‚Üí Set of <strong>accepting/final states</strong>, <code>F ‚äÜ Q</code></li>
</ul>
<p><strong>üîπ Characteristics</strong></p>
<ul>
<li><p><strong>Non-deterministic</strong>:</p>
<ul>
<li>From a given state and input, the NFA can <strong>go to multiple next states</strong>.</li>
<li>The NFA <strong>accepts</strong> an input string if <strong>at least one possible path</strong> leads to an accepting state.</li>
</ul>
</li>
<li><strong>Œµ-transitions allowed</strong>: The machine can move <strong>without reading input</strong>.</li>
<li><strong>Can be in multiple states</strong> at once during computation.</li>
</ul>
<p><strong>üîπ Example NFA</strong></p>
<p>Let‚Äôs define an NFA that accepts strings over <code>&#123;0,1&#125;</code> ending in <code>01</code>.</p>
<ul>
<li><code>Q = &#123;q0, q1, q2&#125;</code></li>
<li><code>Œ£ = &#123;0, 1&#125;</code></li>
<li><code>q‚ÇÄ = q0</code></li>
<li><code>F = &#123;q2&#125;</code></li>
</ul>
<p>Transition table:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Current State</th>
<th>Input</th>
<th>Next States</th>
</tr>
</thead>
<tbody>
<tr>
<td>q0</td>
<td>0</td>
<td>{q0, q1}</td>
</tr>
<tr>
<td>q0</td>
<td>1</td>
<td>{q0}</td>
</tr>
<tr>
<td>q1</td>
<td>1</td>
<td>{q2}</td>
</tr>
<tr>
<td>q2</td>
<td>0,1</td>
<td>‚àÖ</td>
</tr>
</tbody>
</table>
</div>
<p>In this NFA, from <code>q0</code>, if we read <code>0</code>, we can <strong>either</strong> stay in <code>q0</code> or go to <code>q1</code>.</p>
<p><strong>üîπ NFA vs DFA</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>NFA</th>
<th>DFA</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transitions</td>
<td>Can go to <strong>multiple</strong> states</td>
<td>Only <strong>one</strong> next state</td>
</tr>
<tr>
<td>Œµ-transitions</td>
<td><strong>Allowed</strong></td>
<td><strong>Not allowed</strong></td>
</tr>
<tr>
<td>Execution</td>
<td>Can explore multiple paths in parallel</td>
<td>Only one deterministic path</td>
</tr>
<tr>
<td>Implementation</td>
<td>More complex</td>
<td>Easier</td>
</tr>
<tr>
<td>Expressive Power</td>
<td><strong>Same</strong> ‚Äì both recognize regular languages</td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>üí° Every NFA can be converted into an equivalent DFA (subset construction), though the DFA may have exponentially more states.</p>
</blockquote>
<p><strong>üîπ Applications</strong></p>
<ul>
<li>Easier to <strong>design</strong> than DFA for complex patterns</li>
<li>Used in <strong>regular expression engines</strong></li>
<li>Foundations for <strong>parser generators</strong> and <strong>compiler design</strong></li>
</ul>
<hr>
<h3 id="Finite-State-Machine-FSM"><a href="#Finite-State-Machine-FSM" class="headerlink" title="Finite-State Machine (FSM)"></a>Finite-State Machine (FSM)</h3><p>A <strong>Finite-State Machine (FSM)</strong> is a computational model used to design and describe the behavior of digital systems, software, or processes that are dependent on a sequence of inputs and a finite number of internal states.</p>
<p><strong>üß† Key Concepts</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Term</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>State</strong></td>
<td>A unique configuration or condition of the system at a given time.</td>
</tr>
<tr>
<td><strong>Input</strong></td>
<td>External data or signal that triggers a transition.</td>
</tr>
<tr>
<td><strong>Transition</strong></td>
<td>The process of moving from one state to another.</td>
</tr>
<tr>
<td><strong>Initial State</strong></td>
<td>The state in which the FSM starts.</td>
</tr>
<tr>
<td><strong>Final State(s)</strong></td>
<td>Some FSMs may have one or more accepting states that signify a successful process.</td>
</tr>
</tbody>
</table>
</div>
<p><strong>üõ† Types of FSM</strong></p>
<ol>
<li><p><strong>Deterministic Finite Automaton (DFA)</strong></p>
<ul>
<li>Each state has <em>exactly one</em> transition for each possible input.</li>
<li>There is <em>no ambiguity</em> in state transitions.</li>
</ul>
</li>
<li><p><strong>Nondeterministic Finite Automaton (NFA)</strong></p>
<ul>
<li>A state can have <em>multiple transitions</em> for the same input.</li>
<li>May include <em>Œµ-transitions</em> (transitions without input).</li>
</ul>
</li>
</ol>
<p><strong>‚öôÔ∏è Components of an FSM</strong></p>
<p>An FSM is formally defined as a 5-tuple:</p>
<script type="math/tex; mode=display">
M = (Q, \Sigma, \delta, q_0, F)</script><p><strong>üß≠ How It Works (Example)</strong></p>
<p>Suppose we have an FSM that accepts binary strings ending in <code>01</code>.</p>
<ul>
<li><strong>States</strong>: <code>S0</code> (start), <code>S1</code> (seen 0), <code>S2</code> (accepting, seen 01)</li>
<li><strong>Input</strong>: <code>0</code>, <code>1</code></li>
<li><p><strong>Transitions</strong>:</p>
<ul>
<li>From <code>S0</code>, on <code>0</code> ‚Üí <code>S1</code></li>
<li>From <code>S1</code>, on <code>1</code> ‚Üí <code>S2</code></li>
<li>From <code>S2</code>, on <code>0</code> ‚Üí <code>S1</code>, on <code>1</code> ‚Üí <code>S0</code> (reset if wrong pattern)</li>
</ul>
</li>
</ul>
<p><strong>üì¶ Applications</strong></p>
<ul>
<li>Lexical analyzers (compilers)</li>
<li>Protocol design</li>
<li>Game development (e.g., AI behavior)</li>
<li>Digital circuit design</li>
<li>Control systems</li>
</ul>
<hr>
<h3 id="Pumping-Lemma-for-regular-languages"><a href="#Pumping-Lemma-for-regular-languages" class="headerlink" title="Pumping Lemma for regular languages"></a>Pumping Lemma for regular languages</h3><p>The <strong>Pumping Lemma</strong> for regular languages is an important tool in formal language and automata theory, used to prove that a given language is <strong>not</strong> regular. The pumping lemma provides a ‚Äúpumping‚Äù property, which means that certain strings in a regular language can be repeated (or ‚Äúpumped‚Äù) under specific conditions without changing whether the string belongs to the language.</p>
<p>The pumping lemma mainly applies to regular languages. It states:<br>If a language is regular, then there exists a constant $p$ (called the pumping length), such that for any string $s \in L$ (where $s$ belongs to language $L$) with length greater than or equal to $p$, it is possible to divide $s$ into the following three parts:</p>
<ul>
<li><p>$s = xyz$, where:</p>
<ul>
<li>$x$ is a prefix of $s$ (possibly empty).</li>
<li>$y$ is the part that can be ‚Äúpumped‚Äù, and $|y| &gt; 0$.</li>
<li>$z$ is a suffix of $s$ (possibly empty).</li>
</ul>
</li>
</ul>
<p>Moreover, for any $i \geq 0$, the string $xy^i z$ must also belong to the language $L$. That is, the substring $y$ can be repeated any number of times without affecting whether $s$ belongs to $L$.</p>
<hr>
<h3 id="Pumping-Lemma-for-CFLs"><a href="#Pumping-Lemma-for-CFLs" class="headerlink" title="Pumping Lemma for CFLs"></a>Pumping Lemma for CFLs</h3><p>The Pumping Lemma for Context-Free Languages (CFLs) states that for any context-free language $L$, if $L$ is infinite, then there exists a constant $p$ (pumping length), such that for every string $s \in L$ with length greater than or equal to $p$, the string $s$ can be divided into five parts $s = uvwxy$, satisfying the following conditions:</p>
<ol>
<li>For all $i \geq 0$, $uv^i w x^i y \in L$.</li>
<li>$|v| + |x| &gt; 0$ (i.e., $v$ and $x$ are not both empty).</li>
<li>$|vwx| \leq p$ (the total length of $v$, $w$, and $x$ does not exceed the pumping length $p$).</li>
</ol>
<p>We assume that $L$ is an infinite context-free language. Since $L$ is a context-free language, based on the structural properties of context-free grammars, it corresponds to a pushdown automaton (PDA). This PDA must satisfy one condition: it can ‚Äúpump‚Äù strings, i.e., repeat certain parts of the string while keeping the resulting string within the language $L$.</p>
<p>According to the pumping lemma assumption, there exists a pumping length $p$, such that for all strings $s \in L$ with length greater than or equal to $p$, the string $s$ can be decomposed as $s = uvwxy$, satisfying the following conditions:</p>
<ul>
<li>$|vwx| \leq p$</li>
<li>$|v| + |x| &gt; 0$</li>
</ul>
<p>Context-free languages can be generated by context-free grammars (CFGs) or recognized by pushdown automata (PDAs). We use these structures to demonstrate the pumping lemma.</p>
<ul>
<li>For any string $s \in L$ with length greater than or equal to $p$, it must be generated by derivation using a context-free grammar.</li>
<li><p>Since $L$ is infinite, there exists a derivation tree for some parts that can be broken down into five parts $uvwxy$, where:</p>
<ul>
<li>$v$ and $x$ are the parts that can be ‚Äúpumped‚Äù or repeated.</li>
<li>The total length of $v$ and $x$ does not exceed $p$.</li>
<li>This means that for some appropriate $i$, $v$ and $x$ can be repeated without breaking the structure of the language.</li>
</ul>
</li>
</ul>
<blockquote>
<p>The proof here also involves the Pigeonhole Principle, which is not elaborated on in detail.</p>
</blockquote>
<p>Based on the structure of context-free languages, the string $s$ can be decomposed as $s = uvwxy$, satisfying the following conditions:</p>
<ul>
<li>$|vwx| \leq p$, which means the total length of $v$ and $x$ does not exceed the pumping length $p$; their lengths are finite.</li>
<li>$|v| + |x| &gt; 0$, which means $v$ and $x$ cannot both be empty.</li>
</ul>
<p>According to the pumping lemma, we know that if we ‚Äúpump‚Äù the parts $v$ and $x$ of the string $s$, i.e., repeat them multiple times, then the new string $uv^i w x^i y$ will still belong to the language $L$, for all $i \geq 0$.</p>
<p>According to the pumping lemma assumption, for all $i \geq 0$, $uv^i w x^i y \in L$. This means that by increasing the number of repetitions of parts $v$ and $x$, the string remains within the language $L$.</p>
<p>The key to this process is that through appropriate decomposition and pumping operations, the structure of the language remains unchanged, and therefore it can be accepted by a context-free grammar or pushdown automaton.</p>
<p>Using the pumping lemma, we can prove that some languages are <strong>not</strong> context-free. A proof by contradiction is often used to show that a language does not satisfy the requirements of a context-free language. By choosing an appropriate string and assuming it satisfies the conditions of the pumping lemma, we can show that certain operations cause the resulting string to no longer belong to the language, thus concluding that the language is not context-free.</p>
<hr>
<p>Using the pumping lemma, we can prove that certain languages are not context-free by contradiction. Suppose we want to prove that a language $L$ is not context-free. The process usually involves the following steps:</p>
<ol>
<li>Assume that $L$ is a context-free language and that it satisfies the pumping lemma.</li>
<li>Choose a string $s \in L$ with length greater than or equal to the pumping length $p$, then decompose it as $s = uvwxy$ and apply the pumping lemma.</li>
<li>Expand $uv^i w x^i y$ and prove that for some values of $i$, $uv^i w x^i y \notin L$, thus leading to a contradiction.</li>
<li>Conclude that $L$ is not a context-free language.</li>
</ol>
<p>Example: Prove that $L = { a^n b^n c^n \mid n \geq 0 }$ is not a context-free language.</p>
<p>We use the pumping lemma for context-free languages to prove that $L = { a^n b^n c^n \mid n \geq 0 }$ is not context-free.</p>
<ol>
<li><p><strong>Assume $L$ is a context-free language:</strong><br>Assume that $L$ is a context-free language and that a pumping length $p$ exists. According to the pumping lemma, any string $s$ with length greater than or equal to $p$ can be decomposed as $s = uvwxy$, where $|vwx| \leq p$ and $|v| + |x| &gt; 0$.</p>
</li>
<li><p><strong>Choose the string $s = a^p b^p c^p$:</strong><br>Choose the string $s = a^p b^p c^p$, which clearly belongs to $L$, and its length $|s| = 3p \geq p$.</p>
</li>
<li><p><strong>Decompose the string $s$:</strong><br>According to the pumping lemma, $s = uvwxy$, where $|vwx| \leq p$ and $|v| + |x| &gt; 0$. Since $|vwx| \leq p$, it can only span one portion of the string (i.e., the $a^n$, $b^n$, or $c^n$ part). Also, since $|v| + |x| &gt; 0$, $v$ and $x$ must include some repeating characters.</p>
</li>
<li><p><strong>Apply the pumping lemma:</strong><br>According to the pumping lemma, for all $i \geq 0$, $uv^i w x^i y$ should still belong to $L$. However, if we choose $i &gt; 1$, we get a mismatched string such as $uv^2 w x^2 y$. This string would no longer maintain the same number of <code>a</code>s, <code>b</code>s, and <code>c</code>s, and thus would not belong to $L$.</p>
</li>
<li><p><strong>Reach a contradiction:</strong><br>Therefore, we conclude that $L$ cannot be a context-free language because the result from the pumping lemma contradicts the definition of $L$.</p>
</li>
</ol>
<p>The pumping lemma for context-free languages demonstrates certain properties of languages by decomposing and repeating parts of their strings. It provides a method to prove by contradiction that certain languages are not context-free.</p>
<hr>
<h3 id="Context-Free-Language-CFL"><a href="#Context-Free-Language-CFL" class="headerlink" title="Context-Free Language (CFL)"></a>Context-Free Language (CFL)</h3><p>A <strong>Context-Free Language (CFL)</strong> is a type of formal language that can be generated by a <strong>Context-Free Grammar (CFG)</strong>. It is an essential concept in the theory of computation and plays a major role in compiler design and parsing.</p>
<p><strong>üìò What is a Context-Free Grammar (CFG)?</strong></p>
<p>A <strong>Context-Free Grammar</strong> is a set of recursive rewriting rules (productions) used to generate strings in a language. A CFG is formally defined as a 4-tuple:</p>
<script type="math/tex; mode=display">
G = (V, \Sigma, R, S)</script><p>Where:</p>
<ul>
<li>$V$: A finite set of <strong>variables</strong> (non-terminal symbols)</li>
<li>$\Sigma$: A finite set of <strong>terminal symbols</strong> (alphabet of the language)</li>
<li>$R$: A finite set of <strong>production rules</strong>, each of the form $A \rightarrow \gamma$, where $A \in V$ and $\gamma \in (V \cup \Sigma)^*$</li>
<li>$S$: The <strong>start symbol</strong>, $S \in V$</li>
</ul>
<p><strong>üß† Key Characteristics of CFLs</strong></p>
<ul>
<li>The <strong>left-hand side</strong> of every production rule in a CFG has exactly <strong>one non-terminal</strong>.</li>
<li>A string belongs to the CFL if it can be derived from the start symbol using the rules.</li>
<li>CFLs are more powerful than <strong>regular languages</strong>, but less powerful than <strong>context-sensitive languages</strong>.</li>
</ul>
<p><strong>üßÆ Example of a Context-Free Grammar</strong></p>
<p>Let‚Äôs define a CFG for the language $L = { a^n b^n \mid n \geq 0 }$:</p>
<p><strong>Grammar:</strong></p>
<ul>
<li>$V = { S }$</li>
<li>$\Sigma = { a, b }$</li>
<li><p><strong>Production Rules</strong>:</p>
<ul>
<li>$S \rightarrow aSb$</li>
<li>$S \rightarrow \varepsilon$ <em>(epsilon, the empty string)</em></li>
</ul>
</li>
<li>$S$: start symbol</li>
</ul>
<p>This grammar generates:</p>
<ul>
<li>$\varepsilon$</li>
<li>$ab$</li>
<li>$aabb$</li>
<li>$aaabbb$, etc.</li>
</ul>
<p><strong>üìä Closure Properties of CFLs</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Operation</th>
<th>Closed under?</th>
</tr>
</thead>
<tbody>
<tr>
<td>Union</td>
<td>‚úÖ Yes</td>
</tr>
<tr>
<td>Concatenation</td>
<td>‚úÖ Yes</td>
</tr>
<tr>
<td>Kleene Star</td>
<td>‚úÖ Yes</td>
</tr>
<tr>
<td>Intersection</td>
<td>‚ùå No</td>
</tr>
<tr>
<td>Complement</td>
<td>‚ùå No</td>
</tr>
</tbody>
</table>
</div>
<p><strong>üñ• Recognizing CFLs with Pushdown Automata (PDA)</strong></p>
<p>A <strong>Pushdown Automaton (PDA)</strong> is a computational model that recognizes context-free languages.<br>It is similar to a finite automaton but with an added <strong>stack</strong>, which allows it to store an unbounded amount of information.</p>
<blockquote>
<p>CFLs are <strong>exactly</strong> the class of languages accepted by nondeterministic PDAs.</p>
</blockquote>
<p><strong>üö´ Not All Languages Are CFLs</strong></p>
<p>Some languages are <strong>not</strong> context-free, for example:</p>
<script type="math/tex; mode=display">
L = \{ a^n b^n c^n \mid n \geq 0 \}</script><p>No CFG can generate this language because it requires <strong>three-way balancing</strong>, which CFGs cannot handle.</p>
<p><strong>üß™ Applications of CFLs</strong></p>
<ul>
<li><strong>Programming languages</strong> (syntax parsing)</li>
<li><strong>Compilers</strong> (syntax analysis)</li>
<li><strong>Natural language processing</strong></li>
<li><strong>XML and structured data parsing</strong></li>
</ul>
<hr>
<h3 id="Pushdown-Automaton-PDA"><a href="#Pushdown-Automaton-PDA" class="headerlink" title="Pushdown Automaton (PDA)"></a>Pushdown Automaton (PDA)</h3><p>A <strong>Pushdown Automaton (PDA)</strong> is a type of computational model that extends the <strong>finite automaton</strong> by adding a <strong>stack</strong> as memory. This additional memory allows it to recognize <strong>context-free languages</strong> (CFLs), which are more powerful than regular languages.</p>
<p><strong>üß† Intuition</strong></p>
<p>A PDA reads input symbols <strong>one at a time</strong>, transitions between states based on the current input <strong>and</strong> the <strong>top of the stack</strong>, and can <strong>push</strong> or <strong>pop</strong> symbols from the stack.</p>
<ul>
<li>Think of the <strong>stack</strong> as an unlimited memory that operates in <strong>LIFO</strong> (Last-In, First-Out) order.</li>
<li>The PDA uses the stack to keep track of nested or recursive patterns (e.g. matching parentheses).</li>
</ul>
<p><strong>üß± Formal Definition</strong></p>
<p>A <strong>PDA</strong> is a 7-tuple:</p>
<script type="math/tex; mode=display">
M = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)</script><p>Where:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>$Q$</td>
<td>A finite set of <strong>states</strong></td>
</tr>
<tr>
<td>$\Sigma$</td>
<td>The <strong>input alphabet</strong></td>
</tr>
<tr>
<td>$\Gamma$</td>
<td>The <strong>stack alphabet</strong></td>
</tr>
<tr>
<td>$\delta$</td>
<td>The <strong>transition function</strong>: $Q \times (\Sigma \cup \varepsilon) \times \Gamma \rightarrow \mathcal{P}(Q \times \Gamma^*)$</td>
</tr>
<tr>
<td>$q_0$</td>
<td>The <strong>start state</strong>, $q_0 \in Q$</td>
</tr>
<tr>
<td>$Z_0$</td>
<td>The <strong>initial stack symbol</strong>, $Z_0 \in \Gamma$</td>
</tr>
<tr>
<td>$F$</td>
<td>A set of <strong>accepting (final) states</strong>, $F \subseteq Q$</td>
</tr>
</tbody>
</table>
</div>
<p><strong>üîÅ Transition Function Explanation</strong></p>
<p>The transition function:</p>
<script type="math/tex; mode=display">
\delta(q, a, X) = \{ (q', \gamma) \}</script><p>Means:</p>
<ul>
<li>In state $q$, if the input symbol is $a$ (or $\varepsilon$), and the <strong>top of the stack</strong> is $X$,</li>
<li><p>Then the machine can:</p>
<ul>
<li><strong>Move</strong> to state $q‚Äô$</li>
<li><strong>Replace</strong> $X$ with $\gamma$ on the stack (where $\gamma$ can be multiple symbols or empty)</li>
</ul>
</li>
</ul>
<p>üßÆ Example: PDA for $L = { a^n b^n \mid n \geq 0 }$</p>
<p>We want to accept strings where the number of <code>a</code>s equals the number of <code>b</code>s.</p>
<p><strong>Idea</strong>:</p>
<ul>
<li>Push <code>A</code> onto the stack for each <code>a</code>.</li>
<li>Pop <code>A</code> from the stack for each <code>b</code>.</li>
<li>Accept if the stack is empty at the end.</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Step</th>
<th>Stack Operation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Read <code>a</code></td>
<td>Push <code>A</code></td>
</tr>
<tr>
<td>Read <code>b</code></td>
<td>Pop <code>A</code></td>
</tr>
<tr>
<td>Input done</td>
<td>Accept if stack empty</td>
</tr>
</tbody>
</table>
</div>
<p><strong>‚úÖ Acceptance Criteria</strong></p>
<p>There are <strong>two common acceptance methods</strong> for PDAs:</p>
<ol>
<li><strong>By final state</strong>: The PDA ends in an accepting state after reading the entire input.</li>
<li><strong>By empty stack</strong>: The PDA‚Äôs stack is empty after reading the entire input.</li>
</ol>
<blockquote>
<p>Both methods define the same class of languages: <strong>context-free languages</strong>.</p>
</blockquote>
<p><strong>‚ö†Ô∏è Deterministic vs Nondeterministic PDA</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>NPDA</strong></td>
<td>Nondeterministic PDA ‚Äî accepts all CFLs</td>
</tr>
<tr>
<td><strong>DPDA</strong></td>
<td>Deterministic PDA ‚Äî accepts only some CFLs</td>
</tr>
</tbody>
</table>
</div>
<p>Not all context-free languages can be recognized by a deterministic PDA.</p>
<p>üî¨ <strong>Applications</strong></p>
<ul>
<li><strong>Parsing</strong> expressions in compilers</li>
<li><strong>Syntax checking</strong> in programming languages (e.g., bracket matching)</li>
<li>Modeling <strong>recursive structures</strong></li>
<li><strong>Natural language processing</strong> (nested phrase structures)</li>
</ul>
<hr>
<h3 id="Ambiguity-of-Grammar"><a href="#Ambiguity-of-Grammar" class="headerlink" title="Ambiguity of Grammar"></a>Ambiguity of Grammar</h3><p>In formal language theory, a <strong>grammar is said to be ambiguous</strong> if there exists <strong>at least one string</strong> that can be generated by the grammar in <strong>more than one way</strong> ‚Äî specifically, it has <strong>more than one parse tree (or derivation)</strong>.</p>
<p><strong>üìö Definition</strong></p>
<p>A <strong>context-free grammar (CFG)</strong> $G$ is <strong>ambiguous</strong> if <strong>there exists a string</strong> $w \in L(G)$ such that:</p>
<ul>
<li>$w$ has <strong>two or more different parse trees</strong>, or</li>
<li>$w$ has <strong>two or more leftmost (or rightmost) derivations</strong></li>
</ul>
<p><strong>üß† Why Does Ambiguity Matter?</strong></p>
<ul>
<li><strong>Ambiguous grammars</strong> are problematic in <strong>programming language design</strong>, especially during <strong>parsing</strong>, because a compiler may not know which interpretation is correct.</li>
<li>Some context-free languages are <strong>inherently ambiguous</strong> ‚Äî no unambiguous CFG can generate them.</li>
</ul>
<p><strong>üßÆ Example: An Ambiguous Grammar</strong></p>
<p>Let‚Äôs define a simple grammar for arithmetic expressions:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">E ‚Üí E + E  
E ‚Üí E * E  
E ‚Üí (E)  
E ‚Üí id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>This grammar generates expressions like <code>id + id * id</code>, but it is <strong>ambiguous</strong> because:</p>
<ul>
<li>It can be parsed as <code>(id + id) * id</code></li>
<li>Or as <code>id + (id * id)</code></li>
</ul>
<p>Both are valid interpretations but <strong>yield different parse trees</strong>.</p>
<p><strong>üå≤ Two Different Parse Trees for <code>id + id * id</code></strong></p>
<p><strong>1. Left-associative (Addition first)</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">    E
   &#x2F;|\
  E + E
 |    |
id   E * E
     |   |
    id  id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p><strong>2. Right-associative (Multiplication first)</strong></p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">       E
      &#x2F;|\
     E * E
    |    |
   E + E id
  |   |
id  id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>This shows <strong>ambiguity</strong> in structure and meaning.</p>
<p><strong>üõ† Disambiguating a Grammar</strong></p>
<p>To <strong>remove ambiguity</strong>, you can:</p>
<ul>
<li><strong>Introduce precedence and associativity rules</strong> (e.g., make <code>*</code> bind tighter than <code>+</code>)</li>
<li><strong>Refactor the grammar</strong> to eliminate conflicting derivations</li>
</ul>
<p>For example:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">E  ‚Üí E + T | T  
T  ‚Üí T * F | F  
F  ‚Üí (E) | id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure>
<p>Now:</p>
<ul>
<li><code>*</code> has higher precedence than <code>+</code></li>
<li>Left associativity is enforced</li>
<li>This grammar is <strong>unambiguous</strong></li>
</ul>
<p><strong>üî• Inherently Ambiguous Languages</strong></p>
<p>Some CFLs are <strong>inherently ambiguous</strong>, meaning <strong>no matter how you write the grammar</strong>, some strings will always have multiple parse trees.</p>
<p>Example language:</p>
<script type="math/tex; mode=display">
L = \{ a^i b^j c^k \mid i = j \text{ or } j = k \}</script><p>This language is <strong>not inherently unambiguous</strong> because you can‚Äôt write a CFG for it that avoids ambiguity in all cases.</p>
<p><strong>‚úÖ Summary</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Concept</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Ambiguity</strong></td>
<td>A string has multiple parse trees or derivations in a grammar</td>
</tr>
<tr>
<td><strong>Unambiguous CFG</strong></td>
<td>A CFG where every string has <strong>only one</strong> parse tree</td>
</tr>
<tr>
<td><strong>Inherently Ambiguous Language</strong></td>
<td>A CFL for which <strong>no unambiguous grammar exists</strong></td>
</tr>
<tr>
<td><strong>Solution</strong></td>
<td>Rewrite grammar with precedence/associativity or restructure rules</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="Turing-Machine"><a href="#Turing-Machine" class="headerlink" title="Turing Machine"></a>Turing Machine</h3><p>A <strong>Turing Machine</strong> is a powerful abstract computational model introduced by <strong>Alan Turing</strong> in 1936. It forms the foundation of modern computer science and helps define the limits of what can be computed.</p>
<p><strong>üß± Definition</strong></p>
<p>A <strong>Turing Machine (TM)</strong> is a 7-tuple:</p>
<script type="math/tex; mode=display">
M = (Q, \Sigma, \Gamma, \delta, q_0, q_{\text{accept}}, q_{\text{reject}})</script><p>Where:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Symbol</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>$Q$</td>
<td>A finite set of <strong>states</strong></td>
</tr>
<tr>
<td>$\Sigma$</td>
<td>The <strong>input alphabet</strong> (does not include the blank symbol <code>‚ñ°</code>)</td>
</tr>
<tr>
<td>$\Gamma$</td>
<td>The <strong>tape alphabet</strong> (includes <code>‚ñ°</code>, the blank symbol)</td>
</tr>
<tr>
<td>$\delta$</td>
<td>The <strong>transition function</strong>: $Q \times \Gamma \rightarrow Q \times \Gamma \times {L, R}$</td>
</tr>
<tr>
<td>$q_0$</td>
<td>The <strong>start state</strong></td>
</tr>
<tr>
<td>$q_{\text{accept}}$</td>
<td>The <strong>accepting state</strong></td>
</tr>
<tr>
<td>$q_{\text{reject}}$</td>
<td>The <strong>rejecting state</strong> (‚â† $q_{\text{accept}}$)</td>
</tr>
</tbody>
</table>
</div>
<p><strong>üß† How It Works</strong></p>
<ol>
<li><p>The machine has an <strong>infinite tape</strong> divided into cells, each holding one symbol from $\Gamma$.</p>
</li>
<li><p>A <strong>tape head</strong> reads and writes symbols on the tape and moves <strong>left (L)</strong> or <strong>right (R)</strong>.</p>
</li>
<li><p>The machine starts in the <strong>start state</strong> $q_0$, with the tape containing the input string and blanks elsewhere.</p>
</li>
<li><p>Based on the current state and the symbol under the head, the <strong>transition function</strong> determines:</p>
<ul>
<li>The next state</li>
<li>The symbol to write</li>
<li>The direction to move the head</li>
</ul>
</li>
<li><p>The machine halts when it enters either the <strong>accept state</strong> or the <strong>reject state</strong>.</p>
</li>
</ol>
<p><strong>üìã Example Transition</strong></p>
<p>If:</p>
<script type="math/tex; mode=display">
\delta(q_1, 1) = (q_2, 0, R)</script><p>It means:</p>
<ul>
<li>In state $q_1$, if reading symbol <code>1</code></li>
<li>Write <code>0</code>, move <strong>right</strong>, and go to state $q_2$</li>
</ul>
<p><strong>‚úÖ Acceptance Criteria</strong></p>
<p>A string is <strong>accepted</strong> by the Turing Machine if, starting from the initial configuration, the machine <strong>eventually reaches the accept state</strong>.</p>
<p><strong>üßÆ Example Language</strong></p>
<p>Language:</p>
<script type="math/tex; mode=display">
L = \{ w \in \{0,1\}^* \mid w \text{ has an even number of 0s} \}</script><p>A Turing Machine for this language could:</p>
<ul>
<li>Track even/odd count using states</li>
<li>Scan the tape and change state upon reading <code>0</code></li>
<li>Halt in the accept state if the final state indicates even count</li>
</ul>
<p><strong>üß∞ Types of Turing Machines</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Deterministic TM (DTM)</strong></td>
<td>One possible action per state-symbol pair</td>
</tr>
<tr>
<td><strong>Nondeterministic TM (NTM)</strong></td>
<td>Multiple possible transitions (theoretical model)</td>
</tr>
<tr>
<td><strong>Multi-tape TM</strong></td>
<td>Multiple tapes (still equivalent in power to DTM)</td>
</tr>
<tr>
<td><strong>Universal TM</strong></td>
<td>Simulates any other Turing Machine (like real computers!)</td>
</tr>
</tbody>
</table>
</div>
<p><strong>üî¨ Power of Turing Machines</strong></p>
<p>Turing Machines can simulate:</p>
<ul>
<li>Finite automata</li>
<li>Pushdown automata</li>
<li>Real programming languages</li>
</ul>
<p>They can compute anything that is <strong>computable</strong>, but <strong>some problems are undecidable</strong>, like the <strong>halting problem</strong>.</p>
<p><strong>üîí Limitations</strong></p>
<ul>
<li><strong>Not all languages are Turing-decidable</strong></li>
<li><strong>Undecidable problems</strong> exist (e.g., Halting Problem, Post Correspondence Problem)</li>
</ul>
<p><strong>‚úÖ Summary</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Turing Machine</th>
</tr>
</thead>
<tbody>
<tr>
<td>Memory</td>
<td>Infinite tape</td>
</tr>
<tr>
<td>Acceptance</td>
<td>By entering accept state</td>
</tr>
<tr>
<td>More powerful than</td>
<td>FA, PDA, CFG</td>
</tr>
<tr>
<td>Can simulate real CPUs</td>
<td>‚úÖ Yes</td>
</tr>
<tr>
<td>Can solve all problems</td>
<td>‚ùå No (some problems are undecidable)</td>
</tr>
</tbody>
</table>
</div>
<h2 id="5-Programming-Language"><a href="#5-Programming-Language" class="headerlink" title="5. Programming Language"></a>5. Programming Language</h2><h2 id="6-Machine-Learning"><a href="#6-Machine-Learning" class="headerlink" title="6. Machine Learning"></a>6. Machine Learning</h2><h3 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h3><p><strong>Random Forest</strong> ÊòØ‰∏ÄÁßçÂü∫‰∫é <strong>ÈõÜÊàêÂ≠¶‰π†ÔºàEnsemble LearningÔºâ</strong> ÁöÑÂàÜÁ±ªÊàñÂõûÂΩíÁÆóÊ≥ïÔºåÂÆÉÂ∞ÜÂ§ö‰∏™ <strong>ÂÜ≥Á≠ñÊ†ëÔºàDecision TreeÔºâ</strong> ÁªÑÂêàÂú®‰∏ÄËµ∑ÔºåÈÄöËøá‚ÄúÊäïÁ•®‚ÄùÊàñ‚ÄúÂπ≥Âùá‚ÄùÁöÑÊñπÂºèÂæóÂà∞ÊúÄÁªàÁªìÊûú„ÄÇ</p>
<blockquote>
<p>ÂÆÉÊòØ‰∏ÄÁßç <strong>BaggingÔºàBootstrap AggregationÔºâ</strong> ÊñπÊ≥ïÔºåÁî®‰∫éÂáèÂ∞ëËøáÊãüÂêà„ÄÅÊèêÂçáÊ≥õÂåñËÉΩÂäõ„ÄÇ</p>
</blockquote>
<p><strong>üì¶ Â∫îÁî®‰∫éÂú∫ÊôØ</strong></p>
<ul>
<li><strong>ÂàÜÁ±ª‰ªªÂä°</strong>ÔºöÂà§Êñ≠ÈÇÆ‰ª∂ÊòØÂê¶ÂûÉÂúæ</li>
<li><strong>ÂõûÂΩí‰ªªÂä°</strong>ÔºöÈ¢ÑÊµãÊàø‰ª∑</li>
<li><strong>ÁâπÂæÅÈáçË¶ÅÊÄßÂàÜÊûê</strong>ÔºöÂì™‰∫õÂèòÈáèÂØπÈ¢ÑÊµãÁªìÊûúÂΩ±ÂìçÊúÄÂ§ßÔºü</li>
</ul>
<p><strong>üß† Ê†∏ÂøÉÊÄùÊÉ≥</strong></p>
<p><strong>Â§ö‰∏™‚ÄúÂº±Â≠¶‰π†Âô®‚Äù</strong>ÔºàÂç≥ÂçïÊ£µÂÜ≥Á≠ñÊ†ëÔºâÂú®Êï∞ÊçÆÂ≠êÈõÜ‰∏äÁã¨Á´ãËÆ≠ÁªÉÔºåÁÑ∂Âêé<strong>ÈõÜÊàê</strong>ÂÆÉ‰ª¨ÁöÑÈ¢ÑÊµãÁªìÊûú„ÄÇ</p>
<p><strong>‚öôÔ∏è ÊûÑÈÄ†ËøáÁ®ãÔºàÁÆóÊ≥ïÊµÅÁ®ãÔºâ</strong></p>
<p>Step 1Ô∏è‚É£ÔºöBootstrap ÈááÊ†∑ÔºàÊúâÊîæÂõûÊäΩÊ†∑Ôºâ</p>
<p>‰ªéËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰∏≠<strong>ÊúâÊîæÂõûÂú∞ÈöèÊú∫ÊäΩÊ†∑</strong> $N$ Ê¨°ÔºåÊûÑÊàêËã•Âπ≤‰∏™ËÆ≠ÁªÉÂ≠êÈõÜÔºàÊØèÊ£µÊ†ëÁî®‰∏Ä‰ªΩÔºâ</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">ÂéüÂßãÊï∞ÊçÆ D = &#123;x1, x2, ..., xn&#125;
‚Üí Ê†∑Êú¨Â≠êÈõÜ D1, D2, ..., Dk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p>Step 2Ô∏è‚É£ÔºöËÆ≠ÁªÉÂ§öÊ£µÂÜ≥Á≠ñÊ†ëÔºàÊ†ëÁöÑÂ§öÊ†∑ÊÄßÊù•Ê∫ê‰πã‰∏ÄÔºâ</p>
<p>ÂØπÊØè‰∏™Â≠êÈõÜ $D_i$ ËÆ≠ÁªÉ‰∏ÄÊ£µ<strong>ÂÜ≥Á≠ñÊ†ë</strong>Ôºå‰ΩÜÊØè‰∏™ËäÇÁÇπÂàíÂàÜÊó∂Âè™‰ΩøÁî®<strong>ÈöèÊú∫ÈÄâÊã©ÁöÑÈÉ®ÂàÜÁâπÂæÅ</strong>ÔºàÈÄöÂ∏∏ $\sqrt{M}$ ‰∏™ÁâπÂæÅÔºâ</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">‰æãÂ¶ÇÔºöÊÄªÂÖ±Êúâ 100 ‰∏™ÁâπÂæÅÔºåÊØè‰∏™ËäÇÁÇπÂè™‰ªéÈöèÊú∫ÈÄâÂá∫ÁöÑ 10 ‰∏™ÁâπÂæÅ‰∏≠ÈÄâÊã©ÊúÄ‰Ω≥ÂàíÂàÜ<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Step 3Ô∏è‚É£ÔºöÈõÜÊàêÈ¢ÑÊµãÁªìÊûú</p>
<ul>
<li><strong>ÂàÜÁ±ª‰ªªÂä°</strong>ÔºöÈááÁî®<strong>Â§öÊï∞ÊäïÁ•®</strong>Ôºàmajority voteÔºâ</li>
<li><strong>ÂõûÂΩí‰ªªÂä°</strong>ÔºöÈááÁî®<strong>Âπ≥ÂùáÂÄº</strong>ÔºàaverageÔºâ</li>
</ul>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># ÂàÜÁ±ªÊäïÁ•®</span>
final_class <span class="token operator">=</span> most_common<span class="token punctuation">(</span><span class="token punctuation">[</span>tree<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> tree <span class="token keyword">in</span> forest<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># ÂõûÂΩíÂπ≥Âùá</span>
final_value <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>tree<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> tree <span class="token keyword">in</span> forest<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>forest<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>üß© ‰∏∫‰ªÄ‰πà Random Forest ÊúâÊïàÔºü</p>
<p>üéØ Èôç‰ΩéËøáÊãüÂêà</p>
<ul>
<li>ÂçïÊ£µÊ†ëÂÆπÊòìÂØπÂô™Â£∞ÊãüÂêàÔºàÈ´òÊñπÂ∑ÆÔºâ</li>
<li>Â§öÊ£µÊ†ëÂπ≥ÂùáÂèØ‰ª•‚ÄúÁõ∏‰∫íÊäµÊ∂à‚ÄùËøáÊãüÂêàÁöÑÈÉ®ÂàÜ</li>
</ul>
<p>üéØ ÊèêÈ´òÊ≥õÂåñËÉΩÂäõ</p>
<ul>
<li>Âà©Áî®Êï∞ÊçÆÂíåÁâπÂæÅÁöÑÈöèÊú∫ÊÄßÔºå‰ΩøÂæóÊØèÊ£µÊ†ë‰∏çÂ§™Áõ∏ÂêåÔºåÊï¥‰ΩìÊõ¥Âº∫Â§ß</li>
</ul>
<p>üéØ ÂèØÂπ∂Ë°åËÆ≠ÁªÉÔºàÊØèÊ£µÊ†ëÁõ∏‰∫íÁã¨Á´ãÔºâ</p>
<p><strong>üîç ÁâπÂæÅÈáçË¶ÅÊÄßËØÑ‰º∞</strong></p>
<p>ÊØèÊ£µÊ†ëËÆ≠ÁªÉÂêéÂèØËÆ°ÁÆóÂêÑÁâπÂæÅÂú®‰ø°ÊÅØÂ¢ûÁõäÊàñ Gini ÊåáÊï∞‰∏äÁöÑË¥°ÁåÆ<br>‚Üí ÂèØ‰ª•ËØÑ‰º∞Âì™‰∫õÂèòÈáèÂØπÊ®°ÂûãÂΩ±ÂìçÊúÄÂ§ß</p>
<p>üìä Êó∂Èó¥‰∏éÁ©∫Èó¥Â§çÊùÇÂ∫¶</p>
<p>ËÆæÔºö</p>
<ul>
<li>$n$ÔºöÊ†∑Êú¨Êï∞Èáè</li>
<li>$m$ÔºöÁâπÂæÅÊï∞Èáè</li>
<li>$k$ÔºöÊ†ëÁöÑÊï∞Èáè</li>
<li>$d$ÔºöÊ†ëÁöÑÂπ≥ÂùáÊ∑±Â∫¶</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Êìç‰Ωú</th>
<th>Â§çÊùÇÂ∫¶</th>
</tr>
</thead>
<tbody>
<tr>
<td>ËÆ≠ÁªÉÊó∂Èó¥</td>
<td>$O(k \cdot n \cdot \log n \cdot m‚Äô)$Ôºà$m‚Äô \ll m$Ôºâ</td>
</tr>
<tr>
<td>Êé®ÁêÜÊó∂Èó¥</td>
<td>$O(k \cdot d)$</td>
</tr>
<tr>
<td>Á©∫Èó¥Â§çÊùÇÂ∫¶</td>
<td>$O(k \cdot n)$ÔºàÊØèÊ£µÊ†ëÂ≠òÂÇ®Ë∑ØÂæÑÔºâ</td>
</tr>
</tbody>
</table>
</div>
<p> ‚úÖ ‰ºòÁÇπÊÄªÁªì</p>
<ul>
<li>‰∏çÂÆπÊòìËøáÊãüÂêà</li>
<li>ÂèØÂ§ÑÁêÜÈ´òÁª¥Êï∞ÊçÆ</li>
<li>ÂØπÂºÇÂ∏∏ÂÄº‰∏çÊïèÊÑü</li>
<li>ÊîØÊåÅÁâπÂæÅÈáçË¶ÅÊÄßÊéíÂ∫è</li>
<li>ÈÄÇÂêàÂπ∂Ë°åÂ§ÑÁêÜ</li>
</ul>
<p>‚ö†Ô∏è Áº∫ÁÇπ</p>
<ul>
<li>Áõ∏ÊØîÂçïÊ£µÊ†ëÂèØËß£ÈáäÊÄßËæÉÂ∑Æ</li>
<li>ËÆ≠ÁªÉÊó∂Èó¥ËæÉÈïø</li>
<li>Ëã•Ê†∑Êú¨‰∏çÂπ≥Ë°°ÔºåÂàÜÁ±ªÊÄßËÉΩÂèØËÉΩ‰∏ãÈôç</li>
</ul>
<p>üìå PythonÁ§∫‰æãÔºà‰ΩøÁî® <code>sklearn</code>Ôºâ</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment"># Âä†ËΩΩÊï∞ÊçÆ</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> load_iris<span class="token punctuation">(</span>return_X_y<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span>

<span class="token comment"># ËÆ≠ÁªÉÈöèÊú∫Ê£ÆÊûó</span>
clf <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> max_features<span class="token operator">=</span><span class="token string">'sqrt'</span><span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token comment"># È¢ÑÊµã</span>
y_pred <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p><strong>üìñ ÊÄªÁªìË°®Ê†º</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>È°πÁõÆ</th>
<th>ÊèèËø∞</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ê®°ÂûãÁ±ªÂûã</td>
<td>ÈõÜÊàêÂ≠¶‰π†ÔºàBaggingÔºâ</td>
</tr>
<tr>
<td>Âü∫Â≠¶‰π†Âô®</td>
<td>ÂÜ≥Á≠ñÊ†ë</td>
</tr>
<tr>
<td>Â§öÊ†∑ÊÄßÊù•Ê∫ê</td>
<td>Êï∞ÊçÆÈááÊ†∑ + ÁâπÂæÅÂ≠êÈõÜÈÄâÊã©</td>
</tr>
<tr>
<td>ËÅöÂêàÊñπÂºè</td>
<td>Â§öÊï∞ÊäïÁ•®ÔºàÂàÜÁ±ªÔºâ / Âπ≥ÂùáÔºàÂõûÂΩíÔºâ</td>
</tr>
<tr>
<td>‰ºòÁÇπ</td>
<td>ÊäóËøáÊãüÂêà„ÄÅÁ®≥ÂÆö„ÄÅËÉΩËØÑ‰º∞ÁâπÂæÅÈáçË¶ÅÊÄß</td>
</tr>
<tr>
<td>Â∏∏Áî®Â∫ì</td>
<td><code>scikit-learn</code>„ÄÅ<code>xgboost</code>„ÄÅ<code>lightgbm</code>ÔºàÂèòÁßçÔºâ</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/img/concepts/random.svg" srcset="/img/loading.gif" lazyload alt="ÈöèÊú∫Ê£ÆÊûó" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Á∫øÊÄßÂõûÂΩíÔºàLinear-RegressionÔºâ"><a href="#Á∫øÊÄßÂõûÂΩíÔºàLinear-RegressionÔºâ" class="headerlink" title="Á∫øÊÄßÂõûÂΩíÔºàLinear RegressionÔºâ"></a>Á∫øÊÄßÂõûÂΩíÔºàLinear RegressionÔºâ</h3><p><strong>Á∫øÊÄßÂõûÂΩí</strong>ÊòØ‰∏ÄÁßçÂü∫Á°ÄÁöÑÁõëÁù£Â≠¶‰π†ÁÆóÊ≥ïÔºåÁî®‰∫éÂª∫Á´ã<strong>ÁâπÂæÅÂèòÈáèÔºàËá™ÂèòÈáèÔºâ</strong> ‰∏é <strong>ÁõÆÊ†áÂèòÈáèÔºàÂõ†ÂèòÈáèÔºâ</strong> ‰πãÈó¥ÁöÑ<strong>Á∫øÊÄßÂÖ≥Á≥ª</strong>Ê®°ÂûãÔºö</p>
<script type="math/tex; mode=display">
\hat{y} = w_1x_1 + w_2x_2 + \dots + w_nx_n + b = \mathbf{w}^\top \mathbf{x} + b</script><ul>
<li>$\hat{y}$ÔºöÈ¢ÑÊµãÂÄº</li>
<li>$\mathbf{x}$ÔºöËæìÂÖ•ÁâπÂæÅÂêëÈáèÔºàÂ¶Ç $[x_1, x_2, ‚Ä¶, x_n]$Ôºâ</li>
<li>$\mathbf{w}$ÔºöÊùÉÈáçÂêëÈáèÔºàÂèÇÊï∞Ôºâ</li>
<li>$b$ÔºöÂÅèÁΩÆÈ°πÔºàinterceptÔºâ</li>
</ul>
<p>üéØ ÁõÆÊ†á</p>
<p>ÊâæÂà∞‰∏ÄÁªÑÂèÇÊï∞ $(\mathbf{w}, b)$Ôºå‰ΩøÂæóÈ¢ÑÊµãÂÄº $\hat{y}$ <strong>Â∞ΩÂèØËÉΩÊé•ËøëÁúüÂÆûÂÄº $y$</strong>„ÄÇ</p>
<p>üìê ÊçüÂ§±ÂáΩÊï∞ÔºàLoss FunctionÔºâ</p>
<p>Êàë‰ª¨ÊúÄÂ∏∏Áî®ÁöÑÊòØ<strong>ÂùáÊñπËØØÂ∑ÆÔºàMean Squared Error, MSEÔºâ</strong>Ôºö</p>
<script type="math/tex; mode=display">
J(\mathbf{w}, b) = \frac{1}{m} \sum_{i=1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right)^2
= \frac{1}{m} \sum_{i=1}^{m} \left( \mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)} \right)^2</script><ul>
<li>$m$ÔºöÊ†∑Êú¨Êï∞</li>
<li>ÊúÄÂ∞èÂåñ $J(\mathbf{w}, b)$ Â∞±ÊòØËÆ≠ÁªÉËøáÁ®ãÁöÑÁõÆÊ†á</li>
</ul>
<p>‚öôÔ∏è Ê±ÇËß£ÊñπÊ≥ï</p>
<p>1Ô∏è‚É£ <strong>Ê≠£ËßÑÊñπÁ®ãÊ≥ïÔºàNormal EquationÔºâ</strong> ‚Äî‚Äî Á≤æÁ°ÆËß£Ê≥ï</p>
<p>Áõ¥Êé•ÂØπÊçüÂ§±ÂáΩÊï∞Ê±ÇÂØºÂπ∂Ëß£ÊñπÁ®ãÔºö</p>
<script type="math/tex; mode=display">
\mathbf{w} = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{y}</script><ul>
<li>$\mathbf{X}$Ôºö$m \times n$ ÁöÑÁâπÂæÅÁü©Èòµ</li>
<li>$\mathbf{y}$Ôºö$m \times 1$ ÁöÑÁõÆÊ†áÂÄºÂêëÈáè</li>
<li>Ë¶ÅÊ±Ç $\mathbf{X}^\top \mathbf{X}$ ÂèØÈÄÜÔºàÊï∞ÂÄºÁ®≥ÂÆöÊÄßÂ∑ÆÊó∂ÈúÄÁî®‰º™ÈÄÜÔºâ</li>
</ul>
<blockquote>
<p>‰ºòÁÇπÔºöËÆ°ÁÆóÁ≤æÁ°Æ<br>Áº∫ÁÇπÔºöÂ§çÊùÇÂ∫¶È´ò $O(n^3)$Ôºå‰∏çÈÄÇÂêàÈ´òÁª¥Â§ßÊï∞ÊçÆ</p>
</blockquote>
<p>2Ô∏è‚É£ <strong>Ê¢ØÂ∫¶‰∏ãÈôçÊ≥ïÔºàGradient DescentÔºâ</strong> ‚Äî‚Äî Ëøë‰ººËß£Ê≥ï</p>
<p>ÂØπÊçüÂ§±ÂáΩÊï∞Ê±ÇÂÅèÂØºÔºå‰ΩøÁî®Ëø≠‰ª£ÊñπÂºèÈÄºËøëÊúÄ‰ºòÔºö</p>
<p>ÂèÇÊï∞Êõ¥Êñ∞ÂÖ¨ÂºèÔºö</p>
<ul>
<li><p>ÂØπÊùÉÈáçÔºö</p>
<script type="math/tex; mode=display">
w_j \leftarrow w_j - \alpha \cdot \frac{\partial J}{\partial w_j}</script></li>
<li><p>ÂØπÂÅèÁΩÆÔºö</p>
<script type="math/tex; mode=display">
b \leftarrow b - \alpha \cdot \frac{\partial J}{\partial b}</script></li>
</ul>
<p>ÂØºÊï∞ËÆ°ÁÆóÁªìÊûúÔºö</p>
<script type="math/tex; mode=display">
\frac{\partial J}{\partial w_j} = \frac{2}{m} \sum_{i=1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right) x_j^{(i)}</script><script type="math/tex; mode=display">
\frac{\partial J}{\partial b} = \frac{2}{m} \sum_{i=1}^{m} \left( \hat{y}^{(i)} - y^{(i)} \right)</script><p>Ê¢ØÂ∫¶‰∏ãÈôç‰º™‰ª£Á†ÅÔºö</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">repeat until converge<span class="token punctuation">:</span>
    w <span class="token operator">-=</span> alpha <span class="token operator">*</span> gradient_w
    b <span class="token operator">-=</span> alpha <span class="token operator">*</span> gradient_b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></div></figure>
<blockquote>
<p>‰ºòÁÇπÔºöÈÄÇÁî®‰∫éÂ§ßÊï∞ÊçÆÈõÜÔºõÂèØÂú®Á∫øÂ≠¶‰π†<br>Áº∫ÁÇπÔºöÈúÄË∞ÉÂ≠¶‰π†Áéá $\alpha$ÔºåÊî∂ÊïõËæÉÊÖ¢</p>
</blockquote>
<p>üìä Êó∂Èó¥Â§çÊùÇÂ∫¶ÂØπÊØî</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>ÊñπÊ≥ï</th>
<th>Êó∂Èó¥Â§çÊùÇÂ∫¶</th>
<th>ÁâπÁÇπ</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ê≠£ËßÑÊñπÁ®ãÊ≥ï</td>
<td>$O(n^3)$</td>
<td>Á≤æÁ°Æ‰ΩÜÊÖ¢</td>
</tr>
<tr>
<td>Ê¢ØÂ∫¶‰∏ãÈôç</td>
<td>$O(knm)$Ôºà$k$ Ê¨°Ëø≠‰ª£Ôºâ</td>
<td>ÂèØË∞ÉÔºåÈÄÇÂêàÂ§ßÊï∞ÊçÆ</td>
</tr>
</tbody>
</table>
</div>
<p>üìö Python Á§∫‰æã‰ª£Á†ÅÔºà‰ΩøÁî® sklearnÔºâ</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_regression

X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_regression<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> n_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> noise<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ÊùÉÈáç:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ÂÅèÁΩÆ:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>üìà ÂèØËßÜÂåñ‰æãÂ≠ê</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Êàø‰ª∑È¢ÑÊµãÔºö
x = Èù¢ÁßØÔºà„é°ÔºâÔºåy = Êàø‰ª∑Ôºà‰∏áÔºâ
ËÆ≠ÁªÉÂêéÊ®°Âûã‰∏∫Ôºöy = 1.5x + 20

‚Üí ÂΩìËæìÂÖ• x = 100„é°ÔºåÈ¢ÑÊµã y = 170‰∏á<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p> ‚úÖ ÊÄªÁªì</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>È°πÁõÆ</th>
<th>ÊèèËø∞</th>
</tr>
</thead>
<tbody>
<tr>
<td>ËæìÂÖ•</td>
<td>Â§öÁª¥ÁâπÂæÅ $\mathbf{x}$</td>
</tr>
<tr>
<td>ËæìÂá∫</td>
<td>ËøûÁª≠ÂèòÈáè $\hat{y}$</td>
</tr>
<tr>
<td>Ê®°ÂûãÂΩ¢Âºè</td>
<td>Á∫øÊÄßÂáΩÊï∞Ôºö$\hat{y} = \mathbf{w}^\top \mathbf{x} + b$</td>
</tr>
<tr>
<td>ÊçüÂ§±ÂáΩÊï∞</td>
<td>ÂùáÊñπËØØÂ∑Æ MSE</td>
</tr>
<tr>
<td>Ê±ÇËß£ÊñπÂºè</td>
<td>Ê≠£ËßÑÊñπÁ®ã or Ê¢ØÂ∫¶‰∏ãÈôç</td>
</tr>
<tr>
<td>ÈÄÇÁî®Âú∫ÊôØ</td>
<td>È¢ÑÊµãÈóÆÈ¢òÔºà‰ª∑Ê†º„ÄÅËØÑÂàÜ„ÄÅË∂ãÂäøÔºâ</td>
</tr>
</tbody>
</table>
</div>
<p><img src="/img/concepts/linear.svg" srcset="/img/loading.gif" lazyload alt="Á∫øÊÄßÂõûÂΩí" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="ÈÄªËæëÂõûÂΩíÔºàLogistic-RegressionÔºâ"><a href="#ÈÄªËæëÂõûÂΩíÔºàLogistic-RegressionÔºâ" class="headerlink" title="ÈÄªËæëÂõûÂΩíÔºàLogistic RegressionÔºâ"></a>ÈÄªËæëÂõûÂΩíÔºàLogistic RegressionÔºâ</h3><p>ÈÄªËæëÂõûÂΩíÁî®‰∫éÈ¢ÑÊµã‰∫ã‰ª∂ÂèëÁîüÁöÑ<strong>Ê¶ÇÁéá</strong>ÔºåÂπ∂Â∞ÜÂÖ∂Êò†Â∞Ñ‰∏∫ 0 Êàñ 1 Á≠âÁ±ªÂà´„ÄÇ</p>
<blockquote>
<p><strong>ÁõÆÊ†á</strong>ÔºöÂ≠¶‰π†‰∏Ä‰∏™Ê®°ÂûãÔºåËæìÂÖ•ÁâπÂæÅ $\mathbf{x}$ÔºåËæìÂá∫ $\mathbb{P}(y = 1 \mid \mathbf{x})$„ÄÇ</p>
</blockquote>
<p>‚öôÔ∏è Ê®°ÂûãÁªìÊûÑ</p>
<p>ÈÄªËæëÂõûÂΩíÁöÑÂü∫Êú¨Ê®°ÂûãÊòØÔºö</p>
<script type="math/tex; mode=display">
\hat{y} = \sigma(\mathbf{w}^\top \mathbf{x} + b)</script><p>ÂÖ∂‰∏≠Ôºö</p>
<ul>
<li>$\mathbf{x}$ ÊòØËæìÂÖ•ÁâπÂæÅÂêëÈáè</li>
<li>$\mathbf{w}$ ÊòØÊùÉÈáçÂêëÈáè</li>
<li>$b$ ÊòØÂÅèÁΩÆÈ°π</li>
<li>$\sigma(z)$ ÊòØ<strong>sigmoid ÊøÄÊ¥ªÂáΩÊï∞</strong>ÔºåÂ∞Ü‰ªªÊÑèÂÆûÊï∞ÂéãÁº©Âà∞ $(0,1)$ Âå∫Èó¥</li>
</ul>
<p>üîÅ Sigmoid ÂáΩÊï∞ÂÆö‰πâÔºö</p>
<script type="math/tex; mode=display">
\sigma(z) = \frac{1}{1 + e^{-z}}</script><p>ÂõæÂÉèÂ¶Ç‰∏ãÔºö</p>
<ul>
<li>ÂΩì $z \gg 0$Ôºå$\sigma(z) \approx 1$</li>
<li>ÂΩì $z \ll 0$Ôºå$\sigma(z) \approx 0$</li>
<li>ÂΩì $z = 0$Ôºå$\sigma(z) = 0.5$</li>
</ul>
<p>üéØ ËæìÂá∫Ëß£Èáä</p>
<p>ÈÄªËæëÂõûÂΩíËæìÂá∫ÁöÑÊòØ‰∏Ä‰∏™<strong>Ê¶ÇÁéá</strong>Ôºö</p>
<script type="math/tex; mode=display">
\hat{y} = \mathbb{P}(y = 1 \mid \mathbf{x})</script><p>ÂÜ≥Á≠ñËßÑÂàôÔºàthresholdÔºâÔºö</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">if ùëÉ(y=1 | x) ‚â• 0.5 ‚Üí È¢ÑÊµã‰∏∫Á±ª1
else ‚Üí È¢ÑÊµã‰∏∫Á±ª0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p><img src="/img/concepts/logistic.svg" srcset="/img/loading.gif" lazyload alt="ÈÄªËæëÂõûÂΩí" style="max-width: 100%; height: auto;" /></p>
<p>üìâ ÊçüÂ§±ÂáΩÊï∞ÔºàÂØπÊï∞‰ººÁÑ∂ÊçüÂ§±Ôºâ</p>
<p>‰ΩøÁî®ÁöÑÊòØ<strong>ÂØπÊï∞ÊçüÂ§±ÂáΩÊï∞ÔºàLog LossÔºâ</strong>ÔºåÊ∫êËá™ÊúÄÂ§ß‰ººÁÑ∂‰º∞ËÆ°Ôºö</p>
<script type="math/tex; mode=display">
\mathcal{L}(\mathbf{w}, b) = -\frac{1}{m} \sum_{i=1}^{m} \left[
y^{(i)} \log \hat{y}^{(i)} + (1 - y^{(i)}) \log (1 - \hat{y}^{(i)})
\right]</script><blockquote>
<ul>
<li>Â¶ÇÊûúÈ¢ÑÊµã $\hat{y} \to y$ÔºåÊçüÂ§±ÂæàÂ∞èÔºõ</li>
<li>Â¶ÇÊûúÈ¢ÑÊµãÁõ∏ÂèçÔºåÊçüÂ§±ÊÄ•Ââß‰∏äÂçáÔºàÊØîÂ¶ÇÈ¢ÑÊµã‰∏∫ 0.01 ÂÆûÈôÖ‰∏∫ 1Ôºâ</li>
</ul>
</blockquote>
<p>üîÅ ÂèÇÊï∞Ê±ÇËß£ÊñπÊ≥ïÔºöÊ¢ØÂ∫¶‰∏ãÈôç</p>
<p>Áî±‰∫éÊçüÂ§±ÂáΩÊï∞ÈùûÁ∫øÊÄßÔºåÊó†Ê≥ïÁî®Ê≠£ËßÑÊñπÁ®ãËß£ÔºåÈúÄ‰ΩøÁî®<strong>Êï∞ÂÄº‰ºòÂåñÊñπÊ≥ï</strong>Ôºö</p>
<p>Ê¢ØÂ∫¶Êõ¥Êñ∞ÂÖ¨ÂºèÔºàÂØπÊçüÂ§±ÂáΩÊï∞Ê±ÇÂÅèÂØºÔºâÔºö</p>
<ul>
<li>ÂØπ $w_j$ ÁöÑÊ¢ØÂ∫¶Ôºö</li>
</ul>
<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}}{\partial w_j} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)}) x_j^{(i)}</script><ul>
<li>ÂØπ $b$ ÁöÑÊ¢ØÂ∫¶Ôºö</li>
</ul>
<script type="math/tex; mode=display">
\frac{\partial \mathcal{L}}{\partial b} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})</script><p>Êõ¥Êñ∞ÊñπÊ≥ïÔºö</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">w <span class="token operator">-=</span> alpha <span class="token operator">*</span> grad_w
b <span class="token operator">-=</span> alpha <span class="token operator">*</span> grad_b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></div></figure>
<p>üìä ‰∏æ‰æã</p>
<p>ÂÅáËÆæÊàë‰ª¨Ë¶ÅÈ¢ÑÊµã‰∏Ä‰∏™‰∫∫ÊòØÂê¶ÊÇ£Á≥ñÂ∞øÁóÖÔºö</p>
<ul>
<li>$x_1$ = Âπ¥ÈæÑÔºå$x_2$ = BMI</li>
<li>$y \in {0, 1}$ Ë°®Á§∫ÊòØÂê¶ÊÇ£ÁóÖ</li>
</ul>
<p>ËÆ≠ÁªÉÂêéÊ®°Âûã‰∏∫Ôºö</p>
<script type="math/tex; mode=display">
\hat{y} = \sigma(0.8x_1 + 1.2x_2 - 15)</script><p>‚úÖ ‰ºòÁÇπ</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>‰ºòÁÇπ</th>
<th>ÊèèËø∞</th>
</tr>
</thead>
<tbody>
<tr>
<td>ÁÆÄÂçïÈ´òÊïà</td>
<td>ÁÆóÊ≥ïÊòì‰∫éÂÆûÁé∞ÔºåËÆ°ÁÆó‰ª£‰ª∑‰Ωé</td>
</tr>
<tr>
<td>ËæìÂá∫Ê¶ÇÁéá</td>
<td>ÂèØÁî®‰∫éÈ£éÈô©Âª∫Ê®°„ÄÅÊéíÂ∫èÁ≠â‰ªªÂä°</td>
</tr>
<tr>
<td>ÂèØËß£ÈáäÊÄßÂº∫</td>
<td>Á≥ªÊï∞ÂèØË°®Á§∫ÊØè‰∏™ÁâπÂæÅÂØπÁªìÊûúÁöÑÂΩ±ÂìçÊñπÂêë‰∏éÂº∫Â∫¶</td>
</tr>
<tr>
<td>ÂèØÊâ©Â±ï‰∏∫Â§öÂàÜÁ±ª Softmax</td>
<td>ÊîØÊåÅÈÄªËæëÂõûÂΩíÁöÑÂ§öÁ±ªÊâ©Â±ï</td>
</tr>
</tbody>
</table>
</div>
<p>‚ö†Ô∏è Áº∫ÁÇπ</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Áº∫ÁÇπ</th>
<th>ÊèèËø∞</th>
</tr>
</thead>
<tbody>
<tr>
<td>Á∫øÊÄßÂèØÂàÜÊÄßÂÅáËÆæ</td>
<td>‰∏çËÉΩÂ§ÑÁêÜÂ§çÊùÇÈùûÁ∫øÊÄßÂÖ≥Á≥ª</td>
</tr>
<tr>
<td>ÂØπÂºÇÂ∏∏ÂÄºÊïèÊÑü</td>
<td>ÁâπÂæÅÊú™ÂΩí‰∏ÄÂåñÊó∂ÔºåÊ®°Âûã‰∏çÁ®≥ÂÆö</td>
</tr>
<tr>
<td>ÂÆπÊòìÊ¨†ÊãüÂêà</td>
<td>Â¶ÇÊûúÊï∞ÊçÆ‰∏çÊòØÁ∫øÊÄßÂèØÂàÜÔºåÊãüÂêàÊïàÊûúÂ∑Æ</td>
</tr>
</tbody>
</table>
</div>
<p>üìö Python Á§∫‰æã‰ª£Á†ÅÔºà<code>sklearn</code>Ôºâ</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment"># Âä†ËΩΩÊï∞ÊçÆÔºà‰ªÖÁî®Ââç‰∏§‰∏™Á±ªÂà´ÂÅö‰∫åÂàÜÁ±ªÔºâ</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> load_iris<span class="token punctuation">(</span>return_X_y<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> X<span class="token punctuation">[</span>y <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span>y <span class="token operator">!=</span> <span class="token number">2</span><span class="token punctuation">]</span>

X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"È¢ÑÊµãÊ¶ÇÁéá:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"È¢ÑÊµãÁªìÊûú:"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>üîÑ ‰∏éÁ∫øÊÄßÂõûÂΩíÁöÑÂå∫Âà´</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>È°πÁõÆ</th>
<th>Á∫øÊÄßÂõûÂΩí</th>
<th>ÈÄªËæëÂõûÂΩí</th>
</tr>
</thead>
<tbody>
<tr>
<td>ËæìÂá∫</td>
<td>ÂÆûÊï∞</td>
<td>Ê¶ÇÁéáÂÄº $\in (0, 1)$</td>
</tr>
<tr>
<td>Áî®ÈÄî</td>
<td>ÂõûÂΩíÈóÆÈ¢òÔºàËøûÁª≠ÂÄºÔºâ</td>
<td>ÂàÜÁ±ªÈóÆÈ¢òÔºà‰∫åÂàÜÁ±ª/Â§öÂàÜÁ±ªÔºâ</td>
</tr>
<tr>
<td>ÊøÄÊ¥ªÂáΩÊï∞</td>
<td>Êó†</td>
<td>Sigmoid / Softmax</td>
</tr>
<tr>
<td>ÊçüÂ§±ÂáΩÊï∞</td>
<td>ÂùáÊñπËØØÂ∑Æ MSE</td>
<td>ÂØπÊï∞ÊçüÂ§± Log Loss</td>
</tr>
<tr>
<td>ÊãüÂêàÊñπÂºè</td>
<td>ÊúÄÂ∞è‰∫å‰πòÊàñÊ¢ØÂ∫¶‰∏ãÈôç</td>
<td>ÊúÄÂ§ß‰ººÁÑ∂‰º∞ËÆ°ÔºàMLEÔºâ + Ê¢ØÂ∫¶‰∏ãÈôç</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h3 id="Reinforcement-Learning-RL"><a href="#Reinforcement-Learning-RL" class="headerlink" title="Reinforcement Learning (RL)"></a>Reinforcement Learning (RL)</h3><p>Reinforcement Learning (RL) is a type of machine learning method whose core idea is <strong>learning the optimal policy through interaction with the environment</strong>. In simple terms, an agent interacts with an environment by taking actions, receives rewards or penalties based on the outcomes, and continuously adjusts its behavior to maximize the long-term cumulative reward.</p>
<p>Key components include:</p>
<ol>
<li><strong>Agent</strong>: The entity that performs actions.</li>
<li><strong>Environment</strong>: The external system in which the agent operates, providing feedback on actions.</li>
<li><strong>State (s)</strong>: A description of the environment at a given time.</li>
<li><strong>Action (a)</strong>: The choices the agent can make.</li>
<li><strong>Reward (r)</strong>: Immediate feedback from the environment, used to evaluate the quality of actions.</li>
<li><strong>Policy (œÄ)</strong>: The rule the agent follows to select actions based on the state.</li>
<li><strong>Value Function (V)</strong>: Evaluates the expected future cumulative reward of a state or state-action pair.</li>
</ol>
<p>The main goal of reinforcement learning is <strong>to learn an optimal policy that allows the agent to maximize its long-term cumulative reward</strong>.</p>
<hr>
<h3 id="Q-Learning"><a href="#Q-Learning" class="headerlink" title="Q Learning"></a>Q Learning</h3><p>Q-Learning is a <strong>model-free</strong> algorithm in Reinforcement Learning used to learn the optimal policy. It works by learning a <strong>Q-function (Q-Value Function)</strong> that evaluates the value of each state-action pair, guiding the agent to choose actions that maximize long-term rewards.</p>
<p>Core ideas:</p>
<ol>
<li><p><strong>Q-function (Q(s, a))</strong>: Represents the <strong>expected cumulative reward</strong> of taking action <code>a</code> in state <code>s</code>.</p>
</li>
<li><p><strong>Update formula (Bellman equation)</strong>:</p>
<script type="math/tex; mode=display">
Q(s, a) \gets Q(s, a) + \alpha \big[ r + \gamma \max_{a'} Q(s', a') - Q(s, a) \big]</script><ul>
<li>$\alpha$: learning rate, controlling the update step</li>
<li>$\gamma$: discount factor, balancing immediate and future rewards</li>
<li>$r$: immediate reward received from the action</li>
<li>$s‚Äô$: the new state after taking the action</li>
</ul>
</li>
<li><p><strong>Learning process</strong>: The agent explores the environment and continuously updates the Q-values. Eventually, it converges to the optimal Q-function, allowing the agent to <strong>select the action with the maximum expected reward in each state</strong>.</p>
</li>
</ol>
<p>In short, Q-Learning is a method that enables an agent to learn the best decisions in each state through trial-and-error experience.</p>
<hr>
<h3 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h3><p>Cross validation is a method in machine learning used to <strong>evaluate model performance and prevent overfitting</strong>. It works by <strong>splitting the dataset into multiple parts, training the model on some parts, and validating it on the remaining parts</strong>, providing a more reliable estimate of how the model will perform on unseen data.</p>
<p>Core ideas:</p>
<ol>
<li><strong>Data splitting</strong>: Divide the dataset into $k$ parts (folds), commonly called <strong>k-fold cross validation</strong>.</li>
<li><p><strong>Training and validation</strong>:</p>
<ul>
<li>In each iteration, use $k-1$ folds as the training set and the remaining fold as the validation set.</li>
<li>Train the model and evaluate its performance on the validation set (e.g., accuracy, mean squared error).</li>
</ul>
</li>
<li><strong>Repeat $k$ times</strong>: Each fold serves as the validation set once.</li>
<li><strong>Aggregate results</strong>: Average the performance metrics over the $k$ iterations to get a reliable estimate of the model‚Äôs overall performance.</li>
</ol>
<p>Advantages:</p>
<ul>
<li>Provides a more stable assessment of model performance, reducing bias from a single train-test split.</li>
<li>Helps in model selection and hyperparameter tuning.</li>
</ul>
<p>Common variants:</p>
<ul>
<li><strong>Leave-One-Out CV (LOOCV)</strong>: Each iteration leaves one sample for validation.</li>
<li><strong>Stratified k-Fold CV</strong>: Maintains the proportion of each class in classification problems.</li>
</ul>
<p>In short, cross validation allows the model to <strong>‚Äúpractice and test‚Äù on different data splits multiple times, yielding a more robust estimate of performance</strong>.</p>
<hr>
<h3 id="Policy-based-and-Value-based-methods"><a href="#Policy-based-and-Value-based-methods" class="headerlink" title="Policy-based and Value-based methods"></a>Policy-based and Value-based methods</h3><p>In Reinforcement Learning (RL), <strong>Policy-based</strong> and <strong>Value-based</strong> methods are two core approaches. The main difference lies in what they learn: one learns the policy directly, while the other learns the value function.</p>
<p><strong>Value-based Methods</strong></p>
<p><strong>Core idea</strong>: Learn the <strong>value function</strong> and derive the optimal policy indirectly.</p>
<ul>
<li><p><strong>Types of value functions</strong>:</p>
<ul>
<li><strong>State value function $V(s)$</strong>: Expected cumulative reward starting from state $s$.</li>
<li><strong>Action value function $Q(s, a)$</strong>: Expected cumulative reward of taking action $a$ in state $s$.</li>
</ul>
</li>
<li><p><strong>Typical algorithms</strong>:</p>
<ul>
<li>Q-Learning</li>
<li>Deep Q-Network (DQN)</li>
</ul>
</li>
<li><p><strong>Characteristics</strong>:</p>
<ul>
<li><p>Does not directly output a policy. The policy is obtained by selecting the action with the highest value in each state:</p>
<script type="math/tex; mode=display">
\pi(s) = \arg\max_a Q(s, a)</script></li>
<li>Better suited for discrete action spaces.</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Policy-based Methods</strong></p>
<p><strong>Core idea</strong>: Learn the <strong>policy function $\pi(a|s)$</strong> directly, which outputs the probability of taking each action in a given state.</p>
<ul>
<li><p><strong>Characteristics</strong>:</p>
<ul>
<li>Optimizes the policy directly without first learning a value function.</li>
<li>Naturally handles continuous action spaces.</li>
<li><p>Often uses gradient-based methods to optimize the policy:</p>
<script type="math/tex; mode=display">
\nabla_\theta J(\theta) = \mathbb{E}_{s,a \sim \pi_\theta} \Big[ \nabla_\theta \log \pi_\theta(a|s) \, Q^{\pi_\theta}(s, a) \Big]</script></li>
</ul>
</li>
<li><p><strong>Typical algorithms</strong>:</p>
<ul>
<li>REINFORCE</li>
<li>Actor-Critic (combines policy and value approaches)</li>
</ul>
</li>
</ul>
<hr>
<p>Summary Comparison</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Value-based</th>
<th>Policy-based</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Learning target</td>
<td>Value function $V$ or $Q$</td>
<td>Policy (\pi(a</td>
<td>s))</td>
</tr>
<tr>
<td>Output</td>
<td>Optimal action or action values</td>
<td>Action probability distribution</td>
<td></td>
</tr>
<tr>
<td>Action space</td>
<td>Discrete</td>
<td>Discrete or continuous</td>
<td></td>
</tr>
<tr>
<td>Advantages</td>
<td>Stable, easy to understand</td>
<td>Handles continuous actions, more flexible</td>
<td></td>
</tr>
<tr>
<td>Disadvantages</td>
<td>Hard to handle continuous actions</td>
<td>Slower convergence, higher variance</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>In short:</p>
<ul>
<li><strong>Value-based</strong>: First learn ‚Äúwhich actions are good,‚Äù then select actions.</li>
<li><strong>Policy-based</strong>: Directly learn ‚Äúwhat action to take in each state.‚Äù</li>
</ul>
<hr>
<h3 id="Supervised-Learning-VS-Unsupervised-Learning"><a href="#Supervised-Learning-VS-Unsupervised-Learning" class="headerlink" title="Supervised Learning VS Unsupervised Learning"></a>Supervised Learning VS Unsupervised Learning</h3><p>In Machine Learning, <strong>Supervised Learning</strong> and <strong>Unsupervised Learning</strong> are two fundamental paradigms. The main difference lies in whether the training data includes labels.</p>
<hr>
<p><strong>Supervised Learning</strong></p>
<p><strong>Definition:</strong><br>Supervised learning uses <strong>labeled data</strong> for training, allowing the model to learn the mapping between input and output. The goal is for the model to correctly predict outputs for new, unseen inputs.</p>
<p><strong>Key characteristics:</strong></p>
<ul>
<li>Training data contains inputs $X$ and corresponding labels $Y$</li>
<li>The model learns by minimizing the error between predicted outputs and true labels</li>
</ul>
<p><strong>Common tasks:</strong></p>
<ul>
<li><strong>Classification</strong>: Output is a discrete label, e.g., spam detection (spam/ham), sentiment analysis (positive/negative)</li>
<li><strong>Regression</strong>: Output is a continuous value, e.g., house price prediction, stock price forecasting</li>
</ul>
<p><strong>Typical algorithms:</strong></p>
<ul>
<li>Logistic Regression</li>
<li>Support Vector Machines (SVM)</li>
<li>Decision Trees, Random Forests</li>
<li>Neural Networks</li>
</ul>
<hr>
<p><strong>Unsupervised Learning</strong></p>
<p><strong>Definition:</strong><br>Unsupervised learning uses <strong>unlabeled data</strong> for training. The model must discover patterns, structures, or distributions in the data on its own.</p>
<p><strong>Key characteristics:</strong></p>
<ul>
<li>Training data only contains input $X$, no corresponding output</li>
<li>The model identifies patterns, similarities, or clusters in the data</li>
</ul>
<p><strong>Common tasks:</strong></p>
<ul>
<li><strong>Clustering</strong>: Grouping similar data points, e.g., customer segmentation, image grouping</li>
<li><strong>Dimensionality Reduction</strong>: Simplifying data representation, e.g., PCA, t-SNE, for visualization or feature extraction</li>
<li><strong>Anomaly Detection</strong>: Identifying outlier data points</li>
</ul>
<p><strong>Typical algorithms:</strong></p>
<ul>
<li>K-Means</li>
<li>Hierarchical Clustering</li>
<li>Principal Component Analysis (PCA)</li>
<li>Autoencoders</li>
</ul>
<hr>
<p>Summary Comparison</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Supervised Learning</th>
<th>Unsupervised Learning</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data type</td>
<td>Labeled data</td>
<td>Unlabeled data</td>
</tr>
<tr>
<td>Goal</td>
<td>Learn input-output mapping</td>
<td>Discover data structure or patterns</td>
</tr>
<tr>
<td>Output</td>
<td>Class labels or continuous values</td>
<td>Clusters, feature representations, or anomalies</td>
</tr>
<tr>
<td>Example</td>
<td>Spam detection, house price prediction</td>
<td>Customer segmentation, dimensionality reduction</td>
</tr>
</tbody>
</table>
</div>
<hr>
<p>Simple intuition:</p>
<ul>
<li><strong>Supervised Learning</strong>: A teacher provides the ‚Äúcorrect answers,‚Äù and you learn to predict.</li>
<li><strong>Unsupervised Learning</strong>: No teacher; you discover patterns on your own.</li>
</ul>
<h2 id="7-Digital-Circuit"><a href="#7-Digital-Circuit" class="headerlink" title="7. Digital Circuit"></a>7. Digital Circuit</h2><h2 id="8-Computer-Networks"><a href="#8-Computer-Networks" class="headerlink" title="8. Computer Networks"></a>8. Computer Networks</h2><h3 id="Distributed-Hash-Table-DHT"><a href="#Distributed-Hash-Table-DHT" class="headerlink" title="Distributed Hash Table (DHT)"></a>Distributed Hash Table (DHT)</h3><p>A <strong>Distributed Hash Table (DHT)</strong> is a decentralized system that provides a lookup service similar to a hash table: it stores <strong>(key, value)</strong> pairs and allows efficient retrieval of the value given a key. Instead of relying on a central server, DHT distributes the data across a network of nodes (often used in <strong>peer-to-peer networks</strong> and <strong>IoT</strong> systems).</p>
<p>Key Features:</p>
<ul>
<li><strong>Scalable</strong>: Works well even with thousands of nodes.</li>
<li><strong>Fault-tolerant</strong>: Data is replicated, so the system can handle node failures.</li>
<li><strong>Efficient</strong>: Most DHTs (like Chord or Kademlia) can find data in <strong>O(log n)</strong> time.</li>
</ul>
<p>DHTs are often used in applications like <strong>BitTorrent</strong> and <strong>distributed file systems</strong>, and are relevant in wireless and digital communication contexts, which aligns well with your research interests in IoT.</p>
<p><img src="/img/concepts/dht.svg" srcset="/img/loading.gif" lazyload alt="DHT" style="max-width: 100%; height: auto;" /></p>
<hr>
<h3 id="Ethernet"><a href="#Ethernet" class="headerlink" title="Ethernet"></a>Ethernet</h3><p>Ethernet is a communication technology used for local area networks (LANs). It defines how computers and network devices send and receive data over a wired medium, typically twisted-pair cables or fiber optics. In brief:</p>
<ol>
<li><p><strong>Basic Principle</strong>: Ethernet uses <strong>frames</strong> as the basic unit of data transmission. Each frame contains the destination address, source address, data, and a checksum (CRC) for error detection.</p>
</li>
<li><p><strong>Communication Method</strong>: Traditional Ethernet uses <strong>CSMA/CD (Carrier Sense Multiple Access with Collision Detection)</strong> to avoid data collisions. Modern switched Ethernet largely eliminates the need for collision detection, as each port has a dedicated communication channel.</p>
</li>
<li><p><strong>Speed and Evolution</strong>: The original Ethernet speed was <strong>10 Mbps</strong>, later evolving to <strong>100 Mbps (Fast Ethernet), 1 Gbps (Gigabit Ethernet), 10 Gbps</strong>, and even higher.</p>
</li>
<li><p><strong>Applications</strong>: Ethernet is the most widely used wired LAN standard, connecting computers, servers, routers, and switches to enable data transmission within a local network.</p>
</li>
</ol>
<hr>
<h3 id="Mac-Address"><a href="#Mac-Address" class="headerlink" title="Mac Address"></a>Mac Address</h3><p>A MAC address (<strong>Media Access Control Address</strong>) is an address that uniquely identifies a network device within a <strong>local area network (LAN)</strong>. It is used in network technologies like <strong>Ethernet and Wi-Fi</strong>, operating at the <strong>data link layer (Layer 2 of the OSI model)</strong>.</p>
<p><strong>Key Points:</strong></p>
<ol>
<li><p><strong>Uniqueness</strong></p>
<ul>
<li>Each network interface card (NIC) or wireless module has a unique MAC address, usually assigned by the manufacturer.</li>
<li>It is typically 48 bits long and represented as <strong>six hexadecimal pairs</strong>, for example: <code>00:1A:2B:3C:4D:5E</code>.</li>
</ul>
</li>
<li><p><strong>Function</strong></p>
<ul>
<li>Identifies devices within a LAN.</li>
<li>Used as the <strong>source and destination address</strong> in Ethernet frames, ensuring data reaches the correct device.</li>
</ul>
</li>
<li><p><strong>Difference from IP Address</strong></p>
<ul>
<li><strong>MAC Address</strong>: Hardware address, fixed and unique within a LAN.</li>
<li><strong>IP Address</strong>: Logical address, can change with the network environment, used for routing across networks.</li>
</ul>
</li>
</ol>
<hr>
<p>üí° <strong>Analogy</strong>:</p>
<ul>
<li>A MAC address is like a <strong>house number</strong>, used to locate a specific house within a neighborhood (LAN).</li>
<li>An IP address is like the <strong>street and city address</strong>, used to find the house across cities or networks.</li>
</ul>
<hr>
<h3 id="Time-Division-Multiple-Access-TDMA"><a href="#Time-Division-Multiple-Access-TDMA" class="headerlink" title="Time Division Multiple Access (TDMA)"></a>Time Division Multiple Access (TDMA)</h3><p>In computer networks and communication systems, <strong>Time Division Multiple Access (TDMA)</strong> is a technique that allows <strong>multiple users to share the same frequency resource</strong> by dividing time into separate slots for each user.</p>
<hr>
<p><strong>Basic Concept</strong></p>
<ul>
<li><strong>TDMA principle</strong>: A frequency channel is divided into several consecutive <strong>time slots</strong>, and each user transmits data exclusively during its assigned slot.</li>
<li><strong>Core idea</strong>: Different users use the same frequency at <strong>different times</strong> to avoid collisions.</li>
</ul>
<hr>
<p><strong>Working Process</strong></p>
<ol>
<li><p><strong>Frame structure</strong>:</p>
<ul>
<li>TDMA divides the communication cycle into <strong>frames</strong>, and each frame is further divided into several <strong>time slots</strong>.</li>
<li>Each user is assigned one or more fixed time slots.</li>
</ul>
</li>
<li><p><strong>Transmission and reception</strong>:</p>
<ul>
<li>When a user‚Äôs time slot arrives, it sends data while other users remain idle or receive.</li>
<li>After the time slot ends, the next user transmits.</li>
</ul>
</li>
<li><p><strong>Synchronization requirement</strong>:</p>
<ul>
<li>Precise time synchronization is needed to ensure users transmit strictly within their own slots (via synchronization signals or clocks).</li>
</ul>
</li>
</ol>
<hr>
<p><strong>Characteristics</strong></p>
<ul>
<li><p><strong>Advantages</strong>:</p>
<ul>
<li>No interference: Users transmit at different times without colliding.</li>
<li>High spectrum efficiency: The same frequency can be shared by multiple users.</li>
<li>Simple and easy to implement, suitable for systems with a fixed number of users.</li>
</ul>
</li>
<li><p><strong>Disadvantages</strong>:</p>
<ul>
<li>High requirement for time synchronization, increasing hardware complexity.</li>
<li>If a user has no data to send, the time slot is wasted (low efficiency).</li>
<li>Not ideal for bursty traffic with unpredictable data.</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Applications</strong></p>
<ul>
<li><strong>GSM cellular networks</strong>: Each user occupies a different time slot for voice or data transmission.</li>
<li><strong>Satellite communication</strong>: Multiple users share the same uplink/downlink frequency channel.</li>
<li><strong>Industrial control networks</strong>: Periodic data collection and transmission.</li>
</ul>
<hr>
<p>Simple analogy:</p>
<blockquote>
<p>TDMA is like taking turns on a single-lane road‚Äîeach person drives during their assigned time slot to avoid congestion.</p>
</blockquote>
<hr>
<h3 id="ALOHA"><a href="#ALOHA" class="headerlink" title="ALOHA"></a>ALOHA</h3><p><strong>ALOHA</strong> is an early wireless multiple access protocol that allows multiple terminals to share the same channel. Its core idea is <strong>transmit whenever you have data, and retransmit if a collision occurs</strong>.</p>
<hr>
<p><strong>Basic Principle</strong></p>
<ul>
<li>Each terminal <strong>sends a data frame immediately</strong> when it has data.</li>
<li>If two terminals transmit simultaneously, a <strong>collision</strong> occurs.</li>
<li>After a collision, the terminal waits for a random time before <strong>retransmitting</strong> the data.</li>
</ul>
<hr>
<p><strong>Characteristics</strong></p>
<ul>
<li><p><strong>Advantages</strong>:</p>
<ul>
<li>Simple and easy to implement</li>
<li>No complex scheduling mechanism required</li>
</ul>
</li>
<li><p><strong>Disadvantages</strong>:</p>
<ul>
<li>Low spectrum efficiency (high collision rate)</li>
<li>Efficiency drops significantly as the number of terminals increases</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Improved Versions</strong></p>
<ul>
<li><strong>Pure ALOHA</strong>: Terminals transmit whenever they have data; if a collision occurs, they retransmit after a random delay.</li>
<li><strong>Slotted ALOHA</strong>: Time is divided into fixed slots, and terminals can only transmit at the beginning of a slot, reducing the collision probability by half.</li>
</ul>
<hr>
<p>Simple analogy:</p>
<blockquote>
<p>Pure ALOHA is like everyone speaking on the same channel whenever they want‚Äîif they speak at the same time, a collision occurs and they retry. Slotted ALOHA is like everyone taking turns speaking in time slots, reducing the chance of collisions.</p>
</blockquote>
<h2 id="9-Cryptography"><a href="#9-Cryptography" class="headerlink" title="9. Cryptography"></a>9. Cryptography</h2><h3 id="üîê-Digital-Signatures"><a href="#üîê-Digital-Signatures" class="headerlink" title="üîê Digital Signatures"></a>üîê Digital Signatures</h3><p>A <strong>digital signature</strong> is a <strong>cryptographic technique</strong> used to <strong>verify the authenticity and integrity</strong> of a digital message or document.<br>It is a <strong>secure form of electronic signature</strong> based on <strong>public-key cryptography</strong>.</p>
<p><strong>üõ†Ô∏è How It Works</strong></p>
<ol>
<li>The sender signs the document using a <strong>private key</strong>.</li>
<li>The recipient verifies the signature using the sender‚Äôs <strong>public key</strong>.</li>
<li><p>If the verification succeeds, the document:</p>
<ul>
<li><strong>Came from the sender</strong></li>
<li><strong>Was not altered</strong> in transit</li>
</ul>
</li>
</ol>
<p><strong>‚úÖ Key Properties</strong></p>
<ul>
<li><strong>Authentication</strong>: Confirms the sender‚Äôs identity</li>
<li><strong>Integrity</strong>: Ensures the content has not been tampered with</li>
<li><strong>Non-repudiation</strong>: The sender cannot deny having signed it</li>
</ul>
<p><strong>üìå Common Use Cases</strong></p>
<ul>
<li>Signing software and updates</li>
<li>Securing emails (e.g., with S/MIME or PGP)</li>
<li>Digital contracts and government forms</li>
<li>Blockchain and cryptocurrencies (e.g., Bitcoin transactions)</li>
</ul>
<h2 id="10-Digital-Signal-Processing"><a href="#10-Digital-Signal-Processing" class="headerlink" title="10. Digital Signal Processing"></a>10. Digital Signal Processing</h2><h2 id="11-Control-Engineering"><a href="#11-Control-Engineering" class="headerlink" title="11. Control Engineering"></a>11. Control Engineering</h2><h2 id="12-Software-Development"><a href="#12-Software-Development" class="headerlink" title="12. Software Development"></a>12. Software Development</h2><h2 id="13-Robotics"><a href="#13-Robotics" class="headerlink" title="13. Robotics"></a>13. Robotics</h2><h2 id="14-Numerical-Computing"><a href="#14-Numerical-Computing" class="headerlink" title="14. Numerical Computing"></a>14. Numerical Computing</h2><h3 id="üí•-Loss-of-Significance"><a href="#üí•-Loss-of-Significance" class="headerlink" title="üí• Loss of Significance"></a>üí• Loss of Significance</h3><p><strong>Definition</strong>:<br>Loss of significance occurs when <strong>two nearly equal numbers are subtracted</strong>, causing the <strong>most significant digits to cancel out</strong>, leaving behind only less significant digits. This results in a <strong>large relative error</strong> due to the limited precision of floating-point arithmetic.</p>
<p><strong>Example</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Let a = 123456.78
    b = 123456.71
Then a - b = 0.07 (correct result)

However, in floating-point representation (with limited digits):
    a ‚âà 1.2345678 √ó 10^5
    b ‚âà 1.2345671 √ó 10^5

The subtraction may cause significant digit loss!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p><strong>Why it matters</strong>:</p>
<ul>
<li>It reduces <strong>numerical accuracy</strong>.</li>
<li>It‚Äôs especially dangerous in algorithms involving derivatives, roots, or iterative methods.</li>
</ul>
<p><strong>Typical scenario</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">f(x) = (1 - cos(x)) / x^2, when x ‚Üí 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>This can lead to significant errors because <code>1 - cos(x)</code> is a subtraction of two nearly equal numbers.</p>
<hr>
<h3 id="üßÆ-Loss-of-Trailing-Digits"><a href="#üßÆ-Loss-of-Trailing-Digits" class="headerlink" title="üßÆ Loss of Trailing Digits"></a>üßÆ Loss of Trailing Digits</h3><p><strong>Definition</strong>:<br>Loss of trailing digits occurs when a <strong>large and a small number are added together</strong>, and the <strong>small number is too small to affect the sum</strong> due to the limits of floating-point precision.</p>
<p><strong>Example</strong>:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-text" data-language="text"><code class="language-text">Let a = 1.000000000000000
    b = 0.000000000000001

In floating-point (double precision), a + b ‚âà 1.000000000000000
The small value of b is 'lost' ‚Äî this is loss of trailing digits.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p><strong>Why it matters</strong>:</p>
<ul>
<li>It causes <strong>rounding errors</strong> in accumulation.</li>
<li>In long summation processes (e.g., numerical integration), many small contributions may be <strong>entirely ignored</strong>.</li>
</ul>
<hr>
<p><strong>üß† Summary Table</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Concept</th>
<th>Trigger</th>
<th>Effect</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Loss of Significance</strong></td>
<td>Subtraction of close numbers</td>
<td>Large <strong>relative error</strong></td>
<td><code>(1 - cos(x)) / x^2</code></td>
</tr>
<tr>
<td><strong>Loss of Trailing Digits</strong></td>
<td>Addition of large + small number</td>
<td>Small number gets ignored</td>
<td><code>1.0 + 1e-15 = 1.0</code></td>
</tr>
</tbody>
</table>
</div>
<h2 id="15-Information-Theory"><a href="#15-Information-Theory" class="headerlink" title="15. Information Theory"></a>15. Information Theory</h2><h3 id="üì¶-Run-Length-Encoding-RLE"><a href="#üì¶-Run-Length-Encoding-RLE" class="headerlink" title="üì¶ Run-Length Encoding (RLE)"></a>üì¶ Run-Length Encoding (RLE)</h3><p><strong>üß† What is it?</strong></p>
<p><strong>Run-Length Encoding</strong> is a <strong>lossless compression algorithm</strong> that works by compressing sequences of repeated data elements (called <strong>runs</strong>) into a single value and a count.</p>
<p><strong>‚öôÔ∏è How it works</strong></p>
<p>When the same character appears multiple times in a row, RLE replaces it with a single character and the number of repetitions.</p>
<p><strong>‚úÖ Example</strong></p>
<p>Original data:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">AAAAABBBCCDAA<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>RLE encoded:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">5A3B2C1D2A<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>This means:</p>
<ul>
<li>5 A‚Äôs</li>
<li>3 B‚Äôs</li>
<li>2 C‚Äôs</li>
<li>1 D</li>
<li>2 A‚Äôs</li>
</ul>
<p><strong>üìå Use Cases</strong></p>
<ul>
<li>Bitmap image compression (e.g., simple black and white images)</li>
<li>Fax machines</li>
<li>Data with lots of repetition</li>
</ul>
<p><strong>‚ö†Ô∏è Limitation</strong></p>
<ul>
<li>Not efficient if the data doesn‚Äôt have many repeated characters (may even increase size).</li>
</ul>
<hr>
<h3 id="üå≤-Huffman-Encoding"><a href="#üå≤-Huffman-Encoding" class="headerlink" title="üå≤ Huffman Encoding"></a>üå≤ Huffman Encoding</h3><p><strong>üß† What is it?</strong></p>
<p><strong>Huffman Encoding</strong> is a <strong>lossless compression technique</strong> that assigns <strong>variable-length binary codes</strong> to characters based on their <strong>frequency</strong>. More frequent characters get <strong>shorter codes</strong>, while less frequent ones get <strong>longer codes</strong>.</p>
<p><strong>‚öôÔ∏è How it works</strong></p>
<ol>
<li>Count the frequency of each character.</li>
<li>Build a <strong>Huffman Tree</strong> using a greedy algorithm.</li>
<li>Assign binary codes to characters by traversing the tree.</li>
</ol>
<p><strong>‚úÖ Example</strong></p>
<p>Given character frequencies:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">A: 45%, B: 13%, C: 12%, D: 16%, E: 14%<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></div></figure>
<p>Possible Huffman codes:</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">A: 0
B: 101
C: 100
D: 111
E: 110<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></figure>
<p>More frequent characters like <code>A</code> get shorter codes.</p>
<p><strong>üìå Use Cases</strong></p>
<ul>
<li>JPEG and PNG image compression</li>
<li>MP3 and audio compression</li>
<li>ZIP file compression</li>
<li>Data transmission and storage</li>
</ul>
<p><strong>‚ö†Ô∏è Limitation</strong></p>
<ul>
<li>Needs to store or transmit the code table (or tree structure).</li>
<li>Slightly more complex to implement than RLE.</li>
</ul>
<p><strong>üßæ Comparison Table</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Feature</th>
<th>Run-Length Encoding</th>
<th>Huffman Encoding</th>
</tr>
</thead>
<tbody>
<tr>
<td>Type</td>
<td>Lossless</td>
<td>Lossless</td>
</tr>
<tr>
<td>Strategy</td>
<td>Compress repeated values</td>
<td>Compress based on frequency</td>
</tr>
<tr>
<td>Best for</td>
<td>Repetitive data</td>
<td>Skewed frequency distributions</td>
</tr>
<tr>
<td>Efficiency</td>
<td>Very simple, fast</td>
<td>More efficient, more complex</td>
</tr>
<tr>
<td>Limitation</td>
<td>Ineffective for random data</td>
<td>Tree must be constructed</td>
</tr>
</tbody>
</table>
</div>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%B8%93%E4%B8%9A%E7%A7%91%E7%9B%AE%E7%AC%94%E8%AE%B0/" class="category-chain-item">‰∏ì‰∏öÁßëÁõÆÁ¨îËÆ∞</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E4%BF%AE%E8%80%83/" class="print-no-link">#‰øÆËÄÉ</a>
      
        <a href="/tags/CS-Concepts/" class="print-no-link">#CS Concepts</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>CS Concepts</div>
      <div>http://toutou.zeabur.app/2025/02/09/CS-Concepts/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>toutou</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>February 9, 2025</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - Non-commercial">
                    <i class="iconfont icon-cc-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - Share-alike">
                    <i class="iconfont icon-cc-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/02/21/Calculus/" title="Calculus">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Calculus</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/02/09/computer-networks/" title="Computer Networks">
                        <span class="hidden-mobile">Computer Networks</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://www.instagram.com/hanni_rio/" target="_blank" rel="nofollow noopener"><span>Hanni Rio</span></a> <i class="iconfont icon-copyright"></i> <a href="https://toutou.pro/" target="_blank" rel="nofollow noopener"><span>toutou</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script  src="https://lib.baomitu.com/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.js" ></script>

  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- ‰∏ªÈ¢òÁöÑÂêØÂä®È°πÔºåÂ∞ÜÂÆÉ‰øùÊåÅÂú®ÊúÄÂ∫ïÈÉ® -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
